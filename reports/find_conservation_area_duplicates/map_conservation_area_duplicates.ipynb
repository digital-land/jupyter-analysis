{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conservation area overlaps report\n",
    "**Author**:  Greg Slater <br>\n",
    "**Date**:  6th August 2024 <br>\n",
    "**Dataset Scope**: conservation-area <br>\n",
    "**Report Type**: Ad-hoc <br>\n",
    "\n",
    "## Purpose\n",
    "This report helps investigate issues where LPA conservation area entities are overlapping with Historic England conservation area entities, by showing issues on a map.\n",
    "\n",
    "Run the whole notebook and use the drop-down in the bottom cell to select an LPA. By default all conservation area entities within the LPA will be displayed, but there is a toggle button which can be used to show only those with overlap issues.\n",
    "\n",
    "Overlap issues are defined as where there is some overlap between the polygons of an LPA entity and a Historic England entity.\n",
    "\n",
    "The categories below are used to describe the types of matches which can occur between two entities (note that a single entity can have multiple overlap issues if it overlaps with more than one other entity). These definitions use some thresholds of the % of overlap between two entities to define \"match\", \"partial\", or \"edge\" overlaps. The default thresholds used are highlighted in the definitions below, but they can also be changed by the user if required (see the \"Geographical duplicate identification\" section).\n",
    "\n",
    "\n",
    "* **No overlap issues**: the two entities do not overlap at all. <br></br>\n",
    "* **Complete match (two-way)**: the two entities both overlap each other by more than the match threshold (default 90%) - this suggests the boundaries of each polygon closely match. These entities can usually be merged. <br></br>\n",
    "* **Single match (one-way)**: just one entity is overlapped by the other by more than the match threshold (default 90%) - this is usually where one entity is completely or partially covered by another, larger entity. These may need further investigation or escalation with the LPA. <br></br>\n",
    "* **Partial match**: the two entities overlap but by less than the match treshold for each (default 90%). These may need further investigation or escalation with the LPA. <br></br>\n",
    "* **Edge overlap**: the two entities both overlap each other by an amount between the edge threshold (default between 1-10%). These may not be a serious issue, but may still be raised with the LPA. <br></br>\n",
    "\n",
    "The image below gives a visual breakdown of these categories:\n",
    "\n",
    "<img src=\"overlap_issue_types.png\" style=\"height:1.in\"/> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if running on Colab, uncomment and run this line below too:\n",
    "# !pip install mapclassify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import shapely.wkt\n",
    "import urllib\n",
    "import numpy as np\n",
    "import os\n",
    "import folium\n",
    "import ipywidgets as widgets\n",
    "from datetime import datetime\n",
    "\n",
    "td = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "output_dir = \"../../data/reports/conservation-area-duplicates/\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_organisations():\n",
    "    params = urllib.parse.urlencode({\n",
    "        \"sql\": f\"\"\"\n",
    "        select entity as organisation_entity, name as organisation_name, organisation, dataset, local_planning_authority\n",
    "        from organisation\n",
    "        \"\"\",\n",
    "        \"_size\": \"max\"\n",
    "        })\n",
    "    url = f\"https://datasette.planning.data.gov.uk/digital-land.csv?{params}\"\n",
    "    df = pd.read_csv(url)\n",
    "    return df\n",
    "\n",
    "def get_pdp_geo_dataset(dataset, underscore_cols=True, crs_out=27700):\n",
    "\n",
    "    url = f\"https://files.planning.data.gov.uk/dataset/{dataset}.geojson\"\n",
    "    gdf = gpd.read_file(url)\n",
    "\n",
    "    if underscore_cols:\n",
    "        gdf.columns = [x.replace(\"-\", \"_\") for x in gdf.columns]\n",
    "\n",
    "\n",
    "    gdf.set_crs(epsg=4326, inplace=True)\n",
    "    gdf.to_crs(epsg=crs_out, inplace=True)\n",
    "\n",
    "    return gdf\n",
    "\n",
    "def get_provisions():\n",
    "    global provisions_df  \n",
    "    params = urllib.parse.urlencode({\n",
    "        \"sql\": f\"\"\"\n",
    "            SELECT\n",
    "                cohort, notes, organisation, project, provision_reason, start_date\n",
    "            FROM\n",
    "                provision   \n",
    "            WHERE \n",
    "                provision_reason = \"expected\"\n",
    "                AND project = \"open-digital-planning\"\n",
    "            GROUP BY organisation\n",
    "            ORDER BY cohort\n",
    "        \"\"\",\n",
    "        \"_size\": \"max\"\n",
    "    })\n",
    "    url = f\"https://datasette.planning.data.gov.uk/digital-land.csv?{params}\"\n",
    "    provisions_df = pd.read_csv(url)\n",
    "    return provisions_df\n",
    "\n",
    "def get_old_entity(collection_name):\n",
    "    params = urllib.parse.urlencode({\n",
    "        \"sql\": f\"\"\"\n",
    "        select *\n",
    "        from old_entity\n",
    "        \"\"\",\n",
    "        \"_size\": \"max\"\n",
    "        })\n",
    "    url = f\"https://datasette.planning.data.gov.uk/{collection_name}.csv?{params}\"\n",
    "    df = pd.read_csv(url)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_lpa_issues(lpa_name, show_only_issues = False):\n",
    "\n",
    "    if show_only_issues:\n",
    "        map_gdf = lpa_ca_all[\n",
    "            (lpa_ca_all[\"lpa_name\"] == lpa_name) &\n",
    "            lpa_ca_all[\"has_overlap_issues\"]].copy()\n",
    "        \n",
    "    else: map_gdf = lpa_ca_all[lpa_ca_all[\"lpa_name\"] == lpa_name].copy()\n",
    "\n",
    "    print(map_gdf.groupby([\"lpa_name\", \"overlap_issue_types\"], dropna=False).size().reset_index(name = \"n_entities\"))\n",
    "\n",
    "    ents_lpa = map_gdf[map_gdf[\"organisation_entity\"] != 16]\n",
    "    ents_he = map_gdf[map_gdf[\"organisation_entity\"] == 16]\n",
    "\n",
    "    if (len(ents_lpa) == 0) | (len(ents_he) == 0):\n",
    "        print(\"\")\n",
    "        print(\"No entities for one of the organisations, not possible to display map\")\n",
    "        return None\n",
    "    \n",
    "    else:\n",
    "\n",
    "        m = ents_lpa.explore(\n",
    "            tiles = \"CartoDB positron\",\n",
    "            column = \"organisation_name\", \n",
    "            cmap = \"Accent\",\n",
    "            highlight = True,\n",
    "            tooltip = [\"organisation_name\", \"entity\", \"reference\", \"name\", \"has_overlap_issues\", \"n_overlap_issues\", \"overlap_issue_types\"],\n",
    "            style_kwds={\"fillOpacity\" : \"0.1\"},\n",
    "            name = \"LPA entities\")\n",
    "\n",
    "        ents_he.explore(\n",
    "            m = m,\n",
    "            column = \"organisation_name\", \n",
    "            cmap = [\"#bf5b16\"],\n",
    "            highlight = True,\n",
    "            tooltip = [\"organisation_name\", \"entity\", \"reference\", \"name\", \"has_overlap_issues\", \"n_overlap_issues\", \"overlap_issue_types\"],\n",
    "            style_kwds={\"fillOpacity\" : \"0.1\"},\n",
    "            name = \"Historic England entities\")\n",
    "\n",
    "        folium.LayerControl(show = True).add_to(m)  # use folium to add layer control\n",
    "\n",
    "        return m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get orgs and flag ODP\n",
    "provisions_df = get_provisions()\n",
    "\n",
    "org_df = get_all_organisations()\n",
    "org_df[\"odp_flag\"] = np.where(org_df[\"organisation\"].isin(provisions_df[\"organisation\"]), True, False)\n",
    "print(len(org_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CA from pdp\n",
    "ca_in = pd.read_csv(\"https://files.planning.data.gov.uk/dataset/conservation-area.csv\",\n",
    "                            usecols = [\"entity\", \"name\", \"organisation-entity\", \"reference\", \"entry-date\", \"point\", \"geometry\"])\n",
    "\n",
    "ca_in.columns = [x.replace(\"-\", \"_\") for x in ca_in.columns]\n",
    "\n",
    "ca_df = ca_in[ca_in[\"geometry\"].notnull()].copy()\n",
    "\n",
    "# join organisation name and LPA codes from lookup\n",
    "ca_df = ca_df.merge(\n",
    "    org_df[[\"organisation_entity\", \"organisation_name\"]], \n",
    "    how = \"left\",\n",
    "    on = \"organisation_entity\")\n",
    "\n",
    "# load to gdf, both point and poly versions\n",
    "ca_df[\"point\"] = ca_df[\"point\"].apply(shapely.wkt.loads)\n",
    "ca_point_gdf = gpd.GeoDataFrame(ca_df, geometry=\"point\")\n",
    "\n",
    "ca_df[\"geometry\"] = ca_df[\"geometry\"].apply(shapely.wkt.loads)\n",
    "ca_poly_gdf = gpd.GeoDataFrame(ca_df, geometry=\"geometry\")\n",
    "\n",
    "# Transform to ESPG:27700 for more interpretable area units\n",
    "ca_point_gdf.set_crs(epsg=4326, inplace=True)\n",
    "ca_point_gdf.to_crs(epsg=27700, inplace=True)\n",
    "\n",
    "ca_poly_gdf.set_crs(epsg=4326, inplace=True)\n",
    "ca_poly_gdf.to_crs(epsg=27700, inplace=True)\n",
    "\n",
    "print(len(ca_poly_gdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LPA boundaries from PDP site\n",
    "lpa_gdf = get_pdp_geo_dataset(\"local-planning-authority\")\n",
    "lpa_gdf.rename(columns={'name':'lpa_name', 'reference':'lpa_reference'}, inplace=True)\n",
    "lpa_gdf[\"ODP_flag\"] = np.where(lpa_gdf[\"lpa_reference\"].isin(org_df[org_df[\"odp_flag\"]][\"local_planning_authority\"]), True, False)\n",
    "print(len(lpa_gdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculations\n",
    "### Spatial joining - LPA boundaries to conservation area points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join LPAs to all conservation areas, then join on the names of supplying organisations for matching conservation areas\n",
    "lpa_ca_join = gpd.sjoin(\n",
    "    lpa_gdf[[\"lpa_reference\", \"lpa_name\", \"ODP_flag\", \"geometry\"]],\n",
    "    ca_point_gdf[[\"entity\", \"organisation_entity\", \"organisation_name\", \"point\"]],\n",
    "    how = \"left\",\n",
    "    predicate = \"intersects\"\n",
    ")\n",
    "\n",
    "print(len(lpa_ca_join))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geographical duplicate identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MATCH_LOWER_THRESH = 0.95  # defines the lower limit of the shared overlap between two entities to be called a match\n",
    "EDGE_UPPER_THRESH = 0.1   # defines the upper limit of the shared overlap between two entities to be called an edge intersection\n",
    "EDGE_LOWER_THRESH = 0.01   # defines the lower limit of the shared overlap between two entities to be called an edge intersection\n",
    "\n",
    "# calculate area\n",
    "ca_poly_gdf[\"area\"] = ca_poly_gdf[\"geometry\"].area\n",
    "\n",
    "# full join of all geometries\n",
    "entity_join_all = gpd.overlay(\n",
    "    ca_poly_gdf, \n",
    "    ca_poly_gdf,\n",
    "    how = \"intersection\", keep_geom_type=False \n",
    ")\n",
    "\n",
    "# remove self-intersections \n",
    "entity_join_all = entity_join_all[entity_join_all[\"entity_1\"] != entity_join_all[\"entity_2\"]]\n",
    "\n",
    "# flag the types of intersections between organisations\n",
    "# is org the same\n",
    "entity_join_all[\"int_org_match\"] = np.where(entity_join_all[\"organisation_entity_1\"] == entity_join_all[\"organisation_entity_2\"], True, False)\n",
    "\n",
    "# the types of org-org matches\n",
    "entity_join_all[\"int_org_types\"] = np.select(\n",
    "    [\n",
    "        (entity_join_all[\"organisation_entity_1\"] == 16) & (entity_join_all[\"organisation_entity_2\"] == 16),\n",
    "        (entity_join_all[\"organisation_entity_1\"] != 16) & (entity_join_all[\"organisation_entity_2\"] != 16),\n",
    "        ((entity_join_all[\"organisation_entity_1\"] != 16) & (entity_join_all[\"organisation_entity_2\"] == 16)) |\n",
    "        ((entity_join_all[\"organisation_entity_1\"] == 16) & (entity_join_all[\"organisation_entity_2\"] != 16))\n",
    "    ],\n",
    "    [\"HE - HE\", \"LPA - LPA\", \"HE - other\"],\n",
    "    default = \"-\"\n",
    ")\n",
    "\n",
    "# does the entity entry date match?\n",
    "entity_join_all[\"date_match\"] = np.where(entity_join_all[\"entry_date_1\"] == entity_join_all[\"entry_date_2\"], True, False)\n",
    "\n",
    "# calculate overlap %'s\n",
    "\n",
    "entity_join_all[\"area_intersection\"] = entity_join_all[\"geometry\"].area\n",
    "\n",
    "entity_join_all[\"p_pct_intersect\"] = entity_join_all[\"area_intersection\"] / entity_join_all[\"area_1\"]\n",
    "entity_join_all[\"pct_intersection\"] = entity_join_all[\"area_intersection\"] / (entity_join_all[\"area_1\"] + entity_join_all[\"area_2\"] - entity_join_all[\"area_intersection\"])\n",
    "entity_join_all[\"s_pct_intersect\"] = entity_join_all[\"area_intersection\"] / entity_join_all[\"area_2\"]\n",
    "\n",
    "# intersection area as % of smallest primary or secondary area\n",
    "entity_join_all[\"pct_min_intersection\"] = entity_join_all[\"area_intersection\"] / entity_join_all[[\"area_1\", \"area_2\"]].min(axis = 1)\n",
    "\n",
    "\n",
    "entity_join_all[\"intersection_type\"] = np.select(\n",
    "    [\n",
    "        (entity_join_all[\"p_pct_intersect\"] >= MATCH_LOWER_THRESH) & (entity_join_all[\"s_pct_intersect\"] >= MATCH_LOWER_THRESH),\n",
    "        (entity_join_all[\"pct_min_intersection\"] <= EDGE_UPPER_THRESH) & (entity_join_all[\"pct_min_intersection\"] >= EDGE_LOWER_THRESH),\n",
    "        (entity_join_all[\"pct_min_intersection\"] < EDGE_LOWER_THRESH),\n",
    "        ((entity_join_all[\"p_pct_intersect\"] >= MATCH_LOWER_THRESH) | (entity_join_all[\"s_pct_intersect\"] >= MATCH_LOWER_THRESH)),\n",
    "        \n",
    "    ],\n",
    "    [\n",
    "        \"Complete match (two-way)\", \"Edge overlap\", \"Tiny edge - ignore\", \"Single match (one-way)\"\n",
    "    ],\n",
    "    default = \"Partial match\"\n",
    ")\n",
    "\n",
    "print(len(entity_join_all))\n",
    "# entity_join_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUMMARISE OVERLAP ISSUES\n",
    "\n",
    "# filter to just HE - LPA overlaps, and exclude tiny edges\n",
    "ca_issues_he_lpa = entity_join_all[\n",
    "    (entity_join_all[\"int_org_types\"] == \"HE - other\") &\n",
    "    (entity_join_all[\"intersection_type\"] != \"Tiny edge - ignore\")\n",
    "]\n",
    "\n",
    "# group and count\n",
    "ca_issues_he_lpa_count = ca_issues_he_lpa.groupby(\n",
    "        [\"entity_1\"] # , \"name_1\", \"reference_1\", \"organisation_entity_1\", \"geometry\"\n",
    "    ).agg(\n",
    "        {\"entity_2\" : \"count\",\n",
    "         \"intersection_type\" : lambda x: ', '.join(set(x))}\n",
    "    ).reset_index(    \n",
    "    )\n",
    "\n",
    "# rename cols\n",
    "ca_issues_he_lpa_count.rename(columns=\n",
    "    {\"entity_1\":\"entity\", \n",
    "     \"entity_2\":\"n_overlap_issues\", \n",
    "     \"intersection_type\" : \"overlap_issue_types\"}, inplace = True)\n",
    "\n",
    "# ca_issues_he_lpa_count.sort_values(\"n_overlap_issues\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create subset table with only single instances of each issue\n",
    "overlap_issues_dist = ca_issues_he_lpa.copy()\n",
    "\n",
    "overlap_issues_dist[\"entity_join\"] = overlap_issues_dist.apply(lambda x: '-'.join(list(map(str, sorted(x[[\"entity_1\", \"entity_2\"]])))), axis=1)\n",
    "\n",
    "# extra sort to make sure matches to Historic England always show as Historic England as org 2 \n",
    "overlap_issues_dist[\"name_for_sort\"] = np.where(overlap_issues_dist[\"organisation_entity_1\"] == 16, \"Z\", \"A\")\n",
    "overlap_issues_dist.sort_values([\"entity_join\", \"name_for_sort\"], ascending=True, inplace=True)\n",
    "\n",
    "overlap_issues_dist.drop_duplicates(subset=\"entity_join\", inplace = True)  #Drop them by name\n",
    "\n",
    "# flag entities with multiple issues\n",
    "all_ents = pd.concat([overlap_issues_dist[\"entity_1\"], overlap_issues_dist[\"entity_2\"]], ignore_index = True)\n",
    "multi_issue_ents = all_ents.loc[all_ents.duplicated()]\n",
    "\n",
    "overlap_issues_dist[\"multi_issue_entities\"] = np.where(\n",
    "    (overlap_issues_dist[\"entity_2\"].isin(multi_issue_ents)) |\n",
    "    (overlap_issues_dist[\"entity_1\"].isin(multi_issue_ents)),\n",
    "    True, False)\n",
    "\n",
    "# add in action field\n",
    "overlap_issues_dist[\"action\"] = np.select(\n",
    "    [\n",
    "        (overlap_issues_dist[\"intersection_type\"] == \"Complete match (two-way)\") &\n",
    "        (overlap_issues_dist[\"multi_issue_entities\"] == False) \n",
    "\n",
    "    ],\n",
    "    [\"remap\"],\n",
    "    default = \"investigate\"\n",
    ")\n",
    "\n",
    "# write report to output dir\n",
    "print(len(overlap_issues_dist))\n",
    "# overlap_issues_dist.head()\n",
    "overlap_issues_dist.sort_values([\"organisation_name_1\", \"action\"]\n",
    "                                ).to_csv(os.path.join(output_dir, f\"conservation_area_duplicates_report_{td}.csv\"), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write redirections to output dir\n",
    "\n",
    "redirections = overlap_issues_dist[overlap_issues_dist[\"action\"] == \"remap\"]\n",
    "n_redirects = len(redirections)\n",
    "\n",
    "old_entity_update = pd.DataFrame({\n",
    "    \"old-entity\" : redirections[\"entity_2\"],\n",
    "    \"status\" : [\"301\"] * n_redirects,\n",
    "    \"entity\" : redirections[\"entity_1\"],\n",
    "    \"end-date\" : [\"\"] * n_redirects,\n",
    "    \"notes\" : [\"redirect Historic England duplicate to LPA entity\"] * n_redirects,\n",
    "    \"entry-date\" : [td] * n_redirects,\n",
    "    \"start-date\" : [\"\"] * n_redirects\n",
    "})\n",
    "\n",
    "old_entity_update.to_csv(os.path.join(output_dir, f\"redirections_old-entity-update_{td}.csv\"), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine (for mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join LPAs with intersecting CAs to CA geometry, and then to CA overlap issues\n",
    "\n",
    "print(len(lpa_ca_join))\n",
    "\n",
    "lpa_ca_all = lpa_ca_join[[\"lpa_reference\", \"lpa_name\", \"ODP_flag\", \"entity\", \"organisation_entity\", \"organisation_name\"]].merge(\n",
    "        ca_poly_gdf[[\"entity\", \"reference\", \"name\", \"geometry\"]],\n",
    "        how = \"left\",\n",
    "        on = \"entity\"\n",
    "    ).merge(\n",
    "        ca_issues_he_lpa_count,\n",
    "        how = \"left\",\n",
    "        on = \"entity\"\n",
    "    )\n",
    "\n",
    "lpa_ca_all[\"overlap_issue_types\"].replace(np.nan, \"No overlap issues\", inplace=True)\n",
    "lpa_ca_all[\"has_overlap_issues\"] = np.where(lpa_ca_all[\"n_overlap_issues\"].notnull(), True, False)\n",
    "lpa_ca_all = gpd.GeoDataFrame(lpa_ca_all, geometry=\"geometry\")\n",
    "\n",
    "print(len(lpa_ca_all))\n",
    "# lpa_ca_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ODP_overlap_issues_count = lpa_ca_all[\n",
    "    (lpa_ca_all[\"has_overlap_issues\"]) &\n",
    "    (lpa_ca_all[\"ODP_flag\"])].groupby(\"lpa_name\").size().reset_index(name = \"count\").sort_values(\"count\", ascending=False)\n",
    "\n",
    "nODP_overlap_issues_count = lpa_ca_all[\n",
    "    (lpa_ca_all[\"has_overlap_issues\"]) &\n",
    "    (~lpa_ca_all[\"ODP_flag\"])].groupby(\"lpa_name\").size().reset_index(name = \"count\").sort_values(\"count\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map\n",
    "### ODP LPA issues\n",
    "(see next section for non-ODP LPA issues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ODP LPAs by number of overlap issues\")\n",
    "ODP_overlap_issues_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ODP_dataset_options = dict(zip(ODP_overlap_issues_count[\"lpa_name\"], ODP_overlap_issues_count[\"lpa_name\"]))\n",
    "\n",
    "ODP_dataset_dropdown = widgets.Dropdown(\n",
    "    options=ODP_dataset_options,\n",
    "    description=\"Select LPA:\",\n",
    ")\n",
    "\n",
    "widgets.interact(display_lpa_issues, lpa_name=ODP_dataset_dropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### non-ODP LPA issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"non-ODP LPAs by number of overlap issues\")\n",
    "nODP_overlap_issues_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nODP_dataset_options = dict(zip(nODP_overlap_issues_count[\"lpa_name\"], nODP_overlap_issues_count[\"lpa_name\"]))\n",
    "\n",
    "nODP_dataset_dropdown = widgets.Dropdown(\n",
    "    options=nODP_dataset_options,\n",
    "    description=\"Select LPA:\",\n",
    ")\n",
    "\n",
    "widgets.interact(display_lpa_issues, lpa_name=nODP_dataset_dropdown)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdp_jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
