{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Provision data quality report\n",
    "**Author**:  Greg Slater <br>\n",
    "**Date Created**:  November 2024 <br>\n",
    "**Dataset Scope**: ODP datasets <br>\n",
    "**Report Type**: Ad-hoc <br>\n",
    "\n",
    "**Purpose**: The purpose of this report is to measure the quality of the data that makes up each data provision on the platform, by applying a data quality framework that sets out criteria that must be met in order to reach one of 4 different quality levels. These levels have been created for a proof-of-concept, and are based around our current best understanding of user needs for the data.\n",
    "\n",
    "\n",
    "Future improvements:\n",
    "* Error handling. Queries not working may break bits of the report. Not very high priority while report is more of a POC.\n",
    "* Base tables. Expand summaries to full ODP provision, including where no data at all. This could be done by switching the `qual_cat_summary` table to be constructed from a base of the provision table, rather than `qual_all` (which only includes provisions with quality issues).\n",
    "* Adding more quality checks. This depends on more checks going live in issues or expectations tables, but once they are should be easy to add extra criteria checks through the `qual_` table structure.\n",
    "* Include data from old endpoints. This will need re-working of the base table query (from `fi.get_endpoint_res_issues()`) to include old endpoints and resources. Though this will add complexity to work out which are the \"latest\" endpoints and resources to include, especially for provisions with multiple endpoints. May be low priority.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data quality framework  \n",
    "The table below visualises the framework that is used to assign a quality level to each data provision. \n",
    "\n",
    "The criteria marked as \"true\" at each level must be met by a data provision in order for it to be scored at that level. The levels are cumulative, so all criteria must be met in order for a provision to be scored as *data that is trustworthy*. Where we have data from alternative providers (e.g. Historic England conservation-area data) the first criteria cannot be met so it is scored as the first quality level, *some data*.\n",
    "\n",
    "![quality framework table](quality-framwork-table_all-datasets.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from datetime import datetime\n",
    "import folium\n",
    "import matplotlib\n",
    "\n",
    "try:\n",
    "  import mapclassify\n",
    "\n",
    "except:\n",
    "  print(\"installing mapclassify\")\n",
    "  !pip install mapclassify\n",
    "  import mapclassify\n",
    "\n",
    "td = datetime.today().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_util_file(file_name):\n",
    "\n",
    "    if os.path.isfile(file_name) == False:\n",
    "        url = f\"https://raw.githubusercontent.com/digital-land/jupyter-analysis/refs/heads/main/reports/measure_data_quality/{file_name}\"\n",
    "        !wget {url}\n",
    "        print(f\"downloaded {file_name} from github\")\n",
    "\n",
    "    else:\n",
    "        print(\"file available locally\")\n",
    "\n",
    "for f in [\"functions_core.py\", \"functions_import.py\", \"functions_transform.py\"]:\n",
    "    save_util_file(f)\n",
    "\n",
    "import functions_core as fc\n",
    "import functions_import as fi\n",
    "import functions_transform as ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_dir = \"../../data/db_downloads/\"\n",
    "os.makedirs(db_dir, exist_ok=True)\n",
    "\n",
    "output_dir = \"../../data/quality_report/\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance db\n",
    "fc.download_dataset(\"performance\", db_dir, overwrite=True)\n",
    "path_perf_db = os.path.join(db_dir, \"performance.db\")\n",
    "\n",
    "# Issue quality criteria lookup\n",
    "lookup_issue_qual = fi.get_issue_quality_lookup()\n",
    "\n",
    "# Provision lookups\n",
    "lookup_provision_odp = fi.get_odp_provision_lookup()\n",
    "lookup_provision_odp.rename(columns={\"dataset\" : \"pipeline\"}, inplace=True)\n",
    "\n",
    "\n",
    "# Dataset subset dict for chart\n",
    "dataset_subset_dict = dict({\n",
    "        \"BFL\" : [\"brownfield-land\"],\n",
    "        \"Developers\" : [\"developer-agreement\", \"developer-agreement-contribution\", \"developer-agreement-transaction\"]\n",
    "    })\n",
    "\n",
    "# Base table\n",
    "ep_res_issues = fi.get_endpoint_res_issues(path_perf_db)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ISSUES TABLE - flagging when provisions have data quality issues\n",
    "\n",
    "qual_issues = ft.make_issues_input_table(ep_res_issues, lookup_issue_qual)\n",
    "\n",
    "\n",
    "# # FRESHNESS TABLE - flagging when provisions haven't been updated in last year - not included in quality framework for now\n",
    "\n",
    "# create table of old resources and flag quality level as 5\n",
    "qual_fresh = ft.make_freshness_input_table(ep_res_issues, age_days = 365)\n",
    "\n",
    "\n",
    "# ALL QUALITY CATEGORIES TABLE - joining all records of quality categories (freshness & DQ issues) into one long table \n",
    "# concat tables for each type\n",
    "qual_all = pd.concat([qual_issues, qual_fresh])\n",
    "# qual_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_map = {\n",
    "    4: \"4. trustworthy\",\n",
    "    3: \"3. good\",\n",
    "    2: \"2. improve\",\n",
    "    1: \"1. update\"}\n",
    "\n",
    "\n",
    "qual_summary = ft.make_score_summary_table(qual_all, level_map)\n",
    "print(len(qual_summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Summarise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ODP LPA x Dataset quality table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_provider_summary_table(subset):\n",
    "    \"\"\"\n",
    "    Uses the qual summary table to display a horizontal bar chart \n",
    "    \"\"\"\n",
    "\n",
    "    qual_summary_subset = qual_summary[qual_summary[\"pipeline\"].isin(dataset_subset_dict[subset])]\n",
    "\n",
    "    qual_summary_wide = qual_summary_subset.pivot(\n",
    "        columns = \"pipeline\",\n",
    "        values = \"quality_level_label\",\n",
    "        index = [\"organisation\", \"organisation_name\"]\n",
    "    ).rename_axis(\n",
    "        None, axis = 1\n",
    "    ).reset_index(\n",
    "    ).sort_values(\n",
    "        [\"organisation_name\"]\n",
    "    )\n",
    "\n",
    "    qual_summary_wide.replace(np.nan, \"0. no data\", inplace=True)\n",
    "\n",
    "    return qual_summary_wide.style.apply(make_color_mask_odp_lpa, axis=None)\n",
    "\n",
    "# make_provider_summary_table(\"Developers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_background_colours = {\n",
    "    \"4. trustworthy\" : \"background-color: #1a6837\",\n",
    "    \"3. good\" : \"background-color: #87cb67\",\n",
    "    \"2. improve\" : \"background-color: #fefebf\",\n",
    "    \"1. update\" : \"background-color: #f78c51\"\n",
    "    }\n",
    "\n",
    "ready_flag_colours = {\n",
    "        \"yes\" : \"color:green\"\n",
    "    }\n",
    "\n",
    "def make_color_mask_odp_lpa(df):\n",
    "    #DataFrame with same index and columns names as original filled empty strings\n",
    "    df_color_map =  pd.DataFrame(\"\", index=df.index, columns=df.columns)\n",
    "\n",
    "    flag_slice = df.columns[2:]\n",
    "    for s in flag_slice:\n",
    "        df_color_map[s] = df[s].map(level_background_colours)\n",
    "\n",
    "    return df_color_map\n",
    "\n",
    "# make_color_mask_odp_lpa(odp_lpa_summary)\n",
    "# odp_lpa_summary_wide.style.apply(make_color_mask_odp_lpa, axis=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset x quality categories table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count issues by the quality category \n",
    "qual_cat_count = qual_all.groupby(\n",
    "        [\"pipeline\", \"organisation\", \"organisation_name\", \"quality_criteria\"],\n",
    "        as_index=False\n",
    "    ).agg(\n",
    "        n_issues = (\"quality_level\", \"count\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a base table with each quality category for each provision - this is so it can be pivoted correctly with all categories included\n",
    "prov = qual_all[[\"pipeline\", \"organisation\", \"organisation_name\"]].drop_duplicates()\n",
    "prov[\"key\"] = 1\n",
    "\n",
    "qual_cat = qual_all[qual_all[\"quality_criteria\"].notnull()][[\"quality_criteria\"]].drop_duplicates()\n",
    "qual_cat[\"key\"] = 1\n",
    "\n",
    "qual_cat_summary = prov.merge(\n",
    "    qual_cat,\n",
    "    how = \"left\",\n",
    "    on = \"key\"\n",
    ")\n",
    "print(len(qual_cat_summary))\n",
    "\n",
    "# left join on the counts to the base table\n",
    "qual_cat_summary = qual_cat_summary.merge(\n",
    "    qual_cat_count,\n",
    "    how = \"left\",\n",
    "    on = ['pipeline', 'organisation', 'organisation_name', 'quality_criteria']\n",
    ")\n",
    "\n",
    "# create boolean flag for each category\n",
    "qual_cat_summary[\"issue_flag\"] = np.where(qual_cat_summary[\"n_issues\"] > 0, False, True)\n",
    "print(len(qual_cat_summary))\n",
    "# qual_cat_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot quality category summary table so that quality categories are columns, join on overall quality level per provision\n",
    "qual_cat_summary_wide = qual_cat_summary.pivot(\n",
    "        columns = \"quality_criteria\",\n",
    "        values = \"issue_flag\",\n",
    "        index = [\"pipeline\", \"organisation\", \"organisation_name\"]\n",
    "    ).reset_index(\n",
    "    ).merge(\n",
    "        qual_summary[[\"pipeline\", \"organisation\", \"quality_level_label\"]],\n",
    "        how = \"left\",\n",
    "        on = [\"pipeline\", \"organisation\"]\n",
    "    )\n",
    "\n",
    "def get_dataset_qual_detail(dataset):\n",
    "    # just subsets and styles main wide quality detail table\n",
    "\n",
    "    qual_detail = qual_cat_summary_wide[qual_cat_summary_wide[\"pipeline\"] == dataset].copy()\n",
    "\n",
    "    return qual_detail.style.apply(make_color_mask_dataset_lpa, axis=None)\n",
    "\n",
    "\n",
    "flag_colours = {\n",
    "        True : \"color:green\",\n",
    "        False : \"color:red\"\n",
    "    }\n",
    "\n",
    "def make_color_mask_dataset_lpa(df):\n",
    "    #DataFrame with same index and columns names as original filled empty strings\n",
    "    df_color_map =  pd.DataFrame(\"\", index=df.index, columns=df.columns)\n",
    "    # turn label column into colours\n",
    "    df_color_map[\"quality_level_label\"] = df[\"quality_level_label\"].map(level_background_colours)\n",
    "\n",
    "    flag_slice = df.columns[3:-1]\n",
    "    for s in flag_slice:\n",
    "        df_color_map[s] = df[s].map(flag_colours)\n",
    "\n",
    "    return df_color_map\n",
    "\n",
    "\n",
    "# make widget\n",
    "\n",
    "dataset_dropdown = widgets.Dropdown(\n",
    "    options = qual_summary[\"pipeline\"].drop_duplicates().values,\n",
    "    # value = \"article-4-direction\",\n",
    "    description = \"Select Dataset: \",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALISE\n",
    "\n",
    "# color map to use in chart\n",
    "cmap = plt.get_cmap('RdYlGn')\n",
    "colors = [cmap(i / 4) for i in np.arange(1, 5)]\n",
    "\n",
    "def make_quality_overview_chart(subset):\n",
    "    \"\"\"\n",
    "    Uses the qual summary table to display a horizontal bar chart \n",
    "    \"\"\"\n",
    "\n",
    "    qual_summary_subset = qual_summary[qual_summary[\"pipeline\"].isin(dataset_subset_dict[subset])]\n",
    "\n",
    "    # count providers by dataset & quality level\n",
    "    qual_chart = qual_summary_subset.groupby([\"pipeline\", \"quality_level\", \"quality_level_label\"], as_index=False).agg(\n",
    "        n_providers = (\"quality_level\", \"count\")\n",
    "    )\n",
    "\n",
    "    qual_chart.sort_values([\"pipeline\", \"quality_level_label\"], inplace=True)\n",
    "    qual_chart_wide = qual_chart.pivot(columns = \"quality_level_label\", values = \"n_providers\", index = \"pipeline\")\n",
    "    \n",
    "    qual_chart_wide.plot.barh(\n",
    "        stacked = True, \n",
    "        color = colors, \n",
    "        figsize = (9, 6))\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('Count of providers')\n",
    "    plt.ylabel('Dataset')\n",
    "    plt.title('Quality levels for ODP datasets')\n",
    "    plt.legend(title='Quality level')\n",
    "\n",
    "    return plt.show()\n",
    "\n",
    "\n",
    "subset_dropdown = widgets.Dropdown(\n",
    "    options = dataset_subset_dict.keys(),\n",
    "    # value = dataset_list[0],\n",
    "    description = \"Select Dataset subset: \",\n",
    ")\n",
    "\n",
    "# widgets.interact(make_quality_overview_chart, subset = subset_dropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Present"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data quality overview chart - by dataset groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widgets.interact(make_quality_overview_chart, subset = subset_dropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ODP LPA overview table by dataset & quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widgets.interact(make_provider_summary_table, subset = subset_dropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset quality scoring detail table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widgets.interact(get_dataset_qual_detail, dataset = dataset_dropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output\n",
    "Save report files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_bfl = os.path.join(output_dir, f\"quality-dataset-scores-by-provider_BFL_{td}.xlsx\")\n",
    "fn_dev = os.path.join(output_dir, f\"quality-dataset-scores-by-provider_Developers_{td}.xlsx\")\n",
    "\n",
    "make_provider_summary_table(\"BFL\").to_excel(fn_bfl, index = False)\n",
    "make_provider_summary_table(\"Developers\").to_excel(fn_dev, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = os.path.join(output_dir, f\"quality_dataset-quality-detail_{td}.csv\")\n",
    "qual_cat_summary_wide.to_csv(fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdp_jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
