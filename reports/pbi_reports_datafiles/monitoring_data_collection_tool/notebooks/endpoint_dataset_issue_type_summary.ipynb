{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db4ec752",
   "metadata": {},
   "source": [
    "This script automates the process of exporting full tables from a Datasette instance by downloading them in CSV format using the `_stream=on` feature, which bypasses default row limits and retrieves the entire dataset. It is particularly useful for obtaining complete datasets from the [planning.data.gov.uk](https://datasette.planning.data.gov.uk/) performance database.\n",
    "\n",
    "### Detailed Overview:\n",
    "\n",
    "1. **Command-Line Interface**:\n",
    "   The script uses `argparse` to accept a required `--output-dir` argument, specifying where the CSV files will be saved.\n",
    "\n",
    "2. **Datasette Table Downloads**:\n",
    "   A dictionary of table names and corresponding Datasette URLs is defined in the script (`tables`). For each entry:\n",
    "   - The full CSV URL is constructed by appending `.csv?_stream=on` to the base URL.\n",
    "   - The script attempts to load the data using `pandas.read_csv()` and saves it to the specified directory under the given table name.\n",
    "\n",
    "3. **Error Handling**:\n",
    "   If any request or file operation fails (e.g. network issues, bad URLs), an error message is printed, allowing the user to identify which tables couldn't be downloaded.\n",
    "\n",
    "4. **Use Case**:\n",
    "   This is useful when exporting tables that are too large to download via the web UI or API defaults (which often cap rows at 1000), ensuring full data extraction for offline analysis or archiving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6723cca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:/Users/DanielGodden/Documents/MCHLG/collecting_and_managing_data\\endpoint_dataset_issue_type_summary.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "def full_datasette_table(tables, output_dir):\n",
    "    \"\"\"\n",
    "    Downloads full tables from Datasette in CSV format using streaming.\n",
    "\n",
    "    Args:\n",
    "        tables (dict): A dictionary where keys are table names and values are their Datasette URLs.\n",
    "        output_dir (str): The directory to save the exported CSV files.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)  # Ensure output directory exists\n",
    "\n",
    "    for name, url in tables.items():\n",
    "        full_url = f\"{url}.csv?_stream=on\"  # Enable full streaming of rows\n",
    "        try:\n",
    "            df = pd.read_csv(full_url)  # Load full dataset\n",
    "            csv_name = f\"{name}.csv\"\n",
    "            save_path = os.path.join(output_dir, csv_name)\n",
    "            df.to_csv(save_path, index=False)  # Save to CSV without index\n",
    "            print(f\"Saved: {save_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Failed to fetch {name}: {e}\")\n",
    "\n",
    "def parse_args():\n",
    "    \"\"\"\n",
    "    Parses command-line arguments for specifying the output directory.\n",
    "\n",
    "    Returns:\n",
    "        argparse.Namespace: Parsed arguments containing the output directory path.\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(description=\"Datasette batch exporter\")\n",
    "    parser.add_argument(\n",
    "        \"--output-dir\",\n",
    "        type=str,\n",
    "        required=True,\n",
    "        help=\"Directory to save exported CSVs\"\n",
    "    )\n",
    "    return parser.parse_args()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Parse command-line arguments\n",
    "    #args = parse_args()\n",
    "\n",
    "    # Dictionary of table names and their Datasette URLs\n",
    "    tables = {\n",
    "        \"endpoint_dataset_issue_type_summary\":\n",
    "            \"https://datasette.planning.data.gov.uk/performance/endpoint_dataset_issue_type_summary\"\n",
    "    }\n",
    "\n",
    "    # Run export\n",
    "    output_dir = \"C:/Users/DanielGodden/Documents/MCHLG/collecting_and_managing_data\"\n",
    "    full_datasette_table(tables, output_dir)#args.output_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
