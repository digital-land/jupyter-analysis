{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74a42c70-3f28-4d36-94a4-4c5ac5dfc8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbdc1a35-a677-4c5c-bccc-f1b404207645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m No results found for  listed-building-outline\n",
      "\u001b[1m No results found for  tree\n",
      "\u001b[1m No results found for  tree-preservation-order\n",
      "\u001b[1m No results found for  tree-preservation-zone\n"
     ]
    }
   ],
   "source": [
    "collection_input=['article-4-direction', 'article-4-direction-area', 'brownfield-land', 'conservation-area',  'listed-building-outline', 'tree', 'tree-preservation-order', 'tree-preservation-zone']\n",
    "organisation_input=''\n",
    "severity_input=[] # list of issue severities you want to get e.g [\"error\", \"warning\", \"info\", \"notice\"]\n",
    "line_number_input=''\n",
    "\n",
    "datasette_url = \"https://datasette.planning.data.gov.uk/\"\n",
    "\n",
    "current_date = dt.now().date()\n",
    "\n",
    "date_query = f\" where SUBSTRING(s.entry_date, 1, 4) = '2023'\"\n",
    "\n",
    "\n",
    "collection_dfs=[]\n",
    "output_collection_names=[]\n",
    "for collection in collection_input:\n",
    "    query = \"\"\n",
    "    if collection_input:\n",
    "        query = f\" and s.collection = '{collection}'\"\n",
    "\n",
    "    if organisation_input:\n",
    "        query = query + f\" and s.organisation = '{organisation_input}'\"\n",
    "\n",
    "    params = urllib.parse.urlencode({\n",
    "        \"sql\": f\"\"\"\n",
    "        select re.resource, re.endpoint, s.organisation, s.entry_date, e.endpoint_url, l.status\n",
    "        from resource_endpoint re\n",
    "        inner join endpoint e\n",
    "        on re.endpoint = e.endpoint\n",
    "        inner join source s\n",
    "        on e.endpoint = s.endpoint\n",
    "        inner join log l\n",
    "        on s.endpoint = l.endpoint\n",
    "        {date_query}\n",
    "        {query}\n",
    "\n",
    "        \"\"\",\n",
    "        \"_size\": \"max\"\n",
    "    })\n",
    "\n",
    "    url = f\"{datasette_url}digital-land.csv?{params}\"\n",
    "    df = pd.read_csv(url)\n",
    "    df=df.drop_duplicates().reset_index(drop=True)\n",
    "    if (df.empty):\n",
    "        print(\"\\033[1m No results found for \", collection)\n",
    "    else:\n",
    "        collection_dfs.append(df)\n",
    "        output_collection_names.append(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "781f4b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = urllib.parse.urlencode({\n",
    "    \"sql\": f\"\"\"\n",
    "    select description, issue_type, severity\n",
    "    from issue_type\n",
    "    \"\"\",\n",
    "    \"_size\": \"max\"\n",
    "})\n",
    "\n",
    "url = f\"{datasette_url}digital-land.csv?{params}\"\n",
    "issue_type = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23f26e54-a995-455c-9d2c-8e902fd9117c",
   "metadata": {},
   "outputs": [],
   "source": [
    "issues_dfs=[]\n",
    "for idx, collection_df in enumerate(collection_dfs):\n",
    "    query=\"\"\n",
    "    if line_number_input:\n",
    "        query = f\" and line_number = '{line_number_input}'\"\n",
    "\n",
    "    resources = collection_df['resource'].tolist()\n",
    "    issues = []\n",
    "    for resource in resources:\n",
    "        params = urllib.parse.urlencode({\n",
    "        \"sql\": f\"\"\"\n",
    "        select field,issue_type,dataset,resource,value, line_number\n",
    "        from issue\n",
    "        where resource = '{resource}'\n",
    "        {query}\n",
    "        \"\"\",\n",
    "        \"_size\": \"max\"\n",
    "        })\n",
    "        url = f\"{datasette_url}{collection_input[idx]}.csv?{params}\"\n",
    "        df1 = pd.read_csv(url)\n",
    "        issues.append(df1)\n",
    "    df1 = pd.concat(issues, ignore_index=True)\n",
    "    issues_with_type = df1.merge(issue_type, left_on='issue_type', right_on='issue_type')\n",
    "    issues_dfs.append(issues_with_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cace5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dfs=[]\n",
    "for idx, collection_df in enumerate(collection_dfs):\n",
    "    collection_issues_df = collection_df.merge(issues_dfs[idx], left_on='resource', right_on='resource')\n",
    "    collection_issues_df = collection_issues_df.reindex(columns=['resource', 'organisation', 'dataset', 'entry_date', 'field', 'line_number', 'issue_type', 'value', 'severity', 'description', 'endpoint', 'status', 'endpoint_url']).reset_index(drop=True)\n",
    "    if (severity_input):\n",
    "        collection_issues_df = collection_issues_df.loc[collection_issues_df['severity'].isin(severity_input)]\n",
    "    output_dfs.append(collection_issues_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87741790-b5ae-4037-9e5b-a53e63fc5bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46917e109e3941d090130694647b143b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(RadioButtons(description='Select dataset to display:', options=('article-4-direction', 'articleâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d061d7c8b9224d74b2c46ae3d598866c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "def filter_column_by_value(df, column, value):\n",
    "    return df.loc[df[column].isin(value)]\n",
    "\n",
    "def compute_output_df(dataset, error, warning, info, notice, search):\n",
    "    index = output_collection_names.index(dataset)\n",
    "    selected_data = []\n",
    "    output_df = output_dfs[index]\n",
    "    if error or warning or info or notice:\n",
    "        selected_data = []\n",
    "        for i in range(0, len(severity_checkboxes)):\n",
    "            if severity_checkboxes[i].value == True:\n",
    "                selected_data = selected_data + [severity_checkboxes[i].description]\n",
    "        output_df = filter_column_by_value(output_dfs[index], 'severity', selected_data)\n",
    "    if search:\n",
    "        mask = np.column_stack([output_df[col].astype('str').str.contains(search, na=False) for col in output_df])\n",
    "        output_df = output_df.loc[mask.any(axis=1)]\n",
    "    return output_df\n",
    "\n",
    "def display_output_df(dataset, error, warning, info, notice, search):\n",
    "    output_df = compute_output_df(dataset, error, warning, info, notice, search)\n",
    "    display(output_df.head(1000))\n",
    "\n",
    "def download_df(dataset, error, warning, info, notice, search):\n",
    "    output_df = compute_output_df(dataset, error, warning, info, notice, search)\n",
    "    output_df.to_csv(dataset + \"-issues.csv\")\n",
    "\n",
    "severity_options = [\"error\", \"warning\", \"info\", \"notice\"]\n",
    "severity_checkboxes = [widgets.Checkbox(value=False, description=severity) for severity in severity_options]\n",
    "\n",
    "collection_selector = widgets.RadioButtons(\n",
    "    options=output_collection_names,\n",
    "    description='Select dataset to display:',\n",
    "    disabled=False\n",
    ")\n",
    "download_button = widgets.Button(\n",
    "    description = \"Download output table\",\n",
    "    layout=widgets.Layout(width='200px'),\n",
    ")\n",
    "download_button.on_click(lambda b: download_df(collection_selector.value, severity_checkboxes[0].value, severity_checkboxes[1].value, severity_checkboxes[2].value, severity_checkboxes[3].value, search_box.value))\n",
    "search_box = widgets.Text(placeholder=\"Search table\", layout=widgets.Layout(width='200px'))\n",
    "\n",
    "severity_filter = widgets.VBox(severity_checkboxes, layout = widgets.Layout(flex_flow='row wrap'))\n",
    "ui = widgets.VBox([collection_selector, search_box, download_button, severity_filter])\n",
    "out = widgets.interactive_output(display_output_df, {'dataset': collection_selector, \"error\": severity_checkboxes[0], \"warning\": severity_checkboxes[1], \"info\": severity_checkboxes[2], \"notice\": severity_checkboxes[3], \"search\": search_box})\n",
    "display(ui, out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
