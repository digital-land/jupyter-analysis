{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a42c70-3f28-4d36-94a4-4c5ac5dfc8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "from IPython.display import display, HTML\n",
    "import ipywidgets as widgets\n",
    "import urllib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdc1a35-a677-4c5c-bccc-f1b404207645",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_input=['conservation-area', 'article-4-direction-area', 'article-4-direction', 'listed-building-outline', 'tree', 'tree-preservation-order', 'tree-preservation-zone']\n",
    "organisation_input=''\n",
    "severity_input=[] # list of severities e.g [\"error\", \"warning\", \"info\", \"notice\"]\n",
    "line_number_input=''\n",
    "\n",
    "datasette_url = \"https://datasette.planning.data.gov.uk/\"\n",
    "\n",
    "current_date = dt.now().date()\n",
    "\n",
    "date_query = f\" where SUBSTRING(s.entry_date, 1, 4) = '2023'\"\n",
    "\n",
    "\n",
    "collection_dfs=[]\n",
    "output_collection_names=[]\n",
    "for collection in collection_input:\n",
    "    query = \"\"\n",
    "    if collection_input:\n",
    "        query = f\" and s.collection = '{collection}'\"\n",
    "\n",
    "    if organisation_input:\n",
    "        query = query + f\" and s.organisation = '{organisation_input}'\"\n",
    "\n",
    "    params = urllib.parse.urlencode({\n",
    "        \"sql\": f\"\"\"\n",
    "        select re.resource, re.endpoint, s.organisation, s.entry_date, e.endpoint_url\n",
    "        from resource_endpoint re\n",
    "        inner join endpoint e\n",
    "        on re.endpoint = e.endpoint\n",
    "        inner join source s\n",
    "        on e.endpoint = s.endpoint\n",
    "        {date_query}\n",
    "        {query}\n",
    "\n",
    "        \"\"\",\n",
    "        \"_size\": \"max\"\n",
    "    })\n",
    "\n",
    "    url = f\"{datasette_url}digital-land.csv?{params}\"\n",
    "    df = pd.read_csv(url)\n",
    "    if (df.empty):\n",
    "        print(print(\"\\033[1m No results found for \", collection))\n",
    "    else:\n",
    "        collection_dfs.append(df)\n",
    "        output_collection_names.append(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781f4b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = urllib.parse.urlencode({\n",
    "    \"sql\": f\"\"\"\n",
    "    select description, issue_type, severity\n",
    "    from issue_type\n",
    "    \"\"\",\n",
    "    \"_size\": \"max\"\n",
    "})\n",
    "\n",
    "url = f\"{datasette_url}digital-land.csv?{params}\"\n",
    "issue_type = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f26e54-a995-455c-9d2c-8e902fd9117c",
   "metadata": {},
   "outputs": [],
   "source": [
    "issues_dfs=[]\n",
    "for idx, collection_df in enumerate(collection_dfs):\n",
    "    query=\"\"\n",
    "    if line_number_input:\n",
    "        query = f\" and line_number = '{line_number_input}'\"\n",
    "\n",
    "    resources = collection_df['resource'].tolist()\n",
    "    issues = []\n",
    "    for resource in resources:\n",
    "        params = urllib.parse.urlencode({\n",
    "        \"sql\": f\"\"\"\n",
    "        select field,issue_type,dataset,resource,value, line_number\n",
    "        from issue\n",
    "        where resource = '{resource}'\n",
    "        {query}\n",
    "        \"\"\",\n",
    "        \"_size\": \"max\"\n",
    "        })\n",
    "        url = f\"{datasette_url}{collection_input[idx]}.csv?{params}\"\n",
    "        df1 = pd.read_csv(url)\n",
    "        issues.append(df1)\n",
    "    df1 = pd.concat(issues, ignore_index=True)\n",
    "    issues_with_type = df1.merge(issue_type, left_on='issue_type', right_on='issue_type')\n",
    "    issues_dfs.append(issues_with_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cace5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dfs=[]\n",
    "for idx, collection_df in enumerate(collection_dfs):\n",
    "    collection_issues_df = collection_df.merge(issues_dfs[idx], left_on='resource', right_on='resource')\n",
    "    collection_issues_df = collection_issues_df.reindex(columns=['organisation', 'dataset', 'endpoint_url', 'entry_date', 'field', 'line_number', 'issue_type', 'value', 'severity', 'description']).set_index('organisation')\n",
    "    if (severity_input):\n",
    "        collection_issues_df = collection_issues_df.loc[collection_issues_df['severity'].isin(severity_input)]\n",
    "    output_dfs.append(collection_issues_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87741790-b5ae-4037-9e5b-a53e63fc5bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(dataset):\n",
    "    index = output_collection_names.index(dataset)\n",
    "    display(HTML(output_dfs[index].to_html()))\n",
    "\n",
    "selector = widgets.RadioButtons(\n",
    "    options=output_collection_names,\n",
    "    description='Select dataset to display',\n",
    "    disabled=False\n",
    ")\n",
    "ui = widgets.VBox([selector])\n",
    "out = widgets.interactive_output(f, {'dataset': selector})\n",
    "display(ui, out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
