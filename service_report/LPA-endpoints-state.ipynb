{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "from IPython.display import display\n",
    "import urllib\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "import requests\n",
    "import urllib.parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Endpoints Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4d63a2d30aa40389c7934b8ae387e32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Select LPA:', options={\"All LPA's\": None, 'Newcastle': 'local-auth…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasette_url = \"https://datasette.planning.data.gov.uk/\"\n",
    "\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "def update_dataframe(organisation):\n",
    "    global result_df  \n",
    "    if organisation:\n",
    "        query = f\" s.organisation = '{organisation}'\"\n",
    "    else:\n",
    "        query = f\" s.organisation LIKE '%'\"\n",
    "    params = urllib.parse.urlencode({\n",
    "        \"sql\": f\"\"\"\n",
    "        select\n",
    "          e.endpoint_url,\n",
    "          l.status,\n",
    "          l.exception,\n",
    "          s.collection,\n",
    "          group_concat(DISTINCT sp.pipeline) as pipelines,\n",
    "          s.organisation,\n",
    "          o.name,\n",
    "          max(l.entry_date) maxentrydate,\n",
    "          max(e.entry_date) entrydate,\n",
    "          e.end_date\n",
    "        from\n",
    "          log l\n",
    "          inner join source s on l.endpoint = s.endpoint\n",
    "          inner join organisation o on s.organisation=o.organisation\n",
    "          inner join endpoint e on l.endpoint = e.endpoint\n",
    "          inner join source_pipeline sp on s.source = sp.source\n",
    "        where\n",
    "           {query} and not collection=\"brownfield-land\"\n",
    "        group by\n",
    "          l.endpoint,\n",
    "          l.status\n",
    "        order by\n",
    "          l.endpoint,\n",
    "          s.collection,\n",
    "          maxentrydate desc\n",
    "        \"\"\",\n",
    "        \"_size\": \"max\"\n",
    "    })\n",
    "    \n",
    "    url = f\"{datasette_url}digital-land.csv?{params}\"\n",
    "    df = pd.read_csv(url)\n",
    "    result_df = df\n",
    "    return df\n",
    "\n",
    "global organisation_options    \n",
    "organisation_options = {\n",
    "    \"All LPA's\":None,\"Newcastle\": \"local-authority-eng:NET\",\"Medway\": \"local-authority-eng:MDW\",\"Lambeth\": \"local-authority-eng:LBH\",\n",
    "    \"Gloucester\": \"local-authority-eng:GLO\",\"Doncaster\": \"local-authority-eng:DNC\",\"Buckinghamshire\": \"local-authority-eng:BUC\",\"Epsom and Ewell\": \"local-authority-eng:EPS\",\n",
    "    \"Canterbury\": \"local-authority-eng:CAT\",\"Bolton\": \"local-authority-eng:BOL\", \"London Borough of Southwark\": \"local-authority-eng:SWK\"\n",
    "    \n",
    "}\n",
    "global organisation_dropdown\n",
    "organisation_dropdown = widgets.Dropdown(\n",
    "    options=organisation_options,\n",
    "    description=\"Select LPA:\",\n",
    ")\n",
    "\n",
    "widgets.interact(update_dataframe, organisation=organisation_dropdown)\n",
    "initial_organisation = organisation_dropdown.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to download the table with all endpoints? (yes/no):  no\n"
     ]
    }
   ],
   "source": [
    "download = input(\"Do you want to download the table with all endpoints? (yes/no): \")\n",
    "\n",
    "if download.lower() == \"yes\":\n",
    "    result_df.to_csv(\"endpoints_with_all_status.csv\", index=False)\n",
    "    print(\"Query result downloaded as 'endpoints_with_all_status.csv'\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Endpoints with current/latest status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "534eb7487b51429683c913ab99ecf638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Select LPA:', options={\"All LPA's\": None, 'Newcastle': 'local-auth…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_df = pd.DataFrame()\n",
    "\n",
    "def update_dataframe_latest_status(organisation):\n",
    "    global new_df\n",
    "    all_endpoints=update_dataframe(organisation)\n",
    "    new_df=all_endpoints.copy()\n",
    "    new_df['maxentrydate'] = pd.to_datetime(new_df['maxentrydate'])\n",
    "    new_df['last_status'] = None\n",
    "    new_df['last_updated_date'] = None\n",
    "    new_df['date_last_status_200'] = None\n",
    "    \n",
    "    for index, row in new_df.iterrows():\n",
    "        if index < len(new_df) - 1 and (row['status']!=200 or pd.isna(row['status'])):\n",
    "            if row['endpoint_url'] == new_df.at[index + 1, 'endpoint_url']:\n",
    "                new_df.at[index, 'last_status'] = new_df.at[index + 1, 'status']\n",
    "                new_df.at[index, 'last_updated_date'] = new_df.at[index + 1, 'maxentrydate']   \n",
    "    \n",
    "    new_df.drop_duplicates(subset='endpoint_url', keep='first', inplace=True)\n",
    "    new_df.reset_index(drop=True, inplace=True)\n",
    "    for index, row in new_df.iterrows():\n",
    "        if row['last_status'] is not None:\n",
    "            if row['last_status'] != 200  or row['last_status'] is None:\n",
    "                filtered_df = all_endpoints[(all_endpoints['endpoint_url'] == row['endpoint_url'] ) & (all_endpoints['status'] == 200)]\n",
    "                if not filtered_df.empty:\n",
    "                    new_df.at[index, 'date_last_status_200'] = filtered_df['maxentrydate'].values[0][:19] \n",
    "    return new_df\n",
    "\n",
    "widgets.interact(update_dataframe_latest_status, organisation=organisation_dropdown)\n",
    "initial_organisation = organisation_dropdown.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to download the table with latest endpoints? (yes/no):  no\n"
     ]
    }
   ],
   "source": [
    "download = input(\"Do you want to download the table with latest endpoints? (yes/no): \")\n",
    "\n",
    "if download.lower() == \"yes\":\n",
    "    new_df.to_csv(\"endpoints_with_latest_status.csv\", index=False)\n",
    "    print(\"Query result downloaded as 'endpoints_with_latest_status.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Endpoints with status NOT 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a837c8f2f2bf49a08b42acf564cff293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Select LPA:', options={\"All LPA's\": None, 'Newcastle': 'local-auth…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filtered_df = pd.DataFrame()\n",
    "\n",
    "def update_dataframe_erroring_endpoints(organisation):\n",
    "    global filtered_df\n",
    "    filtered_df=update_dataframe_latest_status(organisation)\n",
    "    filtered_df = filtered_df[filtered_df['status'] != 200] \n",
    "    filtered_df.reset_index(drop=True, inplace=True)\n",
    "    return filtered_df\n",
    "\n",
    "widgets.interact(update_dataframe_erroring_endpoints, organisation=organisation_dropdown)\n",
    "initial_organisation = organisation_dropdown.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to download the table with erroring endpoints being collected till date? (yes/no):  no\n"
     ]
    }
   ],
   "source": [
    "download = input(\"Do you want to download the table with erroring endpoints being collected till date? (yes/no): \")\n",
    "\n",
    "if download.lower() == \"yes\":\n",
    "    filtered_df.to_csv(\"endpoints_not_200.csv\", index=False)\n",
    "    print(\"Query result downloaded as 'endpoints_not_200.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First 4 datasets - Endpoints with status NOT 200 - All LPA's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58627ebe52f248ec992da0a68d82b064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Select dataset:', options={'All 4 datasets': None, 'article 4 dire…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasette_url = \"https://datasette.planning.data.gov.uk/\"\n",
    "\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "def update_dataframe1(collection):\n",
    "    global df1  \n",
    "    if collection:\n",
    "        query = f\" s.collection = '{collection}'\"\n",
    "    else:\n",
    "        query = f\" s.collection IN ('article-4-direction', 'listed-building', 'tree-preservation-order', 'conservation-area','article-4-direction-area','article-4-direction-rule','listed-building-grade','listed-building-outline','listed-building-building','tree','tree-preservation-zone','tree-preservation-zone-type')\"\n",
    "    params = urllib.parse.urlencode({\n",
    "        \"sql\": f\"\"\"\n",
    "        select\n",
    "          e.endpoint_url,\n",
    "          l.status,\n",
    "          l.exception,\n",
    "          s.collection,\n",
    "          group_concat(DISTINCT sp.pipeline) as pipelines,\n",
    "          s.organisation,\n",
    "          o.name,\n",
    "          max(l.entry_date) maxentrydate,\n",
    "          max(e.entry_date) entrydate,\n",
    "          e.end_date\n",
    "        from\n",
    "          log l\n",
    "          inner join source s on l.endpoint = s.endpoint\n",
    "          inner join organisation o on s.organisation=o.organisation\n",
    "          inner join endpoint e on l.endpoint = e.endpoint\n",
    "          inner join source_pipeline sp on s.source = sp.source\n",
    "        where\n",
    "           {query} \n",
    "        group by\n",
    "          l.endpoint,\n",
    "          l.status\n",
    "        order by\n",
    "          pipelines,\n",
    "          o.name,\n",
    "          maxentrydate desc\n",
    "        \"\"\",\n",
    "        \"_size\": \"max\"\n",
    "    })\n",
    "    \n",
    "    url = f\"{datasette_url}digital-land.csv?{params}\"\n",
    "    df1 = pd.read_csv(url)\n",
    "    result_df1 = df1.copy()\n",
    "\n",
    "    df1['maxentrydate'] = pd.to_datetime(df1['maxentrydate'])\n",
    "    df1['last_status'] = None\n",
    "    df1['last_updated_date'] = None\n",
    "    df1['date_last_status_200'] = None\n",
    "    \n",
    "    for index, row in df1.iterrows():\n",
    "        if index < len(df1) - 1 and (row['status']!=200 or pd.isna(row['status'])):\n",
    "            if row['endpoint_url'] == df1.at[index + 1, 'endpoint_url']:\n",
    "                df1.at[index, 'last_status'] = df1.at[index + 1, 'status']\n",
    "                df1.at[index, 'last_updated_date'] = df1.at[index + 1, 'maxentrydate']   \n",
    "    \n",
    "    df1.drop_duplicates(subset='endpoint_url', keep='first', inplace=True)\n",
    "    df1.reset_index(drop=True, inplace=True)\n",
    "    for index, row in df1.iterrows():\n",
    "        if row['last_status'] is not None:\n",
    "                if row['last_status'] != 200  or row['last_status'] is None:\n",
    "                    filtered_df = result_df1[(result_df1['endpoint_url'] == row['endpoint_url'] ) & (result_df1['status'] == 200)]\n",
    "                    if not filtered_df.empty:\n",
    "                        df1.at[index, 'date_last_status_200'] = filtered_df['maxentrydate'].values[0][:19]\n",
    "    df1 = df1[df1['status'] != 200]\n",
    "    df1.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return df1\n",
    "\n",
    "\n",
    "global collection_options    \n",
    "collection_options = {\n",
    "    \"All 4 datasets\":None,\"article 4 direction\": \"article-4-direction\",\"conservation area\": \"conservation-area\",\"listed building\": \"listed-building\",\n",
    "    \"tree preservation order\": \"tree-preservation-order\"\n",
    "    \n",
    "}\n",
    "global organisation_dropdown\n",
    "collection_dropdown = widgets.Dropdown(\n",
    "    options=collection_options,\n",
    "    description=\"Select dataset:\",\n",
    ")\n",
    "\n",
    "widgets.interact(update_dataframe1, collection=collection_dropdown)\n",
    "initial_organisation = organisation_dropdown.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to download the table with erroring endpoints being collected till date? (yes/no):  no\n"
     ]
    }
   ],
   "source": [
    "download = input(\"Do you want to download the table with erroring endpoints being collected till date? (yes/no): \")\n",
    "\n",
    "if download.lower() == \"yes\":\n",
    "    df1.to_csv(\"endpoints_not_200_first_4_datasets.csv\", index=False)\n",
    "    print(\"Query result downloaded as 'endpoints_not_200_first_4_datasets.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting the Number of Distinct Non-ended Endpoints\n",
    "\n",
    "This SQL query will **count** the total number of **distinct** and **active** endpoint urls for each collection dataset, for each organisation, and will only return rows with counts greater than 1. Datasets with more than one endpoint url can then be further investigated, so see whether these additional endpoint urls are disfunctional or no longer needed.\n",
    "\n",
    "**N.B:**\n",
    "- Whether the endpoint_url is active it determined by the presence of an end_date value.\n",
    "- Currently the LPA list isn't exhaustive and may need to be added to (defined above) but \"all LPAs\" can be selected.\n",
    "- The BFL dataset is not included in this query because of how large the BFL dataset is.\n",
    "- The number of non-ended endpoints where `status != 200` can also be counted here but it pushes the datasette query limit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a5783bf08f64e609301736b4301ff75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Select LPA:', options={\"All LPA's\": None, 'Newcastle': 'local-auth…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_endpoint_aggregate(organisation):\n",
    "    global endpoint_aggregate  \n",
    "    if organisation:\n",
    "        query = f\" s.organisation = '{organisation}'\"\n",
    "    else:\n",
    "        query = f\" s.organisation LIKE '%'\"\n",
    "    params = urllib.parse.urlencode({\n",
    "        \"sql\": f\"\"\"\n",
    "        SELECT\n",
    "            s.organisation AS organisation,\n",
    "            s.collection AS collection,\n",
    "            sp.pipeline AS pipeline,\n",
    "            COUNT ( \n",
    "                DISTINCT \n",
    "                    CASE \n",
    "                        WHEN e.end_date = \"\" THEN e.endpoint_url ELSE NULL END\n",
    "                )\n",
    "                AS non_ended_endpoints,\n",
    "            COUNT ( \n",
    "                DISTINCT \n",
    "                    CASE \n",
    "                        WHEN e.end_date != \"\" THEN e.endpoint_url ELSE NULL END\n",
    "                )\n",
    "                AS ended_endpoints\n",
    "        FROM\n",
    "          log l\n",
    "          INNER JOIN source s ON l.endpoint = s.endpoint\n",
    "          INNER JOIN endpoint e ON l.endpoint = e.endpoint\n",
    "          LEFT JOIN source_pipeline sp ON s.source = sp.source\n",
    "        WHERE\n",
    "           ({query})\n",
    "           AND (NOT collection=\"brownfield-land\")\n",
    "        GROUP BY\n",
    "            s.organisation,\n",
    "            s.collection,\n",
    "            sp.pipeline\n",
    "        HAVING\n",
    "            non_ended_endpoints > 1\n",
    "        ORDER BY\n",
    "            non_ended_endpoints DESC\n",
    "        \"\"\",\n",
    "        \"_size\": \"max\"\n",
    "    })\n",
    "    \n",
    "    url = f\"{datasette_url}digital-land.csv?{params}\"\n",
    "    endpoint_aggregate = pd.read_csv(url)\n",
    "    return endpoint_aggregate\n",
    "\n",
    "widgets.interact(get_endpoint_aggregate, organisation=organisation_dropdown)\n",
    "initial_organisation = organisation_dropdown.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to download the table? (yes/no):  no\n"
     ]
    }
   ],
   "source": [
    "download = input(\"Do you want to download the table? (yes/no): \")\n",
    "\n",
    "if download.lower() == \"yes\":\n",
    "    endpoint_aggregate.to_csv(\"endpoint_aggregate.csv\", index=False)\n",
    "    print(\"Query result downloaded as 'endpoint_aggregate.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Status and end_date of **all** Distinct Endpoints\n",
    "\n",
    "This cell should retrieve **all** distinct **non BFL** endpoints, grouped by collection and pipeline **(not just the endpoints counted above)**. The endpoint entry date, end date, most recent log date and most recent status for each endpoint are retrieved to help deduce whether the endpoint is no longer functional and if it has been manually listed as an old endpoint.\n",
    "\n",
    "**N.B:** \n",
    "- This is queried mainly for a merge later on but may be useful nonetheless.\n",
    "- This query pushes the datasette timeout limit, and often gives an internal server (500) error, rerun this and following cells if this is the case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6149f09eb400496890580b81e2b2646f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Select LPA:', options={\"All LPA's\": None, 'Newcastle': 'local-auth…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_most_recent_logs():\n",
    "    global most_recent_logs  \n",
    "    params = urllib.parse.urlencode({\n",
    "        \"sql\": f\"\"\"\n",
    "        SELECT e.endpoint AS endpoint_hash, MAX(l.entry_date) AS most_recent_entry_date, l.status AS most_recent_status\n",
    "        FROM endpoint e\n",
    "        JOIN log l ON e.endpoint = l.endpoint\n",
    "        GROUP BY e.endpoint\n",
    "        \"\"\",\n",
    "        \"_size\": \"max\"\n",
    "    })\n",
    "\n",
    "    url = f\"{datasette_url}digital-land.csv?{params}\"\n",
    "    most_recent_logs = pd.read_csv(url)\n",
    "    return most_recent_logs\n",
    "\n",
    "def get_distinct_endpoints_status_and_end_dates(organisation):\n",
    "    global distinct_endpoints_status_and_end_dates_df  \n",
    "    if organisation:\n",
    "        query = f\" s.organisation = '{organisation}'\"\n",
    "    else:\n",
    "        query = f\" s.organisation LIKE '%'\"\n",
    "    params = urllib.parse.urlencode({\n",
    "        \"sql\": f\"\"\"\n",
    "        SELECT\n",
    "            s.organisation AS organisation,\n",
    "            s.collection AS collection,\n",
    "            sp.pipeline AS pipeline,\n",
    "            e.endpoint_url AS endpoint,\n",
    "            e.endpoint AS endpoint_hash,\n",
    "            e.entry_date,\n",
    "            s.end_date AS end_date\n",
    "        FROM\n",
    "          log l\n",
    "          INNER JOIN source s ON l.endpoint = s.endpoint\n",
    "          INNER JOIN endpoint e ON l.endpoint = e.endpoint\n",
    "          LEFT JOIN source_pipeline sp ON s.source = sp.source\n",
    "        WHERE\n",
    "           ({query})\n",
    "           AND (NOT collection=\"brownfield-land\")\n",
    "        GROUP BY\n",
    "            s.collection,\n",
    "            sp.pipeline,\n",
    "            e.endpoint\n",
    "        ORDER BY\n",
    "            s.collection,\n",
    "            sp.pipeline\n",
    "        \"\"\",\n",
    "        \"_size\": \"max\"\n",
    "    })\n",
    "    \n",
    "    url = f\"{datasette_url}digital-land.csv?{params}\"\n",
    "    distinct_endpoints_status_and_end_dates_df = pd.read_csv(url)\n",
    "    return distinct_endpoints_status_and_end_dates_df\n",
    "\n",
    "def combine_dataframes(organisation):\n",
    "    global distinct_endpoints_status_and_end_dates_with_status_df\n",
    "    left_df = get_distinct_endpoints_status_and_end_dates(organisation)\n",
    "    right_df = get_most_recent_logs()\n",
    "    distinct_endpoints_status_and_end_dates_with_status_df = pd.merge(left_df, right_df, left_on=['endpoint_hash'], right_on=['endpoint_hash'])\n",
    "    return distinct_endpoints_status_and_end_dates_with_status_df\n",
    "\n",
    "widgets.interact(combine_dataframes, organisation=organisation_dropdown)\n",
    "initial_organisation = organisation_dropdown.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to download the table? (yes/no):  no\n"
     ]
    }
   ],
   "source": [
    "download = input(\"Do you want to download the table? (yes/no): \")\n",
    "\n",
    "if download.lower() == \"yes\":\n",
    "    distinct_endpoints_status_and_end_dates_with_status_df.to_csv(\"distinct_endpoints_status_and_end_dates_with_status_df.csv\", index=False)\n",
    "    print(\"Query result downloaded as 'distinct_endpoints_status_and_end_dates_with_status_df.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigating Datasets with Multiple Endpoint Urls\n",
    "The `endpoint_aggregate` dataframe counts the number of active endpoints for each organisation dataset, below this is merged with the `distinct_endpoints_status_and_end_dates_with_status_df` to list all suspect endpoints in more detail, rather than their aggregates.\n",
    "\n",
    "**N.B:** To function, the following cell requires the \"Counting the Number of Distinct Active Endpoints\" and \"Investigating All Endpoints\" cells to have been run successfully.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A One-to-many merge\n",
    "df = pd.merge(distinct_endpoints_status_and_end_dates_with_status_df, endpoint_aggregate, left_on=['organisation', 'collection', 'pipeline'], right_on=['organisation', 'collection', 'pipeline'])\n",
    "\n",
    "#Removing endpoint rows which had no match with the endpoint_aggregate dataframe\n",
    "df = df.dropna(subset=[\"non_ended_endpoints\"]).drop([\"non_ended_endpoints\", \"ended_endpoints\"], axis=1)\n",
    "\n",
    "# Dropping rows with an end_date value (non-active), sorting and reseting the index field\n",
    "df = df.drop(df[df.end_date.notnull()].index, axis=0).drop([\"end_date\"], axis=1).sort_values(by = [\"organisation\", \"collection\", \"pipeline\"]).reset_index(drop=True)\n",
    "\n",
    "possible_duplicate_endpoints = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consider when these endpoints were last successfully accessed\n",
    "Below we add the field describing the timestamp the endpoint was last successfully accessed (gave a 200-like response) to the `possible_duplicate_endpoints` dataframe generated above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>organisation</th>\n",
       "      <th>collection</th>\n",
       "      <th>pipeline</th>\n",
       "      <th>endpoint</th>\n",
       "      <th>endpoint_hash</th>\n",
       "      <th>entry_date</th>\n",
       "      <th>most_recent_entry_date</th>\n",
       "      <th>most_recent_status</th>\n",
       "      <th>last_200_LIKE_response_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>government-organisation:D303</td>\n",
       "      <td>local-authority-district</td>\n",
       "      <td>local-authority-district</td>\n",
       "      <td>https://opendata.arcgis.com/datasets/fba7a58e8...</td>\n",
       "      <td>1a1fb45966731d26440c51d63c66260dea3bce90d710e7...</td>\n",
       "      <td>2021-12-11T20:20:29Z</td>\n",
       "      <td>2024-01-31T00:02:42Z</td>\n",
       "      <td>404.0</td>\n",
       "      <td>2022-12-05T00:01:39Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>government-organisation:D303</td>\n",
       "      <td>local-authority-district</td>\n",
       "      <td>local-authority-district</td>\n",
       "      <td>https://services1.arcgis.com/ESMARspQHYMw9BZ9/...</td>\n",
       "      <td>2ef35572a081e84417104abe180737f5e74d7481b36504...</td>\n",
       "      <td>2023-08-02T10:10:35Z</td>\n",
       "      <td>2024-01-31T00:02:42Z</td>\n",
       "      <td>200.0</td>\n",
       "      <td>2024-01-31T00:02:42Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>government-organisation:D303</td>\n",
       "      <td>local-authority-district</td>\n",
       "      <td>local-authority-district</td>\n",
       "      <td>https://opendata.arcgis.com/datasets/4b9e1318d...</td>\n",
       "      <td>3239201775cab1f0d0d240cfd5cfe90b5ffd81d51ecce0...</td>\n",
       "      <td>2021-12-11T20:20:19Z</td>\n",
       "      <td>2024-01-31T00:02:42Z</td>\n",
       "      <td>404.0</td>\n",
       "      <td>2022-12-03T00:01:45Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>government-organisation:D303</td>\n",
       "      <td>national-park</td>\n",
       "      <td>national-park</td>\n",
       "      <td>https://opendata.arcgis.com/datasets/2dcdc561b...</td>\n",
       "      <td>48b0d08d547af3d959084610b07ac4c74ccf5306267827...</td>\n",
       "      <td>2020-11-30T00:00:00Z</td>\n",
       "      <td>2024-01-31T00:22:26Z</td>\n",
       "      <td>404.0</td>\n",
       "      <td>2022-12-05T00:23:41Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>government-organisation:D303</td>\n",
       "      <td>national-park</td>\n",
       "      <td>national-park</td>\n",
       "      <td>https://opendata.arcgis.com/datasets/6b6603ff4...</td>\n",
       "      <td>6b5a5ff541c241f71ac0c4187d0766c84fac32c2341ac1...</td>\n",
       "      <td>2020-11-30T00:00:00Z</td>\n",
       "      <td>2024-01-31T00:22:26Z</td>\n",
       "      <td>404.0</td>\n",
       "      <td>2022-12-02T00:23:38Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>local-authority-eng:WDE</td>\n",
       "      <td>developer-contributions</td>\n",
       "      <td>developer-agreement-contribution</td>\n",
       "      <td>https://westdevon.gov.uk/developer-agreement-c...</td>\n",
       "      <td>697dbfe28573767f45aeb099d7babe91561e95353609c8...</td>\n",
       "      <td>2020-12-18T00:00:00Z</td>\n",
       "      <td>2024-01-31T00:21:05Z</td>\n",
       "      <td>200.0</td>\n",
       "      <td>2024-01-31T00:21:05Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>national-park-authority:Q72617158</td>\n",
       "      <td>developer-contributions</td>\n",
       "      <td>developer-agreement</td>\n",
       "      <td>https://www.newforestnpa.gov.uk/app/uploads/20...</td>\n",
       "      <td>5d011d068dc5da03d3fca7e3387797480d5cf1250b8ca4...</td>\n",
       "      <td>2021-12-31T11:11:11Z</td>\n",
       "      <td>2024-01-31T00:21:05Z</td>\n",
       "      <td>200.0</td>\n",
       "      <td>2024-01-31T00:21:05Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>national-park-authority:Q72617158</td>\n",
       "      <td>developer-contributions</td>\n",
       "      <td>developer-agreement</td>\n",
       "      <td>https://www.newforestnpa.gov.uk/app/uploads/20...</td>\n",
       "      <td>705d90de8c2841af9a725e0e4c0d39166d169e45497d89...</td>\n",
       "      <td>2020-12-18T00:00:00Z</td>\n",
       "      <td>2024-01-31T00:21:05Z</td>\n",
       "      <td>404.0</td>\n",
       "      <td>2021-12-07T01:05:06Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>national-park-authority:Q72617158</td>\n",
       "      <td>developer-contributions</td>\n",
       "      <td>developer-agreement-transaction</td>\n",
       "      <td>https://www.newforestnpa.gov.uk/app/uploads/20...</td>\n",
       "      <td>34ef1379df513fb0b55919653336be6a534f9073482e06...</td>\n",
       "      <td>2021-12-31T11:11:15Z</td>\n",
       "      <td>2024-01-31T00:21:05Z</td>\n",
       "      <td>200.0</td>\n",
       "      <td>2024-01-31T00:21:05Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>national-park-authority:Q72617158</td>\n",
       "      <td>developer-contributions</td>\n",
       "      <td>developer-agreement-transaction</td>\n",
       "      <td>https://www.newforestnpa.gov.uk/app/uploads/20...</td>\n",
       "      <td>6f317f7a4ab4c81d06eaa7e6b8551f8d0ad08a8385bea5...</td>\n",
       "      <td>2020-12-18T00:00:00Z</td>\n",
       "      <td>2024-01-31T00:21:05Z</td>\n",
       "      <td>404.0</td>\n",
       "      <td>2021-12-07T01:05:06Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          organisation                collection  \\\n",
       "0         government-organisation:D303  local-authority-district   \n",
       "1         government-organisation:D303  local-authority-district   \n",
       "2         government-organisation:D303  local-authority-district   \n",
       "3         government-organisation:D303             national-park   \n",
       "4         government-organisation:D303             national-park   \n",
       "..                                 ...                       ...   \n",
       "106            local-authority-eng:WDE   developer-contributions   \n",
       "107  national-park-authority:Q72617158   developer-contributions   \n",
       "108  national-park-authority:Q72617158   developer-contributions   \n",
       "109  national-park-authority:Q72617158   developer-contributions   \n",
       "110  national-park-authority:Q72617158   developer-contributions   \n",
       "\n",
       "                             pipeline  \\\n",
       "0            local-authority-district   \n",
       "1            local-authority-district   \n",
       "2            local-authority-district   \n",
       "3                       national-park   \n",
       "4                       national-park   \n",
       "..                                ...   \n",
       "106  developer-agreement-contribution   \n",
       "107               developer-agreement   \n",
       "108               developer-agreement   \n",
       "109   developer-agreement-transaction   \n",
       "110   developer-agreement-transaction   \n",
       "\n",
       "                                              endpoint  \\\n",
       "0    https://opendata.arcgis.com/datasets/fba7a58e8...   \n",
       "1    https://services1.arcgis.com/ESMARspQHYMw9BZ9/...   \n",
       "2    https://opendata.arcgis.com/datasets/4b9e1318d...   \n",
       "3    https://opendata.arcgis.com/datasets/2dcdc561b...   \n",
       "4    https://opendata.arcgis.com/datasets/6b6603ff4...   \n",
       "..                                                 ...   \n",
       "106  https://westdevon.gov.uk/developer-agreement-c...   \n",
       "107  https://www.newforestnpa.gov.uk/app/uploads/20...   \n",
       "108  https://www.newforestnpa.gov.uk/app/uploads/20...   \n",
       "109  https://www.newforestnpa.gov.uk/app/uploads/20...   \n",
       "110  https://www.newforestnpa.gov.uk/app/uploads/20...   \n",
       "\n",
       "                                         endpoint_hash            entry_date  \\\n",
       "0    1a1fb45966731d26440c51d63c66260dea3bce90d710e7...  2021-12-11T20:20:29Z   \n",
       "1    2ef35572a081e84417104abe180737f5e74d7481b36504...  2023-08-02T10:10:35Z   \n",
       "2    3239201775cab1f0d0d240cfd5cfe90b5ffd81d51ecce0...  2021-12-11T20:20:19Z   \n",
       "3    48b0d08d547af3d959084610b07ac4c74ccf5306267827...  2020-11-30T00:00:00Z   \n",
       "4    6b5a5ff541c241f71ac0c4187d0766c84fac32c2341ac1...  2020-11-30T00:00:00Z   \n",
       "..                                                 ...                   ...   \n",
       "106  697dbfe28573767f45aeb099d7babe91561e95353609c8...  2020-12-18T00:00:00Z   \n",
       "107  5d011d068dc5da03d3fca7e3387797480d5cf1250b8ca4...  2021-12-31T11:11:11Z   \n",
       "108  705d90de8c2841af9a725e0e4c0d39166d169e45497d89...  2020-12-18T00:00:00Z   \n",
       "109  34ef1379df513fb0b55919653336be6a534f9073482e06...  2021-12-31T11:11:15Z   \n",
       "110  6f317f7a4ab4c81d06eaa7e6b8551f8d0ad08a8385bea5...  2020-12-18T00:00:00Z   \n",
       "\n",
       "    most_recent_entry_date  most_recent_status  \\\n",
       "0     2024-01-31T00:02:42Z               404.0   \n",
       "1     2024-01-31T00:02:42Z               200.0   \n",
       "2     2024-01-31T00:02:42Z               404.0   \n",
       "3     2024-01-31T00:22:26Z               404.0   \n",
       "4     2024-01-31T00:22:26Z               404.0   \n",
       "..                     ...                 ...   \n",
       "106   2024-01-31T00:21:05Z               200.0   \n",
       "107   2024-01-31T00:21:05Z               200.0   \n",
       "108   2024-01-31T00:21:05Z               404.0   \n",
       "109   2024-01-31T00:21:05Z               200.0   \n",
       "110   2024-01-31T00:21:05Z               404.0   \n",
       "\n",
       "    last_200_LIKE_response_timestamp  \n",
       "0               2022-12-05T00:01:39Z  \n",
       "1               2024-01-31T00:02:42Z  \n",
       "2               2022-12-03T00:01:45Z  \n",
       "3               2022-12-05T00:23:41Z  \n",
       "4               2022-12-02T00:23:38Z  \n",
       "..                               ...  \n",
       "106             2024-01-31T00:21:05Z  \n",
       "107             2024-01-31T00:21:05Z  \n",
       "108             2021-12-07T01:05:06Z  \n",
       "109             2024-01-31T00:21:05Z  \n",
       "110             2021-12-07T01:05:06Z  \n",
       "\n",
       "[111 rows x 9 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_when_successfully_accessed():\n",
    "    global last_successfully_accessed  \n",
    "    params = urllib.parse.urlencode({\n",
    "        \"sql\": f\"\"\"\n",
    "        SELECT\n",
    "            MAX(l.entry_date) AS last_200_LIKE_response_timestamp,\n",
    "            e.endpoint AS endpoint_hash\n",
    "        FROM\n",
    "          log l\n",
    "          INNER JOIN endpoint e ON l.endpoint = e.endpoint\n",
    "          INNER JOIN source s ON l.endpoint = s.endpoint\n",
    "        WHERE\n",
    "            (NOT collection=\"brownfield-land\")\n",
    "            AND l.status LIKE \"2%\"\n",
    "        GROUP BY\n",
    "            e.endpoint_url\n",
    "        \"\"\",\n",
    "        \"_size\": \"max\"\n",
    "    })\n",
    "\n",
    "    url = f\"{datasette_url}digital-land.csv?{params}\"\n",
    "    last_successfully_accessed = pd.read_csv(url)\n",
    "    return last_successfully_accessed\n",
    "\n",
    "\n",
    "\n",
    "possible_duplicate_endpoints_last_200 = pd.merge(possible_duplicate_endpoints, get_when_successfully_accessed(), left_on=['endpoint_hash'], right_on=['endpoint_hash'])\n",
    "\n",
    "possible_duplicate_endpoints_last_200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to download the table? (yes/no):  no\n"
     ]
    }
   ],
   "source": [
    "download = input(\"Do you want to download the table? (yes/no): \")\n",
    "\n",
    "if download.lower() == \"yes\":\n",
    "    possible_duplicate_endpoints_last_200.to_csv(\"possible_duplicate_endpoints_last_200.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Stale Endpoints\n",
    "Endpoints which were last successfully accessed over **5 days** ago can be assumed faulty, or effectively ended and can be recommended for removal by the standard process https://docs.google.com/document/d/1Xm1frOBY-J4mLfigXuFdeq976cQGghhnt0gbmZleAyc/edit#heading=h.y6u78drjip12.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>organisation</th>\n",
       "      <th>collection</th>\n",
       "      <th>pipeline</th>\n",
       "      <th>endpoint</th>\n",
       "      <th>endpoint_hash</th>\n",
       "      <th>entry_date</th>\n",
       "      <th>most_recent_entry_date</th>\n",
       "      <th>most_recent_status</th>\n",
       "      <th>last_200_LIKE_response_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>government-organisation:D303</td>\n",
       "      <td>local-authority-district</td>\n",
       "      <td>local-authority-district</td>\n",
       "      <td>https://opendata.arcgis.com/datasets/fba7a58e8...</td>\n",
       "      <td>1a1fb45966731d26440c51d63c66260dea3bce90d710e7...</td>\n",
       "      <td>2021-12-11T20:20:29Z</td>\n",
       "      <td>2024-01-31T00:02:42Z</td>\n",
       "      <td>404.0</td>\n",
       "      <td>2022-12-05 00:01:39+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>government-organisation:D303</td>\n",
       "      <td>local-authority-district</td>\n",
       "      <td>local-authority-district</td>\n",
       "      <td>https://opendata.arcgis.com/datasets/4b9e1318d...</td>\n",
       "      <td>3239201775cab1f0d0d240cfd5cfe90b5ffd81d51ecce0...</td>\n",
       "      <td>2021-12-11T20:20:19Z</td>\n",
       "      <td>2024-01-31T00:02:42Z</td>\n",
       "      <td>404.0</td>\n",
       "      <td>2022-12-03 00:01:45+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>government-organisation:D303</td>\n",
       "      <td>national-park</td>\n",
       "      <td>national-park</td>\n",
       "      <td>https://opendata.arcgis.com/datasets/2dcdc561b...</td>\n",
       "      <td>48b0d08d547af3d959084610b07ac4c74ccf5306267827...</td>\n",
       "      <td>2020-11-30T00:00:00Z</td>\n",
       "      <td>2024-01-31T00:22:26Z</td>\n",
       "      <td>404.0</td>\n",
       "      <td>2022-12-05 00:23:41+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>government-organisation:D303</td>\n",
       "      <td>national-park</td>\n",
       "      <td>national-park</td>\n",
       "      <td>https://opendata.arcgis.com/datasets/6b6603ff4...</td>\n",
       "      <td>6b5a5ff541c241f71ac0c4187d0766c84fac32c2341ac1...</td>\n",
       "      <td>2020-11-30T00:00:00Z</td>\n",
       "      <td>2024-01-31T00:22:26Z</td>\n",
       "      <td>404.0</td>\n",
       "      <td>2022-12-02 00:23:38+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>local-authority-eng:CAT</td>\n",
       "      <td>article-4-direction</td>\n",
       "      <td>article-4-direction-area</td>\n",
       "      <td>https://mapping.canterbury.gov.uk/arcgis/rest/...</td>\n",
       "      <td>351fdbd179616dcf25ce0c4498cbd7fd5a917c5bbedcbc...</td>\n",
       "      <td>2021-11-11T14:14:25Z</td>\n",
       "      <td>2024-01-31T00:19:48Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-01-16 00:16:16+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>local-authority-eng:COV</td>\n",
       "      <td>developer-contributions</td>\n",
       "      <td>developer-agreement-transaction</td>\n",
       "      <td>https://www.coventry.gov.uk/download/downloads...</td>\n",
       "      <td>066ee597b0526ddbe1d9bee406eab6ccf316055662be33...</td>\n",
       "      <td>2021-12-31T11:11:14Z</td>\n",
       "      <td>2024-01-31T00:21:05Z</td>\n",
       "      <td>500.0</td>\n",
       "      <td>2022-07-13 00:26:08+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>local-authority-eng:COV</td>\n",
       "      <td>developer-contributions</td>\n",
       "      <td>developer-agreement-transaction</td>\n",
       "      <td>https://www.coventry.gov.uk/download/downloads...</td>\n",
       "      <td>1ae6b8cc4fab55aa8e23b51160c3e51b350eb8d44a04d6...</td>\n",
       "      <td>2021-12-31T11:11:14Z</td>\n",
       "      <td>2024-01-31T00:21:05Z</td>\n",
       "      <td>500.0</td>\n",
       "      <td>2023-08-24 00:18:10+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>local-authority-eng:COV</td>\n",
       "      <td>developer-contributions</td>\n",
       "      <td>developer-agreement-transaction</td>\n",
       "      <td>https://www.coventry.gov.uk/download/downloads...</td>\n",
       "      <td>323046bda27fe8856575a8cc3aa6895684dd6e7a5c0f34...</td>\n",
       "      <td>2021-12-31T11:11:14Z</td>\n",
       "      <td>2024-01-31T00:21:05Z</td>\n",
       "      <td>500.0</td>\n",
       "      <td>2023-02-09 00:21:52+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>local-authority-eng:DOV</td>\n",
       "      <td>developer-contributions</td>\n",
       "      <td>developer-agreement</td>\n",
       "      <td>https://www.dover.gov.uk/Planning/Planning-Pol...</td>\n",
       "      <td>739d4ab8af624694d0a2960571e2fadad37c9d2d353138...</td>\n",
       "      <td>2021-12-31T11:11:11Z</td>\n",
       "      <td>2024-01-31T00:21:05Z</td>\n",
       "      <td>404.0</td>\n",
       "      <td>2023-01-18 00:21:34+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>local-authority-eng:DOV</td>\n",
       "      <td>developer-contributions</td>\n",
       "      <td>developer-agreement-contribution</td>\n",
       "      <td>https://www.dover.gov.uk/Planning/Planning-Pol...</td>\n",
       "      <td>65c04fb830320a32ceb91061f02d85be6fdb0f55fcae67...</td>\n",
       "      <td>2021-10-07T00:00:00Z</td>\n",
       "      <td>2024-01-31T00:21:05Z</td>\n",
       "      <td>404.0</td>\n",
       "      <td>2023-01-18 00:21:34+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>local-authority-eng:DOV</td>\n",
       "      <td>developer-contributions</td>\n",
       "      <td>developer-agreement-transaction</td>\n",
       "      <td>https://www.dover.gov.uk/Planning/Planning-Pol...</td>\n",
       "      <td>11d0f9dae62103b91e42742f01f2e92e7ceb18690cb7b9...</td>\n",
       "      <td>2021-12-31T11:11:15Z</td>\n",
       "      <td>2024-01-31T00:21:05Z</td>\n",
       "      <td>404.0</td>\n",
       "      <td>2023-01-18 00:21:34+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>local-authority-eng:HAT</td>\n",
       "      <td>developer-contributions</td>\n",
       "      <td>developer-agreement</td>\n",
       "      <td>https://www.hart.gov.uk/sites/default/files/4_...</td>\n",
       "      <td>6c00e9469c095af9184485efb79b205142f422365c2fef...</td>\n",
       "      <td>2021-12-31T11:11:09Z</td>\n",
       "      <td>2024-01-31T00:21:05Z</td>\n",
       "      <td>404.0</td>\n",
       "      <td>2023-03-29 00:24:42+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>local-authority-eng:HYN</td>\n",
       "      <td>developer-contributions</td>\n",
       "      <td>developer-agreement</td>\n",
       "      <td>https://www.hyndburnbc.gov.uk/download-package...</td>\n",
       "      <td>02555422754afe68c07c2813ecc77960d7c31fabe28d9b...</td>\n",
       "      <td>2021-12-31T11:11:11Z</td>\n",
       "      <td>2024-01-31T00:21:05Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-12-13 00:21:47+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>local-authority-eng:HYN</td>\n",
       "      <td>developer-contributions</td>\n",
       "      <td>developer-agreement</td>\n",
       "      <td>https://www.hyndburnbc.gov.uk/download-package...</td>\n",
       "      <td>16453d07a8bf6da5ee1b20b6c230159e3757c8fa4ecb7d...</td>\n",
       "      <td>2021-10-07T00:00:00Z</td>\n",
       "      <td>2024-01-31T00:21:05Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-12-13 00:21:47+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>local-authority-eng:LBH</td>\n",
       "      <td>article-4-direction</td>\n",
       "      <td>article-4-direction-area</td>\n",
       "      <td>https://opendata.arcgis.com/datasets/80405101d...</td>\n",
       "      <td>55e8c3db23ada8dac1343c4b6dd8ecd71c6b057ee3cea1...</td>\n",
       "      <td>2021-10-29T00:00:00Z</td>\n",
       "      <td>2024-01-31T00:19:48Z</td>\n",
       "      <td>404.0</td>\n",
       "      <td>2022-11-01 00:22:54+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>local-authority-eng:NEA</td>\n",
       "      <td>developer-contributions</td>\n",
       "      <td>developer-agreement-contribution</td>\n",
       "      <td>https://www.newark-sherwooddc.gov.uk/media/new...</td>\n",
       "      <td>67d437af3185d71185cb7693beff108ebc6feea2f91df5...</td>\n",
       "      <td>2020-12-23T00:00:00Z</td>\n",
       "      <td>2024-01-31T00:21:05Z</td>\n",
       "      <td>404.0</td>\n",
       "      <td>2021-09-07 00:57:21+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>local-authority-eng:NEA</td>\n",
       "      <td>developer-contributions</td>\n",
       "      <td>developer-agreement-transaction</td>\n",
       "      <td>https://www.newark-sherwooddc.gov.uk/media/new...</td>\n",
       "      <td>6a20f4b320841918355187b741c32b8985da7415171936...</td>\n",
       "      <td>2020-12-23T00:00:00Z</td>\n",
       "      <td>2024-01-31T00:21:05Z</td>\n",
       "      <td>404.0</td>\n",
       "      <td>2021-09-07 00:57:21+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>local-authority-eng:PUR</td>\n",
       "      <td>conservation-area</td>\n",
       "      <td>conservation-area</td>\n",
       "      <td>http://geowessex.astuntechnology.com/getows.as...</td>\n",
       "      <td>0d384b928dcd6640dd25a7f6ef6fe7eed1b7a6850b6aee...</td>\n",
       "      <td>2020-09-11T16:47:35Z</td>\n",
       "      <td>2024-01-31T00:06:58Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-05-09 00:05:51+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>local-authority-eng:RUG</td>\n",
       "      <td>developer-contributions</td>\n",
       "      <td>developer-agreement</td>\n",
       "      <td>https://www.rugby.gov.uk/download/downloads/id...</td>\n",
       "      <td>3af3fa69a41e8e389c98c228c9a1d5a63829b415737e63...</td>\n",
       "      <td>2021-12-31T11:11:11Z</td>\n",
       "      <td>2024-01-31T00:21:05Z</td>\n",
       "      <td>404.0</td>\n",
       "      <td>2023-01-18 00:21:34+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>local-authority-eng:RUG</td>\n",
       "      <td>developer-contributions</td>\n",
       "      <td>developer-agreement-transaction</td>\n",
       "      <td>https://www.rugby.gov.uk/download/downloads/id...</td>\n",
       "      <td>1077a9616ecc3f9c5182e524def55e0be7c194bfe1df7f...</td>\n",
       "      <td>2021-12-31T11:11:15Z</td>\n",
       "      <td>2024-01-31T00:21:05Z</td>\n",
       "      <td>404.0</td>\n",
       "      <td>2023-01-18 00:21:34+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>local-authority-eng:SLA</td>\n",
       "      <td>developer-contributions</td>\n",
       "      <td>developer-agreement-transaction</td>\n",
       "      <td>https://www.southlakeland.gov.uk/media/7347/de...</td>\n",
       "      <td>74e6ad20eeb23e7d21a942fcad5316e140e050f36da824...</td>\n",
       "      <td>2020-12-23T00:00:00Z</td>\n",
       "      <td>2024-01-31T00:21:05Z</td>\n",
       "      <td>404.0</td>\n",
       "      <td>2021-12-21 01:07:38+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>local-authority-eng:SNR</td>\n",
       "      <td>developer-contributions</td>\n",
       "      <td>developer-agreement</td>\n",
       "      <td>https://www.southnorthants.gov.uk/download/dow...</td>\n",
       "      <td>043b92f4db06a68b8de3cf74f01327cfd40582c49d9652...</td>\n",
       "      <td>2021-12-31T11:11:12Z</td>\n",
       "      <td>2024-01-31T00:21:05Z</td>\n",
       "      <td>403.0</td>\n",
       "      <td>2022-10-12 00:34:37+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>local-authority-eng:SNR</td>\n",
       "      <td>developer-contributions</td>\n",
       "      <td>developer-agreement</td>\n",
       "      <td>https://www.southnorthants.gov.uk/download/dow...</td>\n",
       "      <td>450f93f25887ed07df4f266fd5c6c4c910d84ff6a0d37e...</td>\n",
       "      <td>2021-12-31T11:11:12Z</td>\n",
       "      <td>2024-01-31T00:21:05Z</td>\n",
       "      <td>403.0</td>\n",
       "      <td>2022-10-12 00:34:37+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>local-authority-eng:SNR</td>\n",
       "      <td>developer-contributions</td>\n",
       "      <td>developer-agreement-transaction</td>\n",
       "      <td>https://www.southnorthants.gov.uk/download/dow...</td>\n",
       "      <td>125fb3f6a22aef73df6ea90ef4db2714d85c91cec3613f...</td>\n",
       "      <td>2021-12-31T11:11:15Z</td>\n",
       "      <td>2024-01-31T00:21:05Z</td>\n",
       "      <td>403.0</td>\n",
       "      <td>2022-10-12 00:34:37+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>local-authority-eng:SNR</td>\n",
       "      <td>developer-contributions</td>\n",
       "      <td>developer-agreement-transaction</td>\n",
       "      <td>https://www.southnorthants.gov.uk/download/dow...</td>\n",
       "      <td>24c6e58b61392f3f73ab40498c77aa0c07d79944d3289a...</td>\n",
       "      <td>2021-12-31T11:11:15Z</td>\n",
       "      <td>2024-01-31T00:21:05Z</td>\n",
       "      <td>403.0</td>\n",
       "      <td>2022-10-12 00:34:37+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>national-park-authority:Q72617158</td>\n",
       "      <td>developer-contributions</td>\n",
       "      <td>developer-agreement</td>\n",
       "      <td>https://www.newforestnpa.gov.uk/app/uploads/20...</td>\n",
       "      <td>705d90de8c2841af9a725e0e4c0d39166d169e45497d89...</td>\n",
       "      <td>2020-12-18T00:00:00Z</td>\n",
       "      <td>2024-01-31T00:21:05Z</td>\n",
       "      <td>404.0</td>\n",
       "      <td>2021-12-07 01:05:06+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>national-park-authority:Q72617158</td>\n",
       "      <td>developer-contributions</td>\n",
       "      <td>developer-agreement-transaction</td>\n",
       "      <td>https://www.newforestnpa.gov.uk/app/uploads/20...</td>\n",
       "      <td>6f317f7a4ab4c81d06eaa7e6b8551f8d0ad08a8385bea5...</td>\n",
       "      <td>2020-12-18T00:00:00Z</td>\n",
       "      <td>2024-01-31T00:21:05Z</td>\n",
       "      <td>404.0</td>\n",
       "      <td>2021-12-07 01:05:06+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         organisation                collection  \\\n",
       "0        government-organisation:D303  local-authority-district   \n",
       "1        government-organisation:D303  local-authority-district   \n",
       "2        government-organisation:D303             national-park   \n",
       "3        government-organisation:D303             national-park   \n",
       "4             local-authority-eng:CAT       article-4-direction   \n",
       "5             local-authority-eng:COV   developer-contributions   \n",
       "6             local-authority-eng:COV   developer-contributions   \n",
       "7             local-authority-eng:COV   developer-contributions   \n",
       "8             local-authority-eng:DOV   developer-contributions   \n",
       "9             local-authority-eng:DOV   developer-contributions   \n",
       "10            local-authority-eng:DOV   developer-contributions   \n",
       "11            local-authority-eng:HAT   developer-contributions   \n",
       "12            local-authority-eng:HYN   developer-contributions   \n",
       "13            local-authority-eng:HYN   developer-contributions   \n",
       "14            local-authority-eng:LBH       article-4-direction   \n",
       "15            local-authority-eng:NEA   developer-contributions   \n",
       "16            local-authority-eng:NEA   developer-contributions   \n",
       "17            local-authority-eng:PUR         conservation-area   \n",
       "18            local-authority-eng:RUG   developer-contributions   \n",
       "19            local-authority-eng:RUG   developer-contributions   \n",
       "20            local-authority-eng:SLA   developer-contributions   \n",
       "21            local-authority-eng:SNR   developer-contributions   \n",
       "22            local-authority-eng:SNR   developer-contributions   \n",
       "23            local-authority-eng:SNR   developer-contributions   \n",
       "24            local-authority-eng:SNR   developer-contributions   \n",
       "25  national-park-authority:Q72617158   developer-contributions   \n",
       "26  national-park-authority:Q72617158   developer-contributions   \n",
       "\n",
       "                            pipeline  \\\n",
       "0           local-authority-district   \n",
       "1           local-authority-district   \n",
       "2                      national-park   \n",
       "3                      national-park   \n",
       "4           article-4-direction-area   \n",
       "5    developer-agreement-transaction   \n",
       "6    developer-agreement-transaction   \n",
       "7    developer-agreement-transaction   \n",
       "8                developer-agreement   \n",
       "9   developer-agreement-contribution   \n",
       "10   developer-agreement-transaction   \n",
       "11               developer-agreement   \n",
       "12               developer-agreement   \n",
       "13               developer-agreement   \n",
       "14          article-4-direction-area   \n",
       "15  developer-agreement-contribution   \n",
       "16   developer-agreement-transaction   \n",
       "17                 conservation-area   \n",
       "18               developer-agreement   \n",
       "19   developer-agreement-transaction   \n",
       "20   developer-agreement-transaction   \n",
       "21               developer-agreement   \n",
       "22               developer-agreement   \n",
       "23   developer-agreement-transaction   \n",
       "24   developer-agreement-transaction   \n",
       "25               developer-agreement   \n",
       "26   developer-agreement-transaction   \n",
       "\n",
       "                                             endpoint  \\\n",
       "0   https://opendata.arcgis.com/datasets/fba7a58e8...   \n",
       "1   https://opendata.arcgis.com/datasets/4b9e1318d...   \n",
       "2   https://opendata.arcgis.com/datasets/2dcdc561b...   \n",
       "3   https://opendata.arcgis.com/datasets/6b6603ff4...   \n",
       "4   https://mapping.canterbury.gov.uk/arcgis/rest/...   \n",
       "5   https://www.coventry.gov.uk/download/downloads...   \n",
       "6   https://www.coventry.gov.uk/download/downloads...   \n",
       "7   https://www.coventry.gov.uk/download/downloads...   \n",
       "8   https://www.dover.gov.uk/Planning/Planning-Pol...   \n",
       "9   https://www.dover.gov.uk/Planning/Planning-Pol...   \n",
       "10  https://www.dover.gov.uk/Planning/Planning-Pol...   \n",
       "11  https://www.hart.gov.uk/sites/default/files/4_...   \n",
       "12  https://www.hyndburnbc.gov.uk/download-package...   \n",
       "13  https://www.hyndburnbc.gov.uk/download-package...   \n",
       "14  https://opendata.arcgis.com/datasets/80405101d...   \n",
       "15  https://www.newark-sherwooddc.gov.uk/media/new...   \n",
       "16  https://www.newark-sherwooddc.gov.uk/media/new...   \n",
       "17  http://geowessex.astuntechnology.com/getows.as...   \n",
       "18  https://www.rugby.gov.uk/download/downloads/id...   \n",
       "19  https://www.rugby.gov.uk/download/downloads/id...   \n",
       "20  https://www.southlakeland.gov.uk/media/7347/de...   \n",
       "21  https://www.southnorthants.gov.uk/download/dow...   \n",
       "22  https://www.southnorthants.gov.uk/download/dow...   \n",
       "23  https://www.southnorthants.gov.uk/download/dow...   \n",
       "24  https://www.southnorthants.gov.uk/download/dow...   \n",
       "25  https://www.newforestnpa.gov.uk/app/uploads/20...   \n",
       "26  https://www.newforestnpa.gov.uk/app/uploads/20...   \n",
       "\n",
       "                                        endpoint_hash            entry_date  \\\n",
       "0   1a1fb45966731d26440c51d63c66260dea3bce90d710e7...  2021-12-11T20:20:29Z   \n",
       "1   3239201775cab1f0d0d240cfd5cfe90b5ffd81d51ecce0...  2021-12-11T20:20:19Z   \n",
       "2   48b0d08d547af3d959084610b07ac4c74ccf5306267827...  2020-11-30T00:00:00Z   \n",
       "3   6b5a5ff541c241f71ac0c4187d0766c84fac32c2341ac1...  2020-11-30T00:00:00Z   \n",
       "4   351fdbd179616dcf25ce0c4498cbd7fd5a917c5bbedcbc...  2021-11-11T14:14:25Z   \n",
       "5   066ee597b0526ddbe1d9bee406eab6ccf316055662be33...  2021-12-31T11:11:14Z   \n",
       "6   1ae6b8cc4fab55aa8e23b51160c3e51b350eb8d44a04d6...  2021-12-31T11:11:14Z   \n",
       "7   323046bda27fe8856575a8cc3aa6895684dd6e7a5c0f34...  2021-12-31T11:11:14Z   \n",
       "8   739d4ab8af624694d0a2960571e2fadad37c9d2d353138...  2021-12-31T11:11:11Z   \n",
       "9   65c04fb830320a32ceb91061f02d85be6fdb0f55fcae67...  2021-10-07T00:00:00Z   \n",
       "10  11d0f9dae62103b91e42742f01f2e92e7ceb18690cb7b9...  2021-12-31T11:11:15Z   \n",
       "11  6c00e9469c095af9184485efb79b205142f422365c2fef...  2021-12-31T11:11:09Z   \n",
       "12  02555422754afe68c07c2813ecc77960d7c31fabe28d9b...  2021-12-31T11:11:11Z   \n",
       "13  16453d07a8bf6da5ee1b20b6c230159e3757c8fa4ecb7d...  2021-10-07T00:00:00Z   \n",
       "14  55e8c3db23ada8dac1343c4b6dd8ecd71c6b057ee3cea1...  2021-10-29T00:00:00Z   \n",
       "15  67d437af3185d71185cb7693beff108ebc6feea2f91df5...  2020-12-23T00:00:00Z   \n",
       "16  6a20f4b320841918355187b741c32b8985da7415171936...  2020-12-23T00:00:00Z   \n",
       "17  0d384b928dcd6640dd25a7f6ef6fe7eed1b7a6850b6aee...  2020-09-11T16:47:35Z   \n",
       "18  3af3fa69a41e8e389c98c228c9a1d5a63829b415737e63...  2021-12-31T11:11:11Z   \n",
       "19  1077a9616ecc3f9c5182e524def55e0be7c194bfe1df7f...  2021-12-31T11:11:15Z   \n",
       "20  74e6ad20eeb23e7d21a942fcad5316e140e050f36da824...  2020-12-23T00:00:00Z   \n",
       "21  043b92f4db06a68b8de3cf74f01327cfd40582c49d9652...  2021-12-31T11:11:12Z   \n",
       "22  450f93f25887ed07df4f266fd5c6c4c910d84ff6a0d37e...  2021-12-31T11:11:12Z   \n",
       "23  125fb3f6a22aef73df6ea90ef4db2714d85c91cec3613f...  2021-12-31T11:11:15Z   \n",
       "24  24c6e58b61392f3f73ab40498c77aa0c07d79944d3289a...  2021-12-31T11:11:15Z   \n",
       "25  705d90de8c2841af9a725e0e4c0d39166d169e45497d89...  2020-12-18T00:00:00Z   \n",
       "26  6f317f7a4ab4c81d06eaa7e6b8551f8d0ad08a8385bea5...  2020-12-18T00:00:00Z   \n",
       "\n",
       "   most_recent_entry_date  most_recent_status last_200_LIKE_response_timestamp  \n",
       "0    2024-01-31T00:02:42Z               404.0        2022-12-05 00:01:39+00:00  \n",
       "1    2024-01-31T00:02:42Z               404.0        2022-12-03 00:01:45+00:00  \n",
       "2    2024-01-31T00:22:26Z               404.0        2022-12-05 00:23:41+00:00  \n",
       "3    2024-01-31T00:22:26Z               404.0        2022-12-02 00:23:38+00:00  \n",
       "4    2024-01-31T00:19:48Z                 NaN        2024-01-16 00:16:16+00:00  \n",
       "5    2024-01-31T00:21:05Z               500.0        2022-07-13 00:26:08+00:00  \n",
       "6    2024-01-31T00:21:05Z               500.0        2023-08-24 00:18:10+00:00  \n",
       "7    2024-01-31T00:21:05Z               500.0        2023-02-09 00:21:52+00:00  \n",
       "8    2024-01-31T00:21:05Z               404.0        2023-01-18 00:21:34+00:00  \n",
       "9    2024-01-31T00:21:05Z               404.0        2023-01-18 00:21:34+00:00  \n",
       "10   2024-01-31T00:21:05Z               404.0        2023-01-18 00:21:34+00:00  \n",
       "11   2024-01-31T00:21:05Z               404.0        2023-03-29 00:24:42+00:00  \n",
       "12   2024-01-31T00:21:05Z                 NaN        2022-12-13 00:21:47+00:00  \n",
       "13   2024-01-31T00:21:05Z                 NaN        2022-12-13 00:21:47+00:00  \n",
       "14   2024-01-31T00:19:48Z               404.0        2022-11-01 00:22:54+00:00  \n",
       "15   2024-01-31T00:21:05Z               404.0        2021-09-07 00:57:21+00:00  \n",
       "16   2024-01-31T00:21:05Z               404.0        2021-09-07 00:57:21+00:00  \n",
       "17   2024-01-31T00:06:58Z                 NaN        2022-05-09 00:05:51+00:00  \n",
       "18   2024-01-31T00:21:05Z               404.0        2023-01-18 00:21:34+00:00  \n",
       "19   2024-01-31T00:21:05Z               404.0        2023-01-18 00:21:34+00:00  \n",
       "20   2024-01-31T00:21:05Z               404.0        2021-12-21 01:07:38+00:00  \n",
       "21   2024-01-31T00:21:05Z               403.0        2022-10-12 00:34:37+00:00  \n",
       "22   2024-01-31T00:21:05Z               403.0        2022-10-12 00:34:37+00:00  \n",
       "23   2024-01-31T00:21:05Z               403.0        2022-10-12 00:34:37+00:00  \n",
       "24   2024-01-31T00:21:05Z               403.0        2022-10-12 00:34:37+00:00  \n",
       "25   2024-01-31T00:21:05Z               404.0        2021-12-07 01:05:06+00:00  \n",
       "26   2024-01-31T00:21:05Z               404.0        2021-12-07 01:05:06+00:00  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab datetime of 5 days ago relative to current date\n",
    "five_days_ago_timestamp = pd.to_datetime('today').normalize().tz_localize(\"Europe/London\" ,ambiguous=True) - pd.Timedelta(days=5)\n",
    "\n",
    "# Assign new df variable and convert most_recent_status to string for later string comparison\n",
    "df = possible_duplicate_endpoints_last_200\n",
    "df[\"most_recent_status\"] = df[\"most_recent_status\"].astype(str)\n",
    "\n",
    "# Convert last_200_response_timestamp field to datetime\n",
    "df[\"last_200_LIKE_response_timestamp\"] = pd.to_datetime(df[\"last_200_LIKE_response_timestamp\"])\n",
    "\n",
    "# Grab non-200 data by comparison\n",
    "df = df[~df[\"most_recent_status\"].str.contains(\"2\")]\n",
    "\n",
    "# Filter for entries which only returned 200 over 5 days ago\n",
    "df = df[df['last_200_LIKE_response_timestamp'] < five_days_ago_timestamp].reset_index(drop=True)\n",
    "\n",
    "# Convert most_recent_status back to float\n",
    "df[\"most_recent_status\"] = df[\"most_recent_status\"].astype(float)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping Endpoints then Converting to Lists\n",
    "The `possible_duplicate_endpoints` dataframe above is grouped by organisation, collection and pipeline, all unique endpoint urls are then placed into a list so that they can be easily looped through. This is so that the csv contents of each endpoint can be compared in future, and then decide on which endpoints to keep.\n",
    "\n",
    "**N.B:** This currently includes the endpoints previously highlighted as stale.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>organisation</th>\n",
       "      <th>collection</th>\n",
       "      <th>pipeline</th>\n",
       "      <th>endpoint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>government-organisation:D303</td>\n",
       "      <td>local-authority-district</td>\n",
       "      <td>local-authority-district</td>\n",
       "      <td>[https://opendata.arcgis.com/datasets/fba7a58e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>government-organisation:D303</td>\n",
       "      <td>national-park</td>\n",
       "      <td>national-park</td>\n",
       "      <td>[https://opendata.arcgis.com/datasets/2dcdc561...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>government-organisation:D4</td>\n",
       "      <td>green-belt</td>\n",
       "      <td>green-belt</td>\n",
       "      <td>[http://maps.communities.gov.uk/geoserver/dclg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>government-organisation:D69</td>\n",
       "      <td>title-boundary</td>\n",
       "      <td>title-boundary</td>\n",
       "      <td>[https://use-land-property-data.service.gov.uk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>government-organisation:EA39</td>\n",
       "      <td>infrastructure-project</td>\n",
       "      <td>infrastructure-project</td>\n",
       "      <td>[https://raw.githubusercontent.com/digital-lan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>local-authority-eng:TON</td>\n",
       "      <td>developer-contributions</td>\n",
       "      <td>developer-agreement-transaction</td>\n",
       "      <td>[https://docs.tmbc.gov.uk/docs/S106/developer-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>local-authority-eng:WDE</td>\n",
       "      <td>developer-contributions</td>\n",
       "      <td>developer-agreement</td>\n",
       "      <td>[https://www.westdevon.gov.uk/developer-agreem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>local-authority-eng:WDE</td>\n",
       "      <td>developer-contributions</td>\n",
       "      <td>developer-agreement-contribution</td>\n",
       "      <td>[https://westdevon.gov.uk/developer-agreement-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>national-park-authority:Q72617158</td>\n",
       "      <td>developer-contributions</td>\n",
       "      <td>developer-agreement</td>\n",
       "      <td>[https://www.newforestnpa.gov.uk/app/uploads/2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>national-park-authority:Q72617158</td>\n",
       "      <td>developer-contributions</td>\n",
       "      <td>developer-agreement-transaction</td>\n",
       "      <td>[https://www.newforestnpa.gov.uk/app/uploads/2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         organisation                collection  \\\n",
       "0        government-organisation:D303  local-authority-district   \n",
       "1        government-organisation:D303             national-park   \n",
       "2          government-organisation:D4                green-belt   \n",
       "3         government-organisation:D69            title-boundary   \n",
       "4        government-organisation:EA39    infrastructure-project   \n",
       "..                                ...                       ...   \n",
       "63            local-authority-eng:TON   developer-contributions   \n",
       "64            local-authority-eng:WDE   developer-contributions   \n",
       "65            local-authority-eng:WDE   developer-contributions   \n",
       "66  national-park-authority:Q72617158   developer-contributions   \n",
       "67  national-park-authority:Q72617158   developer-contributions   \n",
       "\n",
       "                            pipeline  \\\n",
       "0           local-authority-district   \n",
       "1                      national-park   \n",
       "2                         green-belt   \n",
       "3                     title-boundary   \n",
       "4             infrastructure-project   \n",
       "..                               ...   \n",
       "63   developer-agreement-transaction   \n",
       "64               developer-agreement   \n",
       "65  developer-agreement-contribution   \n",
       "66               developer-agreement   \n",
       "67   developer-agreement-transaction   \n",
       "\n",
       "                                             endpoint  \n",
       "0   [https://opendata.arcgis.com/datasets/fba7a58e...  \n",
       "1   [https://opendata.arcgis.com/datasets/2dcdc561...  \n",
       "2   [http://maps.communities.gov.uk/geoserver/dclg...  \n",
       "3   [https://use-land-property-data.service.gov.uk...  \n",
       "4   [https://raw.githubusercontent.com/digital-lan...  \n",
       "..                                                ...  \n",
       "63  [https://docs.tmbc.gov.uk/docs/S106/developer-...  \n",
       "64  [https://www.westdevon.gov.uk/developer-agreem...  \n",
       "65  [https://westdevon.gov.uk/developer-agreement-...  \n",
       "66  [https://www.newforestnpa.gov.uk/app/uploads/2...  \n",
       "67  [https://www.newforestnpa.gov.uk/app/uploads/2...  \n",
       "\n",
       "[68 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove unnecessary columns\n",
    "df = possible_duplicate_endpoints.drop([\"most_recent_status\"], axis = 1)\n",
    "\n",
    "# Group by organisation, collection and pipeline, append the aggregated endpoint urls into a list then reset the index\n",
    "df = df.groupby([\"organisation\",\"collection\",\"pipeline\"])[\"endpoint\"].apply(list).reset_index()\n",
    "possible_duplicate_endpoints_aggregate = df\n",
    "possible_duplicate_endpoints_aggregate\n",
    "\n",
    "# This can be looped through programmatically to check the contents of the remaining endpoints to be eliminated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to download the possible_duplicate_endpoints_aggregate table? (yes/no):  no\n"
     ]
    }
   ],
   "source": [
    "download = input(\"Do you want to download the possible_duplicate_endpoints_aggregate table? (yes/no): \")\n",
    "\n",
    "if download.lower() == \"yes\":\n",
    "    possible_duplicate_endpoints_aggregate.to_csv(\"possible_duplicate_endpoints_aggregate.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
