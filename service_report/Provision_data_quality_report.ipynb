{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Provision data quality report\n",
    "**Author**:  Greg Slater <br>\n",
    "**Date**:  November 2024 <br>\n",
    "**Dataset Scope**: all datasets <br>\n",
    "**Report Type**: Ad-hoc <br>\n",
    "\n",
    "## Purpose\n",
    "The purpose of this report is to measure the quality of the data that makes up each data provision on the platform, by applying a data quality framework that sets out criteria that must be met in order to reach one of 4 different quality levels. These levels are based around the quality requirements of the ODP software which uses platform data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import os\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from datetime import datetime\n",
    "\n",
    "td = datetime.today().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILES_URL = 'https://datasette.planning.data.gov.uk/'\n",
    "\n",
    "def download_dataset(dataset, output_dir_path, overwrite=False):\n",
    "    dataset_file_name = f'{dataset}.db'\n",
    "    \n",
    "    if not os.path.exists(output_dir_path):\n",
    "        os.makedirs(output_dir_path)\n",
    "    \n",
    "    output_file_path = os.path.join(output_dir_path, dataset_file_name)\n",
    "\n",
    "    if overwrite is False and os.path.exists(output_file_path):\n",
    "        return\n",
    "    \n",
    "    final_url = os.path.join(FILES_URL, dataset_file_name)\n",
    "    print(f'downloading data from {final_url}')\n",
    "    print(f'to: {output_file_path}')\n",
    "    urllib.request.urlretrieve(final_url, os.path.join(output_dir_path, dataset_file_name))\n",
    "    print('download complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_sqlite(db_path, query_string):\n",
    "\n",
    "    with sqlite3.connect(db_path) as con:\n",
    "            \n",
    "        cursor = con.execute(query_string)\n",
    "        cols = [column[0] for column in cursor.description]\n",
    "        results_df = pd.DataFrame.from_records(data=cursor.fetchall(), columns=cols)\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def datasette_query(db, sql_string):\n",
    "    params = urllib.parse.urlencode({\n",
    "        \"sql\": sql_string,\n",
    "        \"_size\": \"max\"\n",
    "        })\n",
    "    url = f\"https://datasette.planning.data.gov.uk/{db}.csv?{params}\"\n",
    "    df = pd.read_csv(url)\n",
    "    return df\n",
    "\n",
    "def get_issue_lookup():\n",
    "    \n",
    "    q = \"\"\"\n",
    "    select issue_type, severity, responsibility\n",
    "    from issue_type\n",
    "\"\"\"\n",
    "    return datasette_query(\"digital-land\", q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_dir = \"../data/db_downloads/\"\n",
    "os.makedirs(db_dir, exist_ok=True)\n",
    "\n",
    "output_dir = \"../data/quality_report/\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download_dataset(\"performance\", db_dir, overwrite=True)\n",
    "\n",
    "lookup_issue_qual = pd.read_csv(\"https://raw.githubusercontent.com/digital-land/jupyter-analysis/refs/heads/main/service_report/input/issue_type_quality.csv\")\n",
    "\n",
    "dataset_subset_dict = dict({\n",
    "        \"ODP\" : [\"conservation-area\", \"conservation-area-document\", \"article-4-direction-area\", \"article-4-direction\", \"listed-building-outline\", \"tree\", \"tree-preservation-zone\", \"tree-preservation-order\"],\n",
    "        \"BFL\" : [\"brownfield-land\"],\n",
    "        \"Developers\" : [\"developer-agreement\", \"developer-agreement-contribution\", \"developer-agreement-transaction\"]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE TABLE\n",
    "\n",
    "# get table of active endpoints and resources, with issue summaries per resource joined on\n",
    "q = f\"\"\"\n",
    "    SELECT \n",
    "        rhe.organisation, rhe.name as organisation_name, \n",
    "        rhe.collection, rhe.pipeline, rhe.endpoint, rhe.resource, rhe.latest_status, rhe.endpoint_entry_date, rhe.resource_start_date, \n",
    "        CAST(JULIANDAY('now') - JULIANDAY(rhe.resource_start_date) AS int) as resource_age_days,\n",
    "        its.issue_type, its.count_issues, its.severity, its.responsibility\n",
    "    FROM reporting_historic_endpoints rhe\n",
    "    LEFT JOIN endpoint_dataset_issue_type_summary its on rhe.resource = its.resource\n",
    "    WHERE 1=1\n",
    "        AND rhe.endpoint_end_date = \"\"\n",
    "        AND rhe.resource_end_date = \"\"\n",
    "        AND rhe.latest_status = 200\n",
    "\"\"\"\n",
    "\n",
    "ep_res_issues = query_sqlite(os.path.join(db_dir, \"performance.db\"), q)\n",
    "\n",
    "print(len(ep_res_issues))\n",
    "ep_res_issues.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provision lookups\n",
    "\n",
    "q = f\"\"\"\n",
    "    SELECT \n",
    "        distinct organisation, pipeline, cohort\n",
    "    FROM endpoint_dataset_resource_summary\n",
    "\"\"\"\n",
    "\n",
    "# get organisation, pipeline and cohort flag from performance table\n",
    "lookup_provision = query_sqlite(os.path.join(db_dir, \"performance.db\"), q)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup base tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FRESHNESS TABLE - flagging when provisions haven't been updated in last year\n",
    "\n",
    "# create table of old resources and flag quality level as 5\n",
    "ep_res_fresh_qual = ep_res_issues[ep_res_issues[\"resource_age_days\"] > 365][[\"collection\", \"pipeline\", \"organisation\", \"organisation_name\"]]\n",
    "\n",
    "ep_res_fresh_qual[\"issue_type\"] = \"not_fresh\"\n",
    "ep_res_fresh_qual[\"quality_category\"] = \"1 - endpoint updated in last year\"\n",
    "ep_res_fresh_qual[\"quality_level\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ISSUES TABLE - flagging when provisions have data quality issues\n",
    "\n",
    "# join on quality key and restrict fields\n",
    "ep_res_issues_qual = ep_res_issues.merge(\n",
    "    lookup_issue_qual[[\"issue_type\", \"quality_category\", \"quality_level\"]],\n",
    "    how = \"left\",\n",
    "    on = \"issue_type\"\n",
    ")[[\"collection\", \"pipeline\", \"organisation\", \"organisation_name\", \"issue_type\", \"quality_category\", \"quality_level\"]]\n",
    "\n",
    "print(len(ep_res_issues))\n",
    "print(len(ep_res_issues_qual))\n",
    "\n",
    "ep_res_issues_qual.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL QUALITY CATEGORIES TABLE - joining all records of quality categories (freshness & DQ issues) into one long table \n",
    "# concat tables for each type\n",
    "ep_res_qual_all = pd.concat([ep_res_issues_qual, ep_res_fresh_qual])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCORING - using quality framework levels to assign a quality level to each provision\n",
    "\n",
    "# summarise by provision, taking max quality level for each\n",
    "qual_summary = ep_res_qual_all.groupby([\n",
    "    \"collection\", \"pipeline\", \"organisation\", \"organisation_name\"\n",
    "    ],\n",
    "as_index=False,\n",
    "dropna=False\n",
    ").agg(\n",
    "    quality_level = (\"quality_level\", \"min\")\n",
    ")\n",
    "\n",
    "qual_summary.replace(np.nan, 4, inplace=True)\n",
    "\n",
    "level_map = {\n",
    "    4: \"4. excellent\",\n",
    "    3: \"3. good for ODP\",\n",
    "    2: \"2. improve\",\n",
    "    1: \"1. update\"}\n",
    "\n",
    "qual_summary[\"quality_level_label\"] = qual_summary[\"quality_level\"].map(level_map)\n",
    "print(len(qual_summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qual_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LPA and dataset table summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ODP LPA x Dataset quality table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qual_summary\n",
    "\n",
    "lookup_provision_odp = lookup_provision[\n",
    "    lookup_provision[\"cohort\"].str.contains(\"ODP\")\n",
    "    ][[\"organisation\", \"pipeline\"]].drop_duplicates()\n",
    "\n",
    " # subset and pivot\n",
    "odp_lpa_summary = qual_summary.merge(\n",
    "    lookup_provision_odp,\n",
    "    how = \"inner\",\n",
    "    on = [\"organisation\", \"pipeline\"]\n",
    ").pivot(\n",
    "    columns = \"pipeline\",\n",
    "    values = \"quality_level_label\",\n",
    "    index = [\"organisation\", \"organisation_name\"]\n",
    ").reset_index()\n",
    "\n",
    "odp_lpa_summary.replace(np.nan, \"no data\", inplace=True)\n",
    "# odp_lpa_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_colours = {\n",
    "    \"4. excellent\" : \"background-color: #1a6837\",\n",
    "    \"3. good for ODP\" : \"background-color: #87cb67\",\n",
    "    \"2. improve\" : \"background-color: #fefebf\",\n",
    "    \"1. update\" : \"background-color: #f78c51\"\n",
    "    }\n",
    "\n",
    "\n",
    "def make_color_mask_odp_lpa(df):\n",
    "    #DataFrame with same index and columns names as original filled empty strings\n",
    "    df_color_map =  pd.DataFrame(\"\", index=df.index, columns=df.columns)\n",
    "\n",
    "    flag_slice = df.columns[2:]\n",
    "    for s in flag_slice:\n",
    "        df_color_map[s] = df[s].map(level_colours)\n",
    "\n",
    "    return df_color_map\n",
    "\n",
    "# odp_lpa_summary.style.apply(make_color_mask_odp_lpa, axis=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset x quality categories table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count issues by the quality category key\n",
    "qual_cat_count = ep_res_qual_all.groupby(\n",
    "        [\"pipeline\", \"organisation\", \"organisation_name\", \"quality_category\"],\n",
    "        as_index=False\n",
    "    ).agg(\n",
    "        n_issues = (\"quality_level\", \"count\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a base table with each quality category key for each provision\n",
    "prov = ep_res_qual_all[[\"pipeline\", \"organisation\", \"organisation_name\"]].drop_duplicates()\n",
    "prov[\"key\"] = 1\n",
    "\n",
    "qual_cat = ep_res_qual_all[ep_res_qual_all[\"quality_category\"].notnull()][[\"quality_category\"]].drop_duplicates()\n",
    "qual_cat[\"key\"] = 1\n",
    "\n",
    "qual_cat_summary = prov.merge(\n",
    "    qual_cat,\n",
    "    how = \"left\",\n",
    "    on = \"key\"\n",
    ")\n",
    "print(len(qual_cat_summary))\n",
    "\n",
    "# left join on the counts to the base table\n",
    "qual_cat_summary = qual_cat_summary.merge(\n",
    "    qual_cat_count,\n",
    "    how = \"left\",\n",
    "    on = ['pipeline', 'organisation', 'organisation_name', 'quality_category']\n",
    ")\n",
    "\n",
    "# create boolean flag for each category\n",
    "qual_cat_summary[\"issue_flag\"] = np.where(qual_cat_summary[\"n_issues\"] > 0, False, True)\n",
    "print(len(qual_cat_summary))\n",
    "# qual_cat_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot quality category summary table so that quality categories are columns, join on overall quality level per provision\n",
    "qual_cat_summary_wide = qual_cat_summary.pivot(\n",
    "        columns = \"quality_category\",\n",
    "        values = \"issue_flag\",\n",
    "        index = [\"pipeline\", \"organisation\", \"organisation_name\"]\n",
    "    ).reset_index(\n",
    "    ).merge(\n",
    "        qual_summary[[\"pipeline\", \"organisation\", \"quality_level_label\"]],\n",
    "        how = \"left\",\n",
    "        on = [\"pipeline\", \"organisation\"]\n",
    "    )\n",
    "\n",
    "def get_dataset_qual_detail(dataset):\n",
    "    # just subsets and styles main wide quality detail table\n",
    "\n",
    "    qual_detail = qual_cat_summary_wide[qual_cat_summary_wide[\"pipeline\"] == dataset].copy()\n",
    "\n",
    "    return qual_detail.style.apply(make_color_mask_dataset_lpa, axis=None)\n",
    "\n",
    "# table styling \n",
    "level_colours = {\n",
    "        \"4. excellent\" : \"background-color: #1a6837\",\n",
    "        \"3. good for ODP\" : \"background-color: #87cb67\",\n",
    "        \"2. improve\" : \"background-color: #fefebf\",\n",
    "        \"1. update\" : \"background-color: #f78c51\"\n",
    "    }\n",
    "\n",
    "flag_colours = {\n",
    "        True : \"color:green\",\n",
    "        False : \"color:red\"\n",
    "    }\n",
    "\n",
    "def make_color_mask_dataset_lpa(df):\n",
    "    #DataFrame with same index and columns names as original filled empty strings\n",
    "    df_color_map =  pd.DataFrame(\"\", index=df.index, columns=df.columns)\n",
    "    # turn label column into colours\n",
    "    df_color_map[\"quality_level_label\"] = df[\"quality_level_label\"].map(level_colours)\n",
    "\n",
    "    flag_slice = df.columns[3:-1]\n",
    "    for s in flag_slice:\n",
    "        df_color_map[s] = df[s].map(flag_colours)\n",
    "\n",
    "    return df_color_map\n",
    "\n",
    "\n",
    "# make widget\n",
    "dataset_list = qual_cat_summary[\"pipeline\"].sort_values().drop_duplicates().values\n",
    "\n",
    "dataset_dropdown = widgets.Dropdown(\n",
    "    options = dataset_list,\n",
    "    value = \"conservation-area\",\n",
    "    description = \"Select Dataset: \",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALISE\n",
    "\n",
    "# qual_summary_subset = qual_summary[qual_summary[\"pipeline\"].isin(subset_bfl)]\n",
    "# qual_summary_subset = qual_summary[qual_summary[\"pipeline\"].isin(subset_dvl)]\n",
    "\n",
    "# color map to use in chart\n",
    "cmap = plt.get_cmap('RdYlGn')\n",
    "colors = [cmap(i / 4) for i in np.arange(1, 5)]\n",
    "\n",
    "def make_quality_overview_chart(subset):\n",
    "    \"\"\"\n",
    "    Uses the qual summary table to display a horizontal bar chart \n",
    "    \"\"\"\n",
    "\n",
    "    qual_summary_subset = qual_summary[qual_summary[\"pipeline\"].isin(dataset_subset_dict[subset])]\n",
    "\n",
    "    # count providers by dataset & quality level\n",
    "    qual_chart = qual_summary_subset.groupby([\"pipeline\", \"quality_level\", \"quality_level_label\"], as_index=False).agg(\n",
    "        n_providers = (\"quality_level\", \"count\")\n",
    "    )\n",
    "\n",
    "    qual_chart.sort_values([\"pipeline\", \"quality_level_label\"], inplace=True)\n",
    "    qual_chart_wide = qual_chart.pivot(columns = \"quality_level_label\", values = \"n_providers\", index = \"pipeline\")\n",
    "    \n",
    "    qual_chart_wide.plot.barh(\n",
    "        stacked = True, \n",
    "        color = colors, \n",
    "        figsize = (9, 6))\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('Count of providers')\n",
    "    plt.ylabel('Dataset')\n",
    "    plt.title('Quality levels for ODP datasets')\n",
    "    plt.legend(title='Quality level')\n",
    "\n",
    "    return plt.show()\n",
    "\n",
    "\n",
    "subset_dropdown = widgets.Dropdown(\n",
    "    options = dataset_subset_dict.keys(),\n",
    "    # value = dataset_list[0],\n",
    "    description = \"Select Dataset subset: \",\n",
    ")\n",
    "\n",
    "# widgets.interact(make_quality_overview_chart, subset = subset_dropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data quality overview chart - by dataset groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widgets.interact(make_quality_overview_chart, subset = subset_dropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ODP LPA overview table by dataset & quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odp_lpa_summary.style.apply(make_color_mask_odp_lpa, axis=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset quality scoring detail table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widgets.interact(get_dataset_qual_detail, dataset = dataset_dropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output\n",
    "Save report files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = os.path.join(output_dir, f\"quality_ODP-dataset-scores-by-LPA_{td}.xlsx\")\n",
    "odp_lpa_summary.style.apply(make_color_mask_odp_lpa, axis=None).to_excel(fn, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = os.path.join(output_dir, f\"quality_dataset-quality-detail_{td}.csv\")\n",
    "qual_cat_summary_wide.to_csv(fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdp_jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
