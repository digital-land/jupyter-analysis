{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This report provides status information on the most recent endpoints for a hardcoded list of prioritised list of LPAs, or organisations from an input.\n",
    "\n",
    "The input should be called 'input.csv' and contain one column, 'organisation' that has the organisation codes for the LPAs to be included in the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.parse\n",
    "import os\n",
    "%pip install wget\n",
    "import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util_file = \"master_report_endpoint_utils.py\"\n",
    "if os.path.isfile(util_file):\n",
    "    from master_report_endpoint_utils import *\n",
    "else:\n",
    "    url = \"https://raw.githubusercontent.com/digital-land/jupyter-analysis/main/service_report/master_report/master_report_endpoint_utils.py\"\n",
    "    wget.download(url)\n",
    "    from master_report_endpoint_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get input from .csv or use default prioritised LPAs\n",
    "input_path = './input.csv'\n",
    "if os.path.isfile(input_path):\n",
    "    input_df = pd.read_csv(input_path)\n",
    "    organisation_list = input_df['organisation'].tolist()\n",
    "    print('Input file found. Using', len(organisation_list), 'organisations from input file.')\n",
    "else:\n",
    "    organisation_list = ['local-authority-eng:BUC', 'local-authority-eng:DAC', 'local-authority-eng:DNC',\n",
    "    'local-authority-eng:GLO', 'local-authority-eng:CMD', 'local-authority-eng:LBH', 'local-authority-eng:SWK',\n",
    "    'local-authority-eng:MDW', 'local-authority-eng:NET', 'local-authority-eng:BIR', 'local-authority-eng:CAT',\n",
    "    'local-authority-eng:EPS', 'local-authority-eng:BNE', 'local-authority-eng:GAT', 'local-authority-eng:GRY',\n",
    "    'local-authority-eng:KTT', 'local-authority-eng:SAL', 'local-authority-eng:TEW', 'local-authority-eng:WBK',\n",
    "    'local-authority-eng:DST', 'local-authority-eng:DOV', 'local-authority-eng:LIV', 'local-authority-eng:RDB',\n",
    "    'local-authority-eng:WFT', 'local-authority-eng:NLN', 'local-authority-eng:NSM', 'local-authority-eng:SLF',\n",
    "    'local-authority-eng:WRL' ]\n",
    "    print('Input file not found. Using default list of organisations.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get organisation info\n",
    "organisation_info_df = pd.read_csv('https://raw.githubusercontent.com/digital-land/organisation-collection/main/data/local-authority.csv')\n",
    "organisation_info_df.head()\n",
    "organisation_name_dict = {}\n",
    "for organisation in organisation_list:\n",
    "    organisation_code = organisation.split(':')[1]\n",
    "    organisation_name = organisation_info_df.loc[organisation_info_df['reference'] == organisation_code].iloc[0]['name']\n",
    "    organisation_name_dict[organisation] = organisation_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasette_url = \"https://datasette.planning.data.gov.uk/\"\n",
    "\n",
    "collection_list = ['article-4-direction', 'article-4-direction-area', 'conservation-area', 'conservation-area-document', 'listed-building-outline', 'tree-preservation-order', 'tree-preservation-zone', 'tree']\n",
    "pipelines_list = ['article-4-direction', 'article-4-direction-area', 'conservation-area', 'conservation-area-document', 'listed-building-outline', 'tree-preservation-order', 'tree-preservation-zone', 'tree', 'tree,tree-preservation-order', 'tree-preservation-order,tree-preservation-zone','article-4-direction,article-4-direction-area']\n",
    "all_orgs_recent_endpoints={}\n",
    "for organisation in organisation_list:\n",
    "    recent_endpoints_df = get_latest_endpoints(organisation)\n",
    "    recent_endpoints_df = recent_endpoints_df[recent_endpoints_df['pipelines'].isin(pipelines_list)]\n",
    "    all_orgs_recent_endpoints[organisation] = recent_endpoints_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "def compute_cell_colour(status):\n",
    "    if status == \"200\":\n",
    "        return 'background-color: green'\n",
    "    elif status == 'No endpoint':\n",
    "        return 'background-color: orange'\n",
    "    else:\n",
    "        return 'background-color: red'\n",
    "    \n",
    "def cut_zeros(row):\n",
    "  if row[-2:]=='.0':\n",
    "    row=row[:-2]\n",
    "  return row\n",
    "\n",
    "rows_list = []\n",
    "organisation_dataset_statuses_dict = {}\n",
    "for organisation in organisation_list:\n",
    "    latest_endpoints_df = all_orgs_recent_endpoints[organisation]\n",
    "    latest_endpoints_df = latest_endpoints_df[pd.isna(latest_endpoints_df['end_date'])]\n",
    "    try:\n",
    "        name = organisation_name_dict[organisation]\n",
    "    except:\n",
    "        name = organisation\n",
    "    \n",
    "    dataset_statuses_dict = {}\n",
    "    for index, row in latest_endpoints_df.iterrows():\n",
    "        resource = row['resource']\n",
    "        if ',' in row['pipelines']:\n",
    "            datasets = row['pipelines'].split(',')\n",
    "        else:\n",
    "            datasets = [row['pipelines']]\n",
    "        for dataset in datasets:\n",
    "            # Consider cases where a dataset is contributed to by multiple endpoints\n",
    "            same_datasets_df = recent_endpoints_df[recent_endpoints_df[\"pipelines\"].apply(lambda x: dataset in x.split(','))]\n",
    "            if len(same_datasets_df) > 1:\n",
    "                skip_dataset = handle_skip_dataset(same_datasets_df, dataset, row)\n",
    "            else:\n",
    "                skip_dataset = False\n",
    "\n",
    "            if not skip_dataset:\n",
    "                status = row['status']\n",
    "\n",
    "                # Handle cases where there is no status by looking at exceptions\n",
    "                if not pd.isna(status):\n",
    "                    status = int(status)\n",
    "                else:\n",
    "                    status=latest_endpoints_df.loc[latest_endpoints_df['status'].isna(), 'exception'].values[0]\n",
    "                    if status is None:\n",
    "                        status=\"Unknown Error\"\n",
    "                dataset_statuses_dict[dataset] = status\n",
    "    organisation_dataset_statuses_dict[organisation] = dataset_statuses_dict\n",
    "   \n",
    "    new_row = {'organisation': name}\n",
    "    new_row.update(dataset_statuses_dict)\n",
    "    rows_list.append(new_row)\n",
    "\n",
    "output_df = pd.DataFrame(rows_list, columns=['organisation', *collection_list])\n",
    "output_df = output_df.replace(np.nan, \"No endpoint\")\n",
    "\n",
    "output_df = output_df.astype(str)\n",
    "output_df = output_df.applymap(cut_zeros)\n",
    "\n",
    "output_df.to_csv('endpoint_status_master_report.csv', index=False)\n",
    "output_df.style.applymap(compute_cell_colour, subset=collection_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_columns = ['name', 'pipelines', 'endpoint_url', 'organisation', 'collection', 'maxentrydate', 'entrydate', 'end_date', 'last_status', 'last_updated_date']\n",
    "\n",
    "output_df = produce_output_csv(all_orgs_recent_endpoints, organisation_dataset_statuses_dict, \"status\", 200, output_columns)\n",
    "output_df.to_csv('endpoint_status_not_200.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
