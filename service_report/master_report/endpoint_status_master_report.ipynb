{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This report provides status information on the most recent endpoints for a hardcoded list of prioritised list of LPAs, or organisations from an input.\n",
    "\n",
    "The input should be called 'input.csv' and contain one column, 'organisation' that has the organisation codes for the LPAs to be included in the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in /home/ccoelho/DLUHC/jupyter-analysis/.venv/lib/python3.10/site-packages (3.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "import pandas as pd\n",
    "import urllib.parse\n",
    "import os\n",
    "%pip install wget\n",
    "import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "util_file = \"master_report_endpoint_utils.py\"\n",
    "if os.path.isfile(util_file):\n",
    "    from master_report_endpoint_utils import *\n",
    "else:\n",
    "    url = \"https://raw.githubusercontent.com/digital-land/jupyter-analysis/main/service_report/master_report/master_report_endpoint_utils.py\"\n",
    "    wget.download(url)\n",
    "    from master_report_endpoint_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input file not found. Using default list of organisations.\n"
     ]
    }
   ],
   "source": [
    "# Get input from .csv or use default prioritised LPAs\n",
    "input_path = './input.csv'\n",
    "if os.path.isfile(input_path):\n",
    "    input_df = pd.read_csv(input_path)\n",
    "    organisation_list = input_df['organisation'].tolist()\n",
    "    print('Input file found. Using', len(organisation_list), 'organisations from input file.')\n",
    "else:\n",
    "    organisation_list = ['local-authority-eng:BUC', 'local-authority-eng:DAC', 'local-authority-eng:DNC',\n",
    "    'local-authority-eng:GLO', 'local-authority-eng:CMD', 'local-authority-eng:LBH', 'local-authority-eng:SWK',\n",
    "    'local-authority-eng:MDW', 'local-authority-eng:NET', 'local-authority-eng:BIR', 'local-authority-eng:CAT',\n",
    "    'local-authority-eng:EPS', 'local-authority-eng:BNE', 'local-authority-eng:GAT', 'local-authority-eng:GRY',\n",
    "    'local-authority-eng:KTT', 'local-authority-eng:SAL', 'local-authority-eng:TEW', 'local-authority-eng:WBK',\n",
    "    'local-authority-eng:DST', 'local-authority-eng:DOV', 'local-authority-eng:LIV', 'local-authority-eng:RDB',\n",
    "    'local-authority-eng:WFT', 'local-authority-eng:NLN', 'local-authority-eng:NSM', 'local-authority-eng:SLF',\n",
    "    'local-authority-eng:WRL' ]\n",
    "    print('Input file not found. Using default list of organisations.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get organisation info\n",
    "organisation_info_df = pd.read_csv('https://raw.githubusercontent.com/digital-land/organisation-collection/main/data/local-authority.csv')\n",
    "organisation_info_df.head()\n",
    "organisation_name_dict = {}\n",
    "for organisation in organisation_list:\n",
    "    organisation_code = organisation.split(':')[1]\n",
    "    organisation_name = organisation_info_df.loc[organisation_info_df['reference'] == organisation_code].iloc[0]['name']\n",
    "    organisation_name_dict[organisation] = organisation_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasette_url = \"https://datasette.planning.data.gov.uk/\"\n",
    "\n",
    "def update_dataframe(organisation):\n",
    "    global result_df  \n",
    "    if organisation:\n",
    "        query = f\" s.organisation = '{organisation}'\"\n",
    "    else:\n",
    "        query = f\" s.organisation LIKE '%'\"\n",
    "    params = urllib.parse.urlencode({\n",
    "        \"sql\": f\"\"\"\n",
    "        select\n",
    "          e.endpoint_url,\n",
    "          l.status,\n",
    "          l.exception,\n",
    "          s.collection,\n",
    "          group_concat(DISTINCT sp.pipeline) as pipelines,\n",
    "          s.organisation,\n",
    "          o.name,\n",
    "          max(l.entry_date) maxentrydate,\n",
    "          max(e.entry_date) entrydate,\n",
    "          e.end_date\n",
    "        from\n",
    "          log l\n",
    "          inner join source s on l.endpoint = s.endpoint\n",
    "          inner join organisation o on s.organisation=o.organisation\n",
    "          inner join endpoint e on l.endpoint = e.endpoint\n",
    "          inner join source_pipeline sp on s.source = sp.source\n",
    "        where\n",
    "           {query} and not collection=\"brownfield-land\"\n",
    "        group by\n",
    "          l.endpoint,\n",
    "          l.status\n",
    "        order by\n",
    "          l.endpoint,\n",
    "          s.collection,\n",
    "          maxentrydate desc\n",
    "        \"\"\",\n",
    "        \"_size\": \"max\"\n",
    "    })\n",
    "    \n",
    "    url = f\"{datasette_url}digital-land.csv?{params}\"\n",
    "    df = pd.read_csv(url)\n",
    "    result_df = df\n",
    "    return df\n",
    "\n",
    "def update_dataframe_latest_status(organisation):\n",
    "    global new_df\n",
    "    all_endpoints=update_dataframe(organisation)\n",
    "    new_df=all_endpoints.copy()\n",
    "    new_df['maxentrydate'] = pd.to_datetime(new_df['maxentrydate'])\n",
    "    new_df['last_status'] = None\n",
    "    new_df['last_updated_date'] = None\n",
    "    new_df['date_last_status_200'] = None\n",
    "    \n",
    "    for index, row in new_df.iterrows():\n",
    "        if index < len(new_df) - 1 and (row['status']!=200 or pd.isna(row['status'])):\n",
    "            if row['endpoint_url'] == new_df.at[index + 1, 'endpoint_url']:\n",
    "                new_df.at[index, 'last_status'] = new_df.at[index + 1, 'status']\n",
    "                new_df.at[index, 'last_updated_date'] = new_df.at[index + 1, 'maxentrydate']   \n",
    "    \n",
    "    new_df.drop_duplicates(subset='endpoint_url', keep='first', inplace=True)\n",
    "    new_df.reset_index(drop=True, inplace=True)\n",
    "    for index, row in new_df.iterrows():\n",
    "        if row['last_status'] is not None:\n",
    "            if row['last_status'] != 200  or row['last_status'] is None:\n",
    "                filtered_df = all_endpoints[(all_endpoints['endpoint_url'] == row['endpoint_url'] ) & (all_endpoints['status'] == 200)]\n",
    "                if not filtered_df.empty:\n",
    "                    new_df.at[index, 'date_last_status_200'] = filtered_df['maxentrydate'].values[0][:19] \n",
    "    return new_df\n",
    "\n",
    "collection_list = ['article-4-direction', 'article-4-direction-area', 'conservation-area', 'conservation-area-document', 'listed-building-outline', 'tree-preservation-order', 'tree-preservation-zone', 'tree']\n",
    "pipelines_list = ['article-4-direction', 'article-4-direction-area', 'conservation-area', 'conservation-area-document', 'listed-building-outline', 'tree-preservation-order', 'tree-preservation-zone', 'tree', 'tree,tree-preservation-order', 'tree-preservation-order,tree-preservation-zone','article-4-direction,article-4-direction-area']\n",
    "all_orgs_recent_endpoints={}\n",
    "for organisation in organisation_list:\n",
    "    recent_endpoints_df = update_dataframe_latest_status(organisation)\n",
    "    recent_endpoints_df = recent_endpoints_df[recent_endpoints_df['pipelines'].isin(pipelines_list)]\n",
    "    all_orgs_recent_endpoints[organisation] = recent_endpoints_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>endpoint_url</th>\n",
       "      <th>status</th>\n",
       "      <th>exception</th>\n",
       "      <th>collection</th>\n",
       "      <th>pipelines</th>\n",
       "      <th>organisation</th>\n",
       "      <th>name</th>\n",
       "      <th>maxentrydate</th>\n",
       "      <th>entrydate</th>\n",
       "      <th>end_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://maps.buckscc.gov.uk/arcgis/services/PL...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ConnectTimeout</td>\n",
       "      <td>listed-building-outline</td>\n",
       "      <td>listed-building-outline</td>\n",
       "      <td>local-authority-eng:BUC</td>\n",
       "      <td>Buckinghamshire Council</td>\n",
       "      <td>2023-11-17T00:16:29Z</td>\n",
       "      <td>2022-05-04T16:16:06Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://maps.buckscc.gov.uk/arcgis/services/PL...</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>listed-building-outline</td>\n",
       "      <td>listed-building-outline</td>\n",
       "      <td>local-authority-eng:BUC</td>\n",
       "      <td>Buckinghamshire Council</td>\n",
       "      <td>2023-11-16T00:16:27Z</td>\n",
       "      <td>2022-05-04T16:16:06Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://raw.githubusercontent.com/digital-land...</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>design-code</td>\n",
       "      <td>design-code-area</td>\n",
       "      <td>local-authority-eng:BUC</td>\n",
       "      <td>Buckinghamshire Council</td>\n",
       "      <td>2023-11-17T00:11:54Z</td>\n",
       "      <td>2022-05-10T18:18:25Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://maps.buckscc.gov.uk/arcgis/services/PL...</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>article-4-direction-area</td>\n",
       "      <td>article-4-direction-area</td>\n",
       "      <td>local-authority-eng:BUC</td>\n",
       "      <td>Buckinghamshire Council</td>\n",
       "      <td>2023-11-17T00:15:42Z</td>\n",
       "      <td>2022-04-28T16:16:57Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://maps.buckscc.gov.uk/arcgis/services/PL...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ConnectTimeout</td>\n",
       "      <td>article-4-direction-area</td>\n",
       "      <td>article-4-direction-area</td>\n",
       "      <td>local-authority-eng:BUC</td>\n",
       "      <td>Buckinghamshire Council</td>\n",
       "      <td>2023-11-15T00:15:38Z</td>\n",
       "      <td>2022-04-28T16:16:57Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        endpoint_url  status       exception  \\\n",
       "0  https://maps.buckscc.gov.uk/arcgis/services/PL...     NaN  ConnectTimeout   \n",
       "1  https://maps.buckscc.gov.uk/arcgis/services/PL...   200.0             NaN   \n",
       "2  https://raw.githubusercontent.com/digital-land...   200.0             NaN   \n",
       "3  https://maps.buckscc.gov.uk/arcgis/services/PL...   200.0             NaN   \n",
       "4  https://maps.buckscc.gov.uk/arcgis/services/PL...     NaN  ConnectTimeout   \n",
       "\n",
       "                 collection                 pipelines  \\\n",
       "0   listed-building-outline   listed-building-outline   \n",
       "1   listed-building-outline   listed-building-outline   \n",
       "2               design-code          design-code-area   \n",
       "3  article-4-direction-area  article-4-direction-area   \n",
       "4  article-4-direction-area  article-4-direction-area   \n",
       "\n",
       "              organisation                     name          maxentrydate  \\\n",
       "0  local-authority-eng:BUC  Buckinghamshire Council  2023-11-17T00:16:29Z   \n",
       "1  local-authority-eng:BUC  Buckinghamshire Council  2023-11-16T00:16:27Z   \n",
       "2  local-authority-eng:BUC  Buckinghamshire Council  2023-11-17T00:11:54Z   \n",
       "3  local-authority-eng:BUC  Buckinghamshire Council  2023-11-17T00:15:42Z   \n",
       "4  local-authority-eng:BUC  Buckinghamshire Council  2023-11-15T00:15:38Z   \n",
       "\n",
       "              entrydate end_date  \n",
       "0  2022-05-04T16:16:06Z      NaN  \n",
       "1  2022-05-04T16:16:06Z      NaN  \n",
       "2  2022-05-10T18:18:25Z      NaN  \n",
       "3  2022-04-28T16:16:57Z      NaN  \n",
       "4  2022-04-28T16:16:57Z      NaN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_dataframe(\"local-authority-eng:BUC\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'statuses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/ccoelho/DLUHC/jupyter-analysis/service_report/endpoint_status_master_report.ipynb Cell 8\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ccoelho/DLUHC/jupyter-analysis/service_report/endpoint_status_master_report.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=48'>49</a>\u001b[0m                     status\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnknown Error\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ccoelho/DLUHC/jupyter-analysis/service_report/endpoint_status_master_report.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=49'>50</a>\u001b[0m         \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m datasets:\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ccoelho/DLUHC/jupyter-analysis/service_report/endpoint_status_master_report.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=50'>51</a>\u001b[0m             dataset_statuses_dict[i] \u001b[39m=\u001b[39m compute_status(statuses, i, status)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ccoelho/DLUHC/jupyter-analysis/service_report/endpoint_status_master_report.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ccoelho/DLUHC/jupyter-analysis/service_report/endpoint_status_master_report.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=52'>53</a>\u001b[0m     \u001b[39mif\u001b[39;00m status\u001b[39m.\u001b[39mempty:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'statuses' is not defined"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "def compute_cell_colour(status):\n",
    "    if status == 200:\n",
    "        return 'background-color: green'\n",
    "    elif status == 'No endpoint':\n",
    "        return 'background-color: orange'\n",
    "    else:\n",
    "        return 'background-color: red'\n",
    "    \n",
    "def compute_status(existing_statuses, collection, status):\n",
    "    if collection in existing_statuses:\n",
    "        if existing_statuses[collection] == 200:\n",
    "            return status\n",
    "        elif existing_statuses[collection] == 'No endpoint':\n",
    "            return status\n",
    "        else:\n",
    "            return existing_statuses[collection]\n",
    "    else:\n",
    "        return status\n",
    "\n",
    "rows_list = []\n",
    "organisation_dataset_statuses_dict = {}\n",
    "for organisation in organisation_list:\n",
    "    # organisation = \"local-authority-eng:BUC\"\n",
    "    df = all_orgs_recent_endpoints[organisation]\n",
    "    df = df[pd.isna(df['end_date'])]\n",
    "    try:\n",
    "        name = organisation_name_dict[organisation]\n",
    "    except:\n",
    "        name = organisation\n",
    "    dataset_statuses_dict = {}\n",
    "    for pipeline in pipelines_list:\n",
    "        status = df[df['pipelines'] == pipeline]['status']\n",
    "        df_datasets = pd.DataFrame(df['pipelines'], columns=[\"pipelines\"])\n",
    "        list_datasets = df_datasets['pipelines'].tolist()\n",
    "        if ',' in pipeline:\n",
    "            if pipeline in list_datasets:\n",
    "                datasets = pipeline.split(',')\n",
    "                status = pd.Series(status)\n",
    "                if status.empty or (status=='No endpoint').any():\n",
    "                    status = 'No endpoint'\n",
    "                else:\n",
    "                    if not pd.isna(status.values[0]):\n",
    "                        status = int(status.values[0])\n",
    "                    else:\n",
    "                        status=df.loc[df['status'].isna(), 'exception'].values[0]\n",
    "                        if status is None:\n",
    "                            status=\"Unknown Error\"\n",
    "                for i in datasets:\n",
    "                    dataset_statuses_dict[i] = compute_status(dataset_statuses_dict, i, status)\n",
    "        else:\n",
    "            if status.empty:\n",
    "                status = 'No endpoint'\n",
    "            else:\n",
    "                df_status = status.to_frame()\n",
    "                df_no_duplicates = df_status.drop_duplicates()\n",
    "                df_filtered = df_no_duplicates[df_no_duplicates['status'] != 200]\n",
    "                if df_filtered.size>0:\n",
    "                    if not pd.isna(df_filtered.iloc[0, 0]):\n",
    "                        status=int(df_filtered.iloc[0, 0])\n",
    "                    else:\n",
    "                        status=df.loc[df['status'].isna(), 'exception'].values[0]\n",
    "                        if status is None:\n",
    "                            status=\"Unknown Error\"\n",
    "                else:\n",
    "                    status=200\n",
    "            dataset_statuses_dict[pipeline] = compute_status(dataset_statuses_dict, pipeline, status)\n",
    "    organisation_dataset_statuses_dict[organisation] = dataset_statuses_dict\n",
    "    new_row = {'organisation': name}\n",
    "    new_row.update(dataset_statuses_dict)\n",
    "    rows_list.append(new_row)\n",
    "\n",
    "output_df = pd.DataFrame(rows_list, columns=['organisation', *collection_list])\n",
    "output_df.to_csv('endpoint_status_master_report.csv', index=False)\n",
    "output_df.style.applymap(compute_cell_colour, subset=collection_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_columns = ['name', 'pipelines', 'endpoint_url', 'organisation', 'collection', 'maxentrydate', 'entrydate', 'end_date', 'last_status', 'last_updated_date']\n",
    "\n",
    "output_df = produce_output_csv(all_orgs_recent_endpoints, orga, \"issues\", \"No issues\", output_columns)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
