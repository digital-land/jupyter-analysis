{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install wget\n",
    "import wget\n",
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util_file = \"master_report_endpoint_utils.py\"\n",
    "if os.path.isfile(util_file):\n",
    "    from master_report_endpoint_utils import *\n",
    "else:\n",
    "    url = \"https://raw.githubusercontent.com/digital-land/jupyter-analysis/main/service_report/master_report/master_report_endpoint_utils.py\"\n",
    "    wget.download(url)\n",
    "    from master_report_endpoint_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_columns_in_endpoint(fields, dataset_field_df, column_field_df, dataset):\n",
    "    dataset_columns = dataset_field_df['field'].tolist()\n",
    "    dataset_columns = remove_assigned_columns(dataset, dataset_columns)\n",
    "    \n",
    "    missing_columns = []\n",
    "    present_columns = []\n",
    "    for column in dataset_columns:\n",
    "        if column not in fields:\n",
    "            missing_columns.append(column)\n",
    "        else:\n",
    "            present_columns.append(column)\n",
    "    structure_score = f\"{len(dataset_columns) - len(missing_columns)}/{len(dataset_columns)}\"\n",
    "    structure_percentage = (len(dataset_columns) - len(missing_columns)) / len(dataset_columns) * 100\n",
    "\n",
    "    filtered_columns = [\"WKT\"]\n",
    "    column_field_df = column_field_df[-column_field_df['column'].isin(filtered_columns)]\n",
    "\n",
    "    mapped_fields = column_field_df['field'].tolist()\n",
    "    correct_column_names = 0\n",
    "    for field in present_columns:\n",
    "        if field not in mapped_fields:\n",
    "            correct_column_names += 1\n",
    "    \n",
    "\n",
    "    if len(column_field_df.index) == 0:\n",
    "        column_score = \"0/0\"\n",
    "        column_percentage = 0\n",
    "        return structure_score, structure_percentage, column_score, column_percentage\n",
    "    column_score = f\"{correct_column_names}/{len(dataset_columns)}\"\n",
    "    column_percentage = (correct_column_names)/ len(dataset_columns)*100\n",
    "   \n",
    "    return structure_score, structure_percentage, column_score, column_percentage\n",
    "\n",
    "\n",
    "def get_fields_for_resource(resource, dataset):\n",
    "    datasette_url = \"https://datasette.planning.data.gov.uk/\"\n",
    "    params = urllib.parse.urlencode({\n",
    "        \"sql\": f\"\"\"\n",
    "        select f.field \n",
    "        from \n",
    "            fact_resource fr\n",
    "            inner join fact f on fr.fact = f.fact\n",
    "        where \n",
    "            resource = '{resource}'\n",
    "        group by\n",
    "            f.field\n",
    "        \"\"\",\n",
    "        \"_size\": \"max\"\n",
    "    })\n",
    "    url = f\"{datasette_url}{dataset}.csv?{params}\"\n",
    "    facts_df = pd.read_csv(url)\n",
    "    facts_list = facts_df['field'].tolist()\n",
    "    return facts_list\n",
    "\n",
    "def get_column_mappings_for_resource(resource, dataset):\n",
    "    datasette_url = \"https://datasette.planning.data.gov.uk/\"\n",
    "    params = urllib.parse.urlencode({\n",
    "        \"sql\": f\"\"\"\n",
    "        select column, field\n",
    "        from \n",
    "          column_field  \n",
    "        where \n",
    "            resource = '{resource}'\n",
    "        \"\"\",\n",
    "        \"_size\": \"max\"\n",
    "    })\n",
    "    url = f\"{datasette_url}{dataset}.csv?{params}\"\n",
    "    column_field_df = pd.read_csv(url)\n",
    "    return column_field_df\n",
    "\n",
    "def remove_assigned_columns(dataset, dataset_columns):\n",
    "    dataset_columns.remove('entity')\n",
    "    dataset_columns.remove('organisation')\n",
    "    dataset_columns.remove('prefix')\n",
    "    dataset_columns.remove('entry-date')\n",
    "    if dataset != \"tree\" and \"point\" in dataset_columns:\n",
    "        dataset_columns.remove('point')\n",
    "    return dataset_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get input from .csv or use default prioritised LPAs\n",
    "input_path = './organisation_input.csv'\n",
    "if os.path.isfile(input_path):\n",
    "    input_df = pd.read_csv(input_path)\n",
    "    organisation_list = input_df['organisation'].tolist()\n",
    "    print('Input file found. Using', len(organisation_list), 'organisations from input file.')\n",
    "else:\n",
    "    organisation_list = [\n",
    "    'local-authority-eng:BUC', \n",
    "    'local-authority-eng:DAC', 'local-authority-eng:DNC',\n",
    "    'local-authority-eng:GLO', 'local-authority-eng:CMD', 'local-authority-eng:LBH', 'local-authority-eng:SWK',\n",
    "    'local-authority-eng:MDW', 'local-authority-eng:NET', 'local-authority-eng:BIR', 'local-authority-eng:CAT',\n",
    "    'local-authority-eng:EPS', 'local-authority-eng:BNE', 'local-authority-eng:GAT', 'local-authority-eng:GRY',\n",
    "    'local-authority-eng:KTT', 'local-authority-eng:SAL', 'local-authority-eng:TEW', 'local-authority-eng:WBK',\n",
    "    'local-authority-eng:DST', 'local-authority-eng:DOV', 'local-authority-eng:LIV', 'local-authority-eng:RDB',\n",
    "    'local-authority-eng:WFT', 'local-authority-eng:NLN', 'local-authority-eng:NSM', 'local-authority-eng:SLF',\n",
    "    'local-authority-eng:WRL' ]\n",
    "    print('Input file not found. Using default list of organisations.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get organisation names for output table\n",
    "organisation_info_df = pd.read_csv('https://raw.githubusercontent.com/digital-land/organisation-collection/main/data/local-authority.csv')\n",
    "organisation_info_df.head()\n",
    "organisation_name_dict = {}\n",
    "for organisation in organisation_list:\n",
    "    organisation_code = organisation.split(':')[1]\n",
    "    organisation_name = organisation_info_df.loc[organisation_info_df['reference'] == organisation_code].iloc[0]['name']\n",
    "    organisation_name_dict[organisation] = organisation_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasette_url = \"https://datasette.planning.data.gov.uk/\"\n",
    "\n",
    "# Collect latest endpoints for each organisation\n",
    "collection_list = ['article-4-direction', 'article-4-direction-area', 'conservation-area', 'conservation-area-document', 'listed-building-outline', 'tree-preservation-order', 'tree-preservation-zone', 'tree']\n",
    "pipelines_list = ['article-4-direction', 'article-4-direction-area', 'conservation-area', 'conservation-area-document', 'listed-building-outline', 'tree-preservation-order', 'tree-preservation-zone', 'tree', 'tree,tree-preservation-order', 'tree-preservation-order,tree-preservation-zone']\n",
    "all_orgs_latest_endpoints={}\n",
    "for organisation in organisation_list:\n",
    "    latest_endpoints_df = get_latest_endpoints(organisation)\n",
    "    latest_endpoints_df = latest_endpoints_df[latest_endpoints_df['pipelines'].isin(pipelines_list)]\n",
    "    all_orgs_latest_endpoints[organisation] = latest_endpoints_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cell_colour(value):\n",
    "    if \"%\" in value:\n",
    "        value = int(value.replace(\"%\", \"\"))\n",
    "        if value >= 75:\n",
    "            return 'background-color: green'\n",
    "        elif value < 75 and value >= 50:\n",
    "            return 'background-color: orange'\n",
    "        elif 0 <= value < 50:\n",
    "            return 'background-color: red'\n",
    "        else:\n",
    "            return 'background-color: brown'\n",
    "\n",
    "organisation_dataset_compliance_dict={}\n",
    "rows_list = []\n",
    "for organisation in organisation_list:\n",
    "    latest_endpoints_df = all_orgs_latest_endpoints[organisation]\n",
    "    dataset_compliance_dict = {}\n",
    "    for index, row in latest_endpoints_df.iterrows():\n",
    "        resource = row['resource']\n",
    "        if ',' in row['pipelines']:\n",
    "            datasets = row['pipelines'].split(',')\n",
    "        else:\n",
    "            datasets = [row['pipelines']]\n",
    "        for dataset in datasets:\n",
    "            same_datasets_df = latest_endpoints_df[latest_endpoints_df[\"pipelines\"].apply(lambda x: dataset in x.split(','))]\n",
    "            if len(same_datasets_df) > 1:\n",
    "                skip_dataset = handle_skip_dataset(same_datasets_df, dataset, row)\n",
    "            else:\n",
    "                skip_dataset = False\n",
    "            print(organisation, dataset, resource)\n",
    "\n",
    "            dataset_field_df = pd.read_csv('https://raw.githubusercontent.com/digital-land/specification/main/specification/dataset-field.csv')\n",
    "            dataset_field_df = dataset_field_df[dataset_field_df['dataset'] == dataset]\n",
    "\n",
    "            if not skip_dataset:\n",
    "                column_field_df = get_column_mappings_for_resource(resource, dataset)\n",
    "                fields = get_fields_for_resource(resource, dataset)\n",
    "                structure_score, structure_percentage, column_score, column_percentage = check_columns_in_endpoint(fields, dataset_field_df, column_field_df, dataset)\n",
    "                overall_percentage = (structure_percentage + column_percentage) / 2\n",
    "                dataset_compliance_dict[dataset] = {\"structure_score\": structure_score, \"structure_percentage\": structure_percentage, \"column_score\": column_score, \"column_percentage\": column_percentage}\n",
    "                new_row = {'organisation': organisation_name_dict[organisation], 'dataset': dataset, 'structure_score': structure_score, 'structure_percentage': f\"{int(structure_percentage)}%\" , 'column_name_score': column_score, 'column_name_percentage': f\"{int(column_percentage)}%\", 'overall_percentage': f\"{int(overall_percentage)}%\"}\n",
    "                rows_list.append(new_row)\n",
    "    \n",
    "    organisation_dataset_compliance_dict[organisation] = dataset_compliance_dict\n",
    "\n",
    "\n",
    "compliance_df = pd.DataFrame(rows_list)\n",
    "compliance_df.to_csv('compliance.csv', index=False)\n",
    "compliance_df.head(100)\n",
    "compliance_df.style.applymap(compute_cell_colour, subset=[\"structure_percentage\", \"column_percentage\", \"overall_percentage\"])\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
