{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00dc14ed",
   "metadata": {},
   "source": [
    "# List of endpoints(404s) failing since last 5 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5395a434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib\n",
    "from datetime import date\n",
    "import urllib.parse\n",
    "import matplotlib \n",
    "\n",
    "datasette_url = \"https://datasette.planning.data.gov.uk/\"\n",
    "\n",
    "params = urllib.parse.urlencode({\n",
    "    \"sql\": f\"\"\"\n",
    "     SELECT l.endpoint, l.status, l.exception, s.collection, s.organisation, l.entry_date\n",
    "  FROM log l\n",
    "  inner join source s\n",
    "    on l.endpoint = s.endpoint where\n",
    "   l.entry_date >= DATE('now', '-5 day')\n",
    "   and l.status = '404'\n",
    "   and s.collection = 'brownfield-land'\n",
    "   GROUP BY l.endpoint\n",
    "HAVING COUNT(DISTINCT l.entry_date) >= 5\n",
    "order by s.organisation\n",
    "\n",
    "    \"\"\",\n",
    "    \"_size\": \"max\"\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "url = f\"{datasette_url}digital-land.csv?{params}\"\n",
    "df = pd.read_csv(url)\n",
    "print(\"\\033[1m List of endpoints failing consecutively since more than 5 days\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441871e5",
   "metadata": {},
   "source": [
    "# Organisation of Failed endpoints and finding out if that organisation has other latest endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095137ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Organisation of Failed endpoints and finding out if that organisation has other latest endpoints\n",
    "#organisations = ', '.join([f'\"{organisation}\"' for organisation in df['organisation']])\n",
    "\n",
    "params = urllib.parse.urlencode({\n",
    "    \"sql\": f\"\"\"\n",
    "    SELECT s.collection, s.endpoint, s.end_date, s.organisation, s.source, MAX(s.entry_date) AS latest_entry_date, l.status, l.entry_date\n",
    "FROM source s\n",
    "INNER JOIN log l ON s.endpoint = l.endpoint\n",
    "WHERE s.organisation IN (\n",
    "    SELECT s2.organisation\n",
    "    FROM log l2\n",
    "    INNER JOIN source s2 ON l2.endpoint = s2.endpoint\n",
    "    WHERE l2.entry_date >= DATE('now', '-5 day')\n",
    "    AND l2.status = '404'\n",
    "    AND s2.collection = 'brownfield-land'\n",
    "    GROUP BY l2.endpoint\n",
    "    HAVING COUNT(DISTINCT l2.entry_date) >= 5\n",
    ")\n",
    "AND s.collection = 'brownfield-land'\n",
    "and s.end_date = '' and l.entry_date >= DATE('now', '-5 day')\n",
    "GROUP BY s.organisation\n",
    "    HAVING COUNT(DISTINCT l.entry_date) >= 5\n",
    "\n",
    "    \"\"\",\n",
    "    \"_size\": \"max\"\n",
    "})\n",
    "\n",
    "url = f\"{datasette_url}digital-land.csv?{params}\"\n",
    "df = pd.read_csv(url)\n",
    "print(\"\\033[1m \")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9b081a",
   "metadata": {},
   "outputs": [],
   "source": [
    "download = input(\"Do you want to download the result? (yes/no): \")\n",
    "\n",
    "if download.lower() == \"yes\":\n",
    "    # Save the DataFrame as a CSV file\n",
    "    df.to_csv(\"query_result.csv\", index=False)\n",
    "    print(\"Query result downloaded as 'query_result.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba48a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[df['status'] == 404]\n",
    "filtered_df\n",
    "\n",
    "#local-authority-eng:CHS -- older date endpoint are passing and newly added endpoint is failing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e20cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "download = input(\"Do you want to download the result? (yes/no): \")\n",
    "\n",
    "if download.lower() == \"yes\":\n",
    "    # Save the DataFrame as a CSV file\n",
    "    filtered_df.to_csv(\"endpoint_failing_result.csv\", index=False)\n",
    "    print(\"Query result downloaded as 'endpoint_failing_result.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b9344f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
