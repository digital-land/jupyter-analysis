{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This report provides status information on the most recent endpoints for a hardcoded list of prioritised list of LPAs, or organisations from an input.\n",
    "\n",
    "The input should be called 'input.csv' and contain one column, 'organisation' that has the organisation codes for the LPAs to be included in the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "from IPython.display import display\n",
    "import urllib\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "import requests\n",
    "import urllib.parse\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input file not found. Using default list of organisations.\n"
     ]
    }
   ],
   "source": [
    "# Get input from .csv or use default prioritised LPAs\n",
    "input_path = './input.csv'\n",
    "if os.path.isfile(input_path):\n",
    "    input_df = pd.read_csv(input_path)\n",
    "    organisation_list = input_df['organisation'].tolist()\n",
    "    print('Input file found. Using', len(organisation_list), 'organisations from input file.')\n",
    "else:\n",
    "    organisation_list = ['local-authority-eng:BUC', 'local-authority-eng:DAC', 'local-authority-eng:DNC',\n",
    "    'local-authority-eng:GLO', 'local-authority-eng:CMD', 'local-authority-eng:LBH', 'local-authority-eng:SWK',\n",
    "    'local-authority-eng:MDW', 'local-authority-eng:NET', 'local-authority-eng:BIR', 'local-authority-eng:CAT',\n",
    "    'local-authority-eng:EPS', 'local-authority-eng:BNE', 'local-authority-eng:GAT', 'local-authority-eng:GRY',\n",
    "    'local-authority-eng:KTT', 'local-authority-eng:SAL', 'local-authority-eng:TEW', 'local-authority-eng:WBK',\n",
    "    'local-authority-eng:DST', 'local-authority-eng:DOV', 'local-authority-eng:LIV', 'local-authority-eng:RDB',\n",
    "    'local-authority-eng:WFT', 'local-authority-eng:NLN', 'local-authority-eng:NSM', 'local-authority-eng:SLF',\n",
    "    'local-authority-eng:WRL' ]\n",
    "    print('Input file not found. Using default list of organisations.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get organisation info\n",
    "organisation_info_df = pd.read_csv('https://raw.githubusercontent.com/digital-land/organisation-collection/main/data/local-authority.csv')\n",
    "organisation_info_df.head()\n",
    "organisation_name_dict = {}\n",
    "for organisation in organisation_list:\n",
    "    organisation_code = organisation.split(':')[1]\n",
    "    organisation_name = organisation_info_df.loc[organisation_info_df['reference'] == organisation_code].iloc[0]['name']\n",
    "    organisation_name_dict[organisation] = organisation_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasette_url = \"https://datasette.planning.data.gov.uk/\"\n",
    "\n",
    "def update_dataframe(organisation):\n",
    "    global result_df  \n",
    "    if organisation:\n",
    "        query = f\" s.organisation = '{organisation}'\"\n",
    "    else:\n",
    "        query = f\" s.organisation LIKE '%'\"\n",
    "    params = urllib.parse.urlencode({\n",
    "        \"sql\": f\"\"\"\n",
    "        select\n",
    "          e.endpoint_url,\n",
    "          l.status,\n",
    "          s.collection,\n",
    "          group_concat(DISTINCT sp.pipeline) as pipelines,\n",
    "          s.organisation,\n",
    "          o.name,\n",
    "          max(l.entry_date) maxentrydate,\n",
    "          max(e.entry_date) entrydate,\n",
    "          e.end_date\n",
    "        from\n",
    "          log l\n",
    "          inner join source s on l.endpoint = s.endpoint\n",
    "          inner join organisation o on s.organisation=o.organisation\n",
    "          inner join endpoint e on l.endpoint = e.endpoint\n",
    "          inner join source_pipeline sp on s.source = sp.source\n",
    "        where\n",
    "           {query} and not collection=\"brownfield-land\"\n",
    "        group by\n",
    "          l.endpoint,\n",
    "          l.status\n",
    "        order by\n",
    "          l.endpoint,\n",
    "          s.collection,\n",
    "          maxentrydate desc\n",
    "        \"\"\",\n",
    "        \"_size\": \"max\"\n",
    "    })\n",
    "    \n",
    "    url = f\"{datasette_url}digital-land.csv?{params}\"\n",
    "    df = pd.read_csv(url)\n",
    "    result_df = df\n",
    "    return df\n",
    "\n",
    "def update_dataframe_latest_status(organisation):\n",
    "    global new_df\n",
    "    all_endpoints=update_dataframe(organisation)\n",
    "    new_df=all_endpoints.copy()\n",
    "    new_df['maxentrydate'] = pd.to_datetime(new_df['maxentrydate'])\n",
    "    new_df['last_status'] = None\n",
    "    new_df['last_updated_date'] = None\n",
    "    new_df['date_last_status_200'] = None\n",
    "    \n",
    "    for index, row in new_df.iterrows():\n",
    "        if index < len(new_df) - 1 and (row['status']!=200 or pd.isna(row['status'])):\n",
    "            if row['endpoint_url'] == new_df.at[index + 1, 'endpoint_url']:\n",
    "                new_df.at[index, 'last_status'] = new_df.at[index + 1, 'status']\n",
    "                new_df.at[index, 'last_updated_date'] = new_df.at[index + 1, 'maxentrydate']   \n",
    "    \n",
    "    new_df.drop_duplicates(subset='endpoint_url', keep='first', inplace=True)\n",
    "    new_df.reset_index(drop=True, inplace=True)\n",
    "    for index, row in new_df.iterrows():\n",
    "        if row['last_status'] is not None:\n",
    "            if row['last_status'] != 200  or row['last_status'] is None:\n",
    "                filtered_df = all_endpoints[(all_endpoints['endpoint_url'] == row['endpoint_url'] ) & (all_endpoints['status'] == 200)]\n",
    "                if not filtered_df.empty:\n",
    "                    new_df.at[index, 'date_last_status_200'] = filtered_df['maxentrydate'].values[0][:19] \n",
    "    return new_df\n",
    "\n",
    "collection_list = ['article-4-direction', 'article-4-direction-area', 'conservation-area', 'conservation-area-document', 'listed-building-outline', 'tree-preservation-order', 'tree-preservation-zone', 'tree']\n",
    "pipelines_list = ['article-4-direction', 'article-4-direction-area', 'conservation-area', 'conservation-area-document', 'listed-building-outline', 'tree-preservation-order', 'tree-preservation-zone', 'tree', 'tree,tree-preservation-order', 'tree-preservation-order,tree-preservation-zone']\n",
    "all_orgs_recent_endpoints={}\n",
    "for organisation in organisation_list:\n",
    "    recent_endpoints_df = update_dataframe_latest_status(organisation)\n",
    "    recent_endpoints_df = recent_endpoints_df[recent_endpoints_df['pipelines'].isin(pipelines_list)]\n",
    "    all_orgs_recent_endpoints[organisation] = recent_endpoints_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Styler' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/ccoelho/DLUHC/jupyter-analysis/master_report.ipynb Cell 6\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ccoelho/DLUHC/jupyter-analysis/master_report.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=49'>50</a>\u001b[0m output_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(rows_list, columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39morganisation\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m*\u001b[39mcollection_list])\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ccoelho/DLUHC/jupyter-analysis/master_report.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=50'>51</a>\u001b[0m output_df \u001b[39m=\u001b[39m output_df\u001b[39m.\u001b[39mstyle\u001b[39m.\u001b[39mapplymap(compute_cell_colour, subset\u001b[39m=\u001b[39mcollection_list)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ccoelho/DLUHC/jupyter-analysis/master_report.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=51'>52</a>\u001b[0m output_df\u001b[39m.\u001b[39;49mhead()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Styler' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "def compute_cell_colour(status):\n",
    "    if status == 200:\n",
    "        return 'background-color: green'\n",
    "    elif status == 'No endpoint':\n",
    "        return 'background-color: orange'\n",
    "    else:\n",
    "        return 'background-color: red'\n",
    "    \n",
    "def compute_status(existing_statuses, collection, status):\n",
    "    if collection in existing_statuses:\n",
    "        if existing_statuses[collection] == 200:\n",
    "            return status\n",
    "        elif existing_statuses[collection] == 'No endpoint':\n",
    "            return status\n",
    "        else:\n",
    "            return existing_statuses[collection]\n",
    "    else:\n",
    "        return status\n",
    "\n",
    "rows_list = []\n",
    "for organisation in organisation_list:\n",
    "    df = all_orgs_recent_endpoints[organisation]\n",
    "    try:\n",
    "        name = organisation_name_dict[organisation]\n",
    "    except:\n",
    "        name = organisation\n",
    "    statuses = {}\n",
    "    for collection in pipelines_list:\n",
    "        status = df[df['pipelines'] == collection]['status']\n",
    "        if ',' in collection:\n",
    "            datasets = collection.split(',')\n",
    "            if status.empty or pd.isna(status.values[0]):\n",
    "                status = 'No endpoint'\n",
    "            else:\n",
    "                status = int(status.values[0])\n",
    "            for i in datasets:\n",
    "                statuses[i] = compute_status(statuses, i, status)\n",
    "        else:\n",
    "            if status.empty or pd.isna(status.values[0]):\n",
    "                status = 'No endpoint'\n",
    "            else:\n",
    "                status = int(status.values[0])\n",
    "            statuses[collection] = compute_status(statuses, collection, status)\n",
    "    new_row = {'organisation': name}\n",
    "    new_row.update(statuses)\n",
    "    rows_list.append(new_row)\n",
    "\n",
    "output_df = pd.DataFrame(rows_list, columns=['organisation', *collection_list])\n",
    "output_df.style.applymap(compute_cell_colour, subset=collection_list)\n",
    "output_df.to_csv('endpoint_status_master_report.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
