{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Provision data quality report\n",
    "**Author**:  Greg Slater <br>\n",
    "**Date**:  November 2024 <br>\n",
    "**Dataset Scope**: all datasets <br>\n",
    "**Report Type**: Ad-hoc <br>\n",
    "\n",
    "**Purpose**: The purpose of this report is to measure the quality of the data that makes up each data provision on the platform, by applying a data quality framework that sets out criteria that must be met in order to reach one of 4 different quality levels. These levels are based around the quality requirements of the ODP software which uses platform data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import os\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from datetime import datetime\n",
    "import wget\n",
    "\n",
    "td = datetime.today().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_util_file(file_name):\n",
    "\n",
    "    if os.path.isfile(file_name) == False:\n",
    "        url = f\"https://raw.githubusercontent.com/digital-land/jupyter-analysis/refs/heads/gs/qual-report-v2/{file_name}\"\n",
    "        wget.download(url)\n",
    "        print(f\"downloaded {file_name} from github\")\n",
    "\n",
    "    else:\n",
    "        print(\"file available locally\")\n",
    "\n",
    "for f in [\"functions_core.py\", \"functions_import.py\", \"functions_transform.py\"]:\n",
    "    save_util_file(f)\n",
    "\n",
    "import functions_core as fc\n",
    "import functions_import as fi\n",
    "import functions_transform as ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_dir = \"../../data/db_downloads/\"\n",
    "os.makedirs(db_dir, exist_ok=True)\n",
    "\n",
    "output_dir = \"../../data/quality_report/\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance db\n",
    "fc.download_dataset(\"performance\", db_dir, overwrite=True)\n",
    "path_perf_db = os.path.join(db_dir, \"performance.db\")\n",
    "\n",
    "# Issue quality criteria lookup\n",
    "lookup_issue_qual = pd.read_csv(\"https://raw.githubusercontent.com/digital-land/jupyter-analysis/refs/heads/main/service_report/input/issue_type_quality.csv\")\n",
    "\n",
    "# Provision lookups\n",
    "lookup_provision_odp = fi.get_odp_provision_lookup()\n",
    "lookup_provision_odp.rename(columns={\"dataset\" : \"pipeline\"}, inplace=True)\n",
    "\n",
    "\n",
    "# Dataset subset dict for chart\n",
    "dataset_subset_dict = dict({\n",
    "        \"ODP\" : [\"conservation-area\", \"conservation-area-document\", \"article-4-direction-area\", \"article-4-direction\", \"listed-building-outline\", \"tree\", \"tree-preservation-zone\", \"tree-preservation-order\"],\n",
    "        \"BFL\" : [\"brownfield-land\"],\n",
    "        \"Developers\" : [\"developer-agreement\", \"developer-agreement-contribution\", \"developer-agreement-transaction\"]\n",
    "    })\n",
    "\n",
    "# Base table\n",
    "ep_res_issues = fi.get_endpoint_res_issues(path_perf_db)\n",
    "\n",
    "\n",
    "# Below is all extra for adding in the conservation-area authoritative or not checks\n",
    "# ---------------------------------------------------------------------------------------------------------\n",
    "# Organisation lookups\n",
    "lookup_org = fi.get_organisation_lookup()\n",
    "lookup_org[[\"lpa_flag\", \"organisation_entity\"]] = lookup_org[[\"lpa_flag\", \"organisation_entity\"]].astype(int)\n",
    "\n",
    "# Conservation area dataset - for non-auth issues\n",
    "ca_gdf = fc.get_pdp_dataset(\"conservation-area\", \"point\")\n",
    "ca_gdf[[\"organisation_entity\"]] = ca_gdf[[\"organisation_entity\"]].astype(int)\n",
    "\n",
    "# LPA boundaries\n",
    "lpa_gdf = fc.get_pdp_dataset(\"local-planning-authority\", \"geometry\")\n",
    "\n",
    "# conservation area manual counts\n",
    "ca_count_df = pd.read_csv(\"https://raw.githubusercontent.com/digital-land/conservation-area-data/refs/heads/main/data/conservation-area-count.csv\")\n",
    "ca_count_df.columns = [x.replace(\"-\", \"_\") for x in ca_count_df.columns]\n",
    "ca_count_df[[\"organisation_entity\"]] = ca_count_df[[\"organisation_entity\"]].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note - need to improve the base table setup here.\n",
    "Currently the endpoint & resource base is any live endpoints with live resources. This captures a lot of provisions, but will miss instances where we have data for a provision from endpoints which have been erroring for a long time or have been ended. E.g. `national-park-authority:Q20198711` BFL endpoint has been erroring for a long time so it doesn't have a live resource, but we could take the most recent valid resource.\n",
    "\n",
    "This is also causing issues with not having total LPA coverage for some datasets. e.g. there are only 61 conservation-area provisions in endpoint table, but we actually have data from LPAs in 78 LPAs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort out CA and LPA tables for joining\n",
    "\n",
    "# rename for easier joining\n",
    "lpa_gdf.rename(\n",
    "    columns = {\n",
    "        'name':'lpa_name',\n",
    "        'reference':'LPACD'\n",
    "    }, \n",
    "        inplace=True)\n",
    "\n",
    "# restrict LPAs to un-ended ones and join on organisation field\n",
    "lpa_live_gdf = lpa_gdf[[\"LPACD\", \"geometry\"]].merge(\n",
    "    lookup_org[lookup_org[\"end_date\"].isnull()][[\"LPACD\", \"organisation\", \"organisation_name\", \"organisation_entity\"]],\n",
    "    how = \"inner\",\n",
    "    on = \"LPACD\"\n",
    ")\n",
    "\n",
    "# set up base table - will now include LPAs with no data, and outer join keeps in non-LPA provided dataset\n",
    "base = lpa_live_gdf[[\"LPACD\", \"organisation\"]].merge(\n",
    "    ep_res_issues,\n",
    "    how = \"outer\",\n",
    "    on = \"organisation\"\n",
    ")\n",
    "\n",
    "# add lpa flag field to ca_gdf - used to calculate provenance\n",
    "ca_gdf = ca_gdf.merge(\n",
    "    lookup_org[[\"organisation_entity\", \"organisation_name\", \"lpa_flag\"]],\n",
    "    how = \"left\",\n",
    "    on = \"organisation_entity\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROVENANCE TABLE - flagging when conservation-area provisions are from alternative sources\n",
    "\n",
    "qual_prov = ft.make_ca_provenance_issues_table(lpa_live_gdf, ca_gdf)\n",
    "\n",
    "# CA MATCH CHECK TABLE - flagging when conservation-area counts per LPA don't match manual count\n",
    "\n",
    "qual_match = ft.make_ca_count_match_issues_table(lpa_live_gdf, ca_gdf, ca_count_df)\n",
    "\n",
    "\n",
    "# ISSUES TABLE - flagging when provisions have data quality issues\n",
    "\n",
    "qual_issues = ft.make_issues_input_table(base, lookup_issue_qual)\n",
    "\n",
    "\n",
    "# # FRESHNESS TABLE - flagging when provisions haven't been updated in last year - not included in quality framework for now\n",
    "\n",
    "# # create table of old resources and flag quality level as 5\n",
    "# ep_res_fresh_qual = ft.make_freshness_input_table(ep_res_issues, age_days = 365)\n",
    "\n",
    "\n",
    "# ALL QUALITY CATEGORIES TABLE - joining all records of quality categories (freshness & DQ issues) into one long table \n",
    "# concat tables for each type\n",
    "qual_all = pd.concat([qual_prov, qual_match, qual_issues])\n",
    "qual_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # store functions & arguments that return quality calculation data as a list of tuples \n",
    "# qual_calc_functions = [\n",
    "#     (ft.make_freshness_input_table, [ep_res_issues, 365]),\n",
    "#     (ft.make_issues_input_table, [ep_res_issues, lookup_issue_qual])\n",
    "# ]\n",
    "\n",
    "# tables = [func(*args) for func, args in qual_calc_functions if isinstance(func(*args), pd.DataFrame)]\n",
    "# print(len(tables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_map = {\n",
    "    4: \"4. data that is trustworthy\",\n",
    "    3: \"3. data that is good for ODP\",\n",
    "    2: \"2. authoritative data from the LPA\",\n",
    "    1: \"1. some data\"}\n",
    "\n",
    "\n",
    "qual_summary = ft.make_score_summary_table(qual_all, level_map)\n",
    "print(len(qual_summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Summarise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ODP LPA x Dataset quality table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qual_summary\n",
    "\n",
    "# subset and pivot\n",
    "odp_lpa_summary = qual_summary.merge(\n",
    "    lookup_provision_odp,\n",
    "    how = \"inner\",\n",
    "    on = [\"organisation\", \"pipeline\"]\n",
    ")\n",
    "\n",
    "odp_lpa_summary_wide = odp_lpa_summary.pivot(\n",
    "    columns = \"pipeline\",\n",
    "    values = \"quality_level_label\",\n",
    "    index = [\"cohort\", \"organisation\", \"organisation_name\"]\n",
    ").reset_index(\n",
    ").sort_values(\n",
    "    [\"cohort\", \"organisation_name\"]\n",
    ")\n",
    "\n",
    "odp_lpa_summary_wide.replace(np.nan, \"0. no data\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ready_for_odp_calc = qual_summary[qual_summary[\"pipeline\"].isin(\n",
    "    [\"article-4-direction-area\", \"conservation-area\", \"listed-building-outline\", \"tree\", \"tree-preservation-zone\"]\n",
    "    )].groupby(\n",
    "    [\"organisation\"], as_index=False\n",
    ").agg(\n",
    "    area_dataset_count = (\"pipeline\", \"count\"),\n",
    "    min_quality_level = (\"quality_level\", \"min\")\n",
    ")\n",
    "\n",
    "ready_for_odp_calc[\"ready_for_ODP\"] = np.where(\n",
    "    (ready_for_odp_calc[\"area_dataset_count\"] == 5) &\n",
    "    (ready_for_odp_calc[\"min_quality_level\"] >= 3),\n",
    "    \"yes\", \"no\"\n",
    ")\n",
    "\n",
    "odp_lpa_summary_wide = odp_lpa_summary_wide.merge(\n",
    "    ready_for_odp_calc[[\"organisation\", \"ready_for_ODP\"]],\n",
    "    how = \"left\",\n",
    "    on = \"organisation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_colours = {\n",
    "    \"4. data that is trustworthy\" : \"background-color: #1a6837\",\n",
    "    \"3. data that is good for ODP\" : \"background-color: #87cb67\",\n",
    "    \"2. authoritative data from the LPA\" : \"background-color: #fefebf\",\n",
    "    \"1. some data\" : \"background-color: #f78c51\"\n",
    "    }\n",
    "\n",
    "ready_flag_colours = {\n",
    "        \"yes\" : \"color:green\"\n",
    "    }\n",
    "\n",
    "def make_color_mask_odp_lpa(df):\n",
    "    #DataFrame with same index and columns names as original filled empty strings\n",
    "    df_color_map =  pd.DataFrame(\"\", index=df.index, columns=df.columns)\n",
    "\n",
    "    flag_slice = df.columns[2:-1]\n",
    "    for s in flag_slice:\n",
    "        df_color_map[s] = df[s].map(level_colours)\n",
    "\n",
    "    df_color_map[\"ready_for_ODP\"] = df[\"ready_for_ODP\"].map(ready_flag_colours)\n",
    "\n",
    "    return df_color_map\n",
    "\n",
    "# make_color_mask_odp_lpa(odp_lpa_summary)\n",
    "# odp_lpa_summary.style.apply(make_color_mask_odp_lpa, axis=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset x quality categories table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count issues by the quality category key\n",
    "qual_cat_count = qual_all.groupby(\n",
    "        [\"pipeline\", \"organisation\", \"organisation_name\", \"quality_category\"],\n",
    "        as_index=False\n",
    "    ).agg(\n",
    "        n_issues = (\"quality_level\", \"count\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a base table with each quality category key for each provision\n",
    "prov = qual_all[[\"pipeline\", \"organisation\", \"organisation_name\"]].drop_duplicates()\n",
    "prov[\"key\"] = 1\n",
    "\n",
    "qual_cat = qual_all[qual_all[\"quality_category\"].notnull()][[\"quality_category\"]].drop_duplicates()\n",
    "qual_cat[\"key\"] = 1\n",
    "\n",
    "qual_cat_summary = prov.merge(\n",
    "    qual_cat,\n",
    "    how = \"left\",\n",
    "    on = \"key\"\n",
    ")\n",
    "print(len(qual_cat_summary))\n",
    "\n",
    "# left join on the counts to the base table\n",
    "qual_cat_summary = qual_cat_summary.merge(\n",
    "    qual_cat_count,\n",
    "    how = \"left\",\n",
    "    on = ['pipeline', 'organisation', 'organisation_name', 'quality_category']\n",
    ")\n",
    "\n",
    "# create boolean flag for each category\n",
    "qual_cat_summary[\"issue_flag\"] = np.where(qual_cat_summary[\"n_issues\"] > 0, False, True)\n",
    "print(len(qual_cat_summary))\n",
    "# qual_cat_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot quality category summary table so that quality categories are columns, join on overall quality level per provision\n",
    "qual_cat_summary_wide = qual_cat_summary.pivot(\n",
    "        columns = \"quality_category\",\n",
    "        values = \"issue_flag\",\n",
    "        index = [\"pipeline\", \"organisation\", \"organisation_name\"]\n",
    "    ).reset_index(\n",
    "    ).merge(\n",
    "        qual_summary[[\"pipeline\", \"organisation\", \"quality_level_label\"]],\n",
    "        how = \"left\",\n",
    "        on = [\"pipeline\", \"organisation\"]\n",
    "    )\n",
    "\n",
    "def get_dataset_qual_detail(dataset):\n",
    "    # just subsets and styles main wide quality detail table\n",
    "\n",
    "    qual_detail = qual_cat_summary_wide[qual_cat_summary_wide[\"pipeline\"] == dataset].copy()\n",
    "\n",
    "    return qual_detail.style.apply(make_color_mask_dataset_lpa, axis=None)\n",
    "\n",
    "\n",
    "flag_colours = {\n",
    "        True : \"color:green\",\n",
    "        False : \"color:red\"\n",
    "    }\n",
    "\n",
    "def make_color_mask_dataset_lpa(df):\n",
    "    #DataFrame with same index and columns names as original filled empty strings\n",
    "    df_color_map =  pd.DataFrame(\"\", index=df.index, columns=df.columns)\n",
    "    # turn label column into colours\n",
    "    df_color_map[\"quality_level_label\"] = df[\"quality_level_label\"].map(level_colours)\n",
    "\n",
    "    flag_slice = df.columns[3:-1]\n",
    "    for s in flag_slice:\n",
    "        df_color_map[s] = df[s].map(flag_colours)\n",
    "\n",
    "    return df_color_map\n",
    "\n",
    "\n",
    "# make widget\n",
    "dataset_list = qual_cat_summary[\"pipeline\"].sort_values().drop_duplicates().values\n",
    "\n",
    "dataset_dropdown = widgets.Dropdown(\n",
    "    options = dataset_list,\n",
    "    value = \"conservation-area\",\n",
    "    description = \"Select Dataset: \",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALISE\n",
    "\n",
    "# color map to use in chart\n",
    "cmap = plt.get_cmap('RdYlGn')\n",
    "colors = [cmap(i / 4) for i in np.arange(1, 5)]\n",
    "\n",
    "def make_quality_overview_chart(subset):\n",
    "    \"\"\"\n",
    "    Uses the qual summary table to display a horizontal bar chart \n",
    "    \"\"\"\n",
    "\n",
    "    qual_summary_subset = qual_summary[qual_summary[\"pipeline\"].isin(dataset_subset_dict[subset])]\n",
    "\n",
    "    # count providers by dataset & quality level\n",
    "    qual_chart = qual_summary_subset.groupby([\"pipeline\", \"quality_level\", \"quality_level_label\"], as_index=False).agg(\n",
    "        n_providers = (\"quality_level\", \"count\")\n",
    "    )\n",
    "\n",
    "    qual_chart.sort_values([\"pipeline\", \"quality_level_label\"], inplace=True)\n",
    "    qual_chart_wide = qual_chart.pivot(columns = \"quality_level_label\", values = \"n_providers\", index = \"pipeline\")\n",
    "    \n",
    "    qual_chart_wide.plot.barh(\n",
    "        stacked = True, \n",
    "        color = colors, \n",
    "        figsize = (9, 6))\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('Count of providers')\n",
    "    plt.ylabel('Dataset')\n",
    "    plt.title('Quality levels for ODP datasets')\n",
    "    plt.legend(title='Quality level')\n",
    "\n",
    "    return plt.show()\n",
    "\n",
    "\n",
    "subset_dropdown = widgets.Dropdown(\n",
    "    options = dataset_subset_dict.keys(),\n",
    "    # value = dataset_list[0],\n",
    "    description = \"Select Dataset subset: \",\n",
    ")\n",
    "\n",
    "# widgets.interact(make_quality_overview_chart, subset = subset_dropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Present"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data quality overview chart - by dataset groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widgets.interact(make_quality_overview_chart, subset = subset_dropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ODP LPA overview table by dataset & quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odp_lpa_summary_wide.style.apply(make_color_mask_odp_lpa, axis=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset quality scoring detail table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widgets.interact(get_dataset_qual_detail, dataset = dataset_dropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output\n",
    "Save report files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = os.path.join(output_dir, f\"quality_ODP-dataset-scores-by-LPA_{td}.xlsx\")\n",
    "odp_lpa_summary.style.apply(make_color_mask_odp_lpa, axis=None).to_excel(fn, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = os.path.join(output_dir, f\"quality_dataset-quality-detail_{td}.csv\")\n",
    "qual_cat_summary_wide.to_csv(fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdp_jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
