{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Provision data quality report\n",
    "**Author**:  Greg Slater <br>\n",
    "**Date**:  November 2024 <br>\n",
    "**Dataset Scope**: ODP datasets <br>\n",
    "**Report Type**: Ad-hoc <br>\n",
    "\n",
    "**Purpose**: The purpose of this report is to measure the quality of the data that makes up each data provision on the platform, by applying a data quality framework that sets out criteria that must be met in order to reach one of 4 different quality levels. These levels are based around the quality requirements of the ODP software which uses platform data.\n",
    "\n",
    "Note: the datasets included in this report are active resources of active endpoints. So where we have retired endpoints we may have data for a provision still appearing on the platform but it will not appear in this report. This means in the \"Dataset quality scoring detail\" table not all ODP provisions are present, 68 compared to 73. This is because there are 5 ODP providers where we don't have endpoints or HE conservation-area data, so there are no issues to display.\n",
    "\n",
    "Future improvements:\n",
    "* Error handling. Queries not working may break bits of the report. Not very high priority while report is more of a POC.\n",
    "* Base tables. Expand summaries to full ODP provision, including where no data at all. This could be done by switching the `qual_cat_summary` table to be constructed from a base of the provision table, rather than `qual_all` (which only includes provisions with quality issues).\n",
    "* Adding more quality checks. This depends on more checks going live in issues or expectations tables, but once they are should be easy to add extra criteria checks through the `qual_` table structure.\n",
    "* Include data from old endpoints. This will need re-working of the base table query (from `fi.get_endpoint_res_issues()`) to include old endpoints and resources. Though this will add complexity to work out which are the \"latest\" endpoints and resources to include, especially for provisions with multiple endpoints. May be low priority.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data quality framework  \n",
    "The table below visualises the framework that is used to assign a quality level to each ODP data provision. \n",
    "\n",
    "The criteria marked as \"true\" at each level must be met by a data provision in order for it to be scored at that level. The levels are cumulative, so all criteria must be met in order for a provision to be scored as *data that is trustworthy*. Where we have data from alternative providers (e.g. Historic England conservation-area data) the first criteria cannot be met so it is scored as the first quality level, *some data*.\n",
    "\n",
    "![quality framework table](quality-framework-table.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from datetime import datetime\n",
    "\n",
    "td = datetime.today().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_util_file(file_name):\n",
    "\n",
    "    if os.path.isfile(file_name) == False:\n",
    "        url = f\"https://raw.githubusercontent.com/digital-land/jupyter-analysis/refs/heads/main/service_report/quality_report/{file_name}\"\n",
    "        !wget {url}\n",
    "        print(f\"downloaded {file_name} from github\")\n",
    "\n",
    "    else:\n",
    "        print(\"file available locally\")\n",
    "\n",
    "for f in [\"functions_core.py\", \"functions_import.py\", \"functions_transform.py\"]:\n",
    "    save_util_file(f)\n",
    "\n",
    "import functions_core as fc\n",
    "import functions_import as fi\n",
    "import functions_transform as ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_dir = \"../../data/db_downloads/\"\n",
    "os.makedirs(db_dir, exist_ok=True)\n",
    "\n",
    "output_dir = \"../../data/quality_report/\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance db\n",
    "fc.download_dataset(\"performance\", db_dir, overwrite=True)\n",
    "path_perf_db = os.path.join(db_dir, \"performance.db\")\n",
    "\n",
    "# Issue quality criteria lookup\n",
    "lookup_issue_qual = pd.read_csv(\"https://raw.githubusercontent.com/digital-land/jupyter-analysis/refs/heads/main/service_report/input/issue_type_quality.csv\")\n",
    "\n",
    "# Provision lookups\n",
    "lookup_provision_odp = fi.get_odp_provision_lookup()\n",
    "lookup_provision_odp.rename(columns={\"dataset\" : \"pipeline\"}, inplace=True)\n",
    "\n",
    "\n",
    "# Dataset subset dict for chart\n",
    "dataset_subset_dict = dict({\n",
    "        \"ODP\" : [\"conservation-area\", \"conservation-area-document\", \"article-4-direction-area\", \"article-4-direction\", \"listed-building-outline\", \"tree\", \"tree-preservation-zone\", \"tree-preservation-order\"],\n",
    "        \"BFL\" : [\"brownfield-land\"],\n",
    "        \"Developers\" : [\"developer-agreement\", \"developer-agreement-contribution\", \"developer-agreement-transaction\"]\n",
    "    })\n",
    "\n",
    "# Base table\n",
    "ep_res_issues = fi.get_endpoint_res_issues(path_perf_db)\n",
    "\n",
    "\n",
    "# Below is all extra for adding in the conservation-area authoritative or not checks\n",
    "# ---------------------------------------------------------------------------------------------------------\n",
    "# Organisation lookups\n",
    "lookup_org = fi.get_organisation_lookup()\n",
    "lookup_org[[\"lpa_flag\", \"organisation_entity\"]] = lookup_org[[\"lpa_flag\", \"organisation_entity\"]].astype(int)\n",
    "\n",
    "# Conservation area dataset - for non-auth issues\n",
    "ca_gdf = fc.get_pdp_dataset(\"conservation-area\", \"point\")\n",
    "ca_gdf[[\"organisation_entity\"]] = ca_gdf[[\"organisation_entity\"]].astype(int)\n",
    "\n",
    "# LPA boundaries\n",
    "lpa_gdf = fc.get_pdp_dataset(\"local-planning-authority\", \"geometry\")\n",
    "\n",
    "# conservation area manual counts\n",
    "ca_count_df = pd.read_csv(\"https://raw.githubusercontent.com/digital-land/conservation-area-data/refs/heads/main/data/conservation-area-count.csv\")\n",
    "ca_count_df.columns = [x.replace(\"-\", \"_\") for x in ca_count_df.columns]\n",
    "ca_count_df[[\"organisation_entity\"]] = ca_count_df[[\"organisation_entity\"]].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort out CA and LPA tables for joining\n",
    "\n",
    "# rename for easier joining\n",
    "lpa_gdf.rename(\n",
    "    columns = {\n",
    "        'name':'lpa_name',\n",
    "        'reference':'LPACD'\n",
    "    }, \n",
    "        inplace=True)\n",
    "\n",
    "# restrict LPAs to un-ended ones and join on organisation field\n",
    "lpa_live_gdf = lpa_gdf[[\"LPACD\", \"geometry\"]].merge(\n",
    "    lookup_org[lookup_org[\"end_date\"].isnull()][[\"LPACD\", \"organisation\", \"organisation_name\", \"organisation_entity\"]],\n",
    "    how = \"inner\",\n",
    "    on = \"LPACD\"\n",
    ")\n",
    "\n",
    "# set up base table - will now include LPAs with no data, and outer join keeps in non-LPA provided dataset\n",
    "base = lpa_live_gdf[[\"LPACD\", \"organisation\"]].merge(\n",
    "    ep_res_issues,\n",
    "    how = \"outer\",\n",
    "    on = \"organisation\"\n",
    ")\n",
    "\n",
    "# add lpa flag field to ca_gdf - used to calculate provenance\n",
    "ca_gdf = ca_gdf.merge(\n",
    "    lookup_org[[\"organisation_entity\", \"organisation_name\", \"lpa_flag\"]],\n",
    "    how = \"left\",\n",
    "    on = \"organisation_entity\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROVENANCE TABLE - flagging when conservation-area provisions are from alternative sources\n",
    "\n",
    "qual_prov = ft.make_ca_provenance_issues_table(lpa_live_gdf, ca_gdf)\n",
    "\n",
    "# CA MATCH CHECK TABLE - flagging when conservation-area counts per LPA don't match manual count\n",
    "\n",
    "qual_match = ft.make_ca_count_match_issues_table(lpa_live_gdf, ca_gdf, ca_count_df)\n",
    "\n",
    "\n",
    "# ISSUES TABLE - flagging when provisions have data quality issues\n",
    "\n",
    "qual_issues = ft.make_issues_input_table(base, lookup_issue_qual)\n",
    "\n",
    "\n",
    "# # FRESHNESS TABLE - flagging when provisions haven't been updated in last year - not included in quality framework for now\n",
    "\n",
    "# # create table of old resources and flag quality level as 5\n",
    "# ep_res_fresh_qual = ft.make_freshness_input_table(ep_res_issues, age_days = 365)\n",
    "\n",
    "\n",
    "# ALL QUALITY CATEGORIES TABLE - joining all records of quality categories (freshness & DQ issues) into one long table \n",
    "# concat tables for each type\n",
    "qual_all = pd.concat([qual_prov, qual_match, qual_issues])\n",
    "# qual_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # store functions & arguments that return quality calculation data as a list of tuples \n",
    "# qual_calc_functions = [\n",
    "#     (ft.make_freshness_input_table, [ep_res_issues, 365]),\n",
    "#     (ft.make_issues_input_table, [ep_res_issues, lookup_issue_qual])\n",
    "# ]\n",
    "\n",
    "# tables = [func(*args) for func, args in qual_calc_functions if isinstance(func(*args), pd.DataFrame)]\n",
    "# print(len(tables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_map = {\n",
    "    4: \"4. data that is trustworthy\",\n",
    "    3: \"3. data that is good for ODP\",\n",
    "    2: \"2. authoritative data from the LPA\",\n",
    "    1: \"1. some data\"}\n",
    "\n",
    "\n",
    "qual_summary = ft.make_score_summary_table(qual_all, level_map)\n",
    "print(len(qual_summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Summarise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ODP LPA x Dataset quality table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# subset to ODP and pivot\n",
    "odp_lpa_summary = qual_summary.merge(\n",
    "    lookup_provision_odp[[\"organisation\", \"pipeline\", \"cohort\"]],\n",
    "    how = \"inner\",\n",
    "    on = [\"organisation\", \"pipeline\"]\n",
    ")\n",
    "\n",
    "odp_lpa_summary_wide = odp_lpa_summary.pivot(\n",
    "    columns = \"pipeline\",\n",
    "    values = \"quality_level_label\",\n",
    "    index = [\"cohort\", \"organisation\", \"organisation_name\"]\n",
    ").reset_index(\n",
    ").sort_values(\n",
    "    [\"cohort\", \"organisation_name\"]\n",
    ")\n",
    "\n",
    "odp_lpa_summary_wide.replace(np.nan, \"0. no data\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flag whether LPAs are \"ready for ODP\" (must have at least quality level 3 for all geography datasets)\n",
    "# count and min quality of geography datasets for each provider\n",
    "ready_for_odp_calc = qual_summary[qual_summary[\"pipeline\"].isin(\n",
    "    [\"article-4-direction-area\", \"conservation-area\", \"listed-building-outline\", \"tree\", \"tree-preservation-zone\"]\n",
    "    )].groupby(\n",
    "    [\"organisation\"], as_index=False\n",
    ").agg(\n",
    "    area_dataset_count = (\"pipeline\", \"count\"),\n",
    "    min_quality_level = (\"quality_level\", \"min\")\n",
    ")\n",
    "\n",
    "# add flag - count == 5 means all datasets must be provided\n",
    "ready_for_odp_calc[\"ready_for_ODP_adoption\"] = np.where(\n",
    "    (ready_for_odp_calc[\"area_dataset_count\"] == 5) &\n",
    "    (ready_for_odp_calc[\"min_quality_level\"] >= 2),\n",
    "    \"yes\", \"no\"\n",
    ")\n",
    "\n",
    "# add flag to summary wide table\n",
    "odp_lpa_summary_wide = odp_lpa_summary_wide.merge(\n",
    "    ready_for_odp_calc[[\"organisation\", \"ready_for_ODP_adoption\"]],\n",
    "    how = \"left\",\n",
    "    on = \"organisation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_background_colours = {\n",
    "    \"4. data that is trustworthy\" : \"background-color: #1a6837\",\n",
    "    \"3. data that is good for ODP\" : \"background-color: #87cb67\",\n",
    "    \"2. authoritative data from the LPA\" : \"background-color: #fefebf\",\n",
    "    \"1. some data\" : \"background-color: #f78c51\"\n",
    "    }\n",
    "\n",
    "ready_flag_colours = {\n",
    "        \"yes\" : \"color:green\"\n",
    "    }\n",
    "\n",
    "def make_color_mask_odp_lpa(df):\n",
    "    #DataFrame with same index and columns names as original filled empty strings\n",
    "    df_color_map =  pd.DataFrame(\"\", index=df.index, columns=df.columns)\n",
    "\n",
    "    flag_slice = df.columns[2:-1]\n",
    "    for s in flag_slice:\n",
    "        df_color_map[s] = df[s].map(level_background_colours)\n",
    "\n",
    "    df_color_map[\"ready_for_ODP_adoption\"] = df[\"ready_for_ODP_adoption\"].map(ready_flag_colours)\n",
    "\n",
    "    return df_color_map\n",
    "\n",
    "# make_color_mask_odp_lpa(odp_lpa_summary)\n",
    "# odp_lpa_summary.style.apply(make_color_mask_odp_lpa, axis=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset x quality categories table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count issues by the quality category \n",
    "qual_cat_count = qual_all.groupby(\n",
    "        [\"pipeline\", \"organisation\", \"organisation_name\", \"quality_category\"],\n",
    "        as_index=False\n",
    "    ).agg(\n",
    "        n_issues = (\"quality_level\", \"count\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a base table with each quality category for each provision - this is so it can be pivoted correctly with all categories included\n",
    "prov = qual_all[[\"pipeline\", \"organisation\", \"organisation_name\"]].drop_duplicates()\n",
    "prov[\"key\"] = 1\n",
    "\n",
    "qual_cat = qual_all[qual_all[\"quality_category\"].notnull()][[\"quality_category\"]].drop_duplicates()\n",
    "qual_cat[\"key\"] = 1\n",
    "\n",
    "qual_cat_summary = prov.merge(\n",
    "    qual_cat,\n",
    "    how = \"left\",\n",
    "    on = \"key\"\n",
    ")\n",
    "print(len(qual_cat_summary))\n",
    "\n",
    "# left join on the counts to the base table\n",
    "qual_cat_summary = qual_cat_summary.merge(\n",
    "    qual_cat_count,\n",
    "    how = \"left\",\n",
    "    on = ['pipeline', 'organisation', 'organisation_name', 'quality_category']\n",
    ")\n",
    "\n",
    "# create boolean flag for each category\n",
    "qual_cat_summary[\"issue_flag\"] = np.where(qual_cat_summary[\"n_issues\"] > 0, False, True)\n",
    "print(len(qual_cat_summary))\n",
    "# qual_cat_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot quality category summary table so that quality categories are columns, join on overall quality level per provision\n",
    "qual_cat_summary_wide = qual_cat_summary.pivot(\n",
    "        columns = \"quality_category\",\n",
    "        values = \"issue_flag\",\n",
    "        index = [\"pipeline\", \"organisation\", \"organisation_name\"]\n",
    "    ).reset_index(\n",
    "    ).merge(\n",
    "        qual_summary[[\"pipeline\", \"organisation\", \"quality_level_label\"]],\n",
    "        how = \"left\",\n",
    "        on = [\"pipeline\", \"organisation\"]\n",
    "    )\n",
    "\n",
    "def get_dataset_qual_detail(dataset):\n",
    "    # just subsets and styles main wide quality detail table\n",
    "\n",
    "    qual_detail = qual_cat_summary_wide[qual_cat_summary_wide[\"pipeline\"] == dataset].copy()\n",
    "\n",
    "    return qual_detail.style.apply(make_color_mask_dataset_lpa, axis=None)\n",
    "\n",
    "\n",
    "flag_colours = {\n",
    "        True : \"color:green\",\n",
    "        False : \"color:red\"\n",
    "    }\n",
    "\n",
    "def make_color_mask_dataset_lpa(df):\n",
    "    #DataFrame with same index and columns names as original filled empty strings\n",
    "    df_color_map =  pd.DataFrame(\"\", index=df.index, columns=df.columns)\n",
    "    # turn label column into colours\n",
    "    df_color_map[\"quality_level_label\"] = df[\"quality_level_label\"].map(level_background_colours)\n",
    "\n",
    "    flag_slice = df.columns[3:-1]\n",
    "    for s in flag_slice:\n",
    "        df_color_map[s] = df[s].map(flag_colours)\n",
    "\n",
    "    return df_color_map\n",
    "\n",
    "\n",
    "# make widget\n",
    "\n",
    "dataset_dropdown = widgets.Dropdown(\n",
    "    options = dataset_subset_dict[\"ODP\"],\n",
    "    value = \"article-4-direction\",\n",
    "    description = \"Select Dataset: \",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ODP quality maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_colours = {\n",
    "    \"4. data that is trustworthy\" : \"#1a6837\",\n",
    "    \"3. data that is good for ODP\" : \"#87cb67\",\n",
    "    \"2. authoritative data from the LPA\" : \"#fefebf\",\n",
    "    \"1. some data\" : \"#f78c51\",\n",
    "    \"0. no data\" : \"#eaeaea\"\n",
    "}\n",
    "\n",
    "def map_odp_quality_scores(dataset):\n",
    "\n",
    "    map_score = lpa_live_gdf.merge(\n",
    "        qual_summary[qual_summary[\"pipeline\"] == dataset][[\"LPACD\", \"pipeline\", \"quality_level_label\"]],\n",
    "        how = \"left\",\n",
    "        on = \"LPACD\"\n",
    "    )\n",
    "\n",
    "    map_score[\"quality_level_label\"] = map_score[\"quality_level_label\"].replace(np.nan, \"0. no data\")\n",
    "    map_score[\"colour\"] = map_score[\"quality_level_label\"].map(level_colours)\n",
    "    map_score[\"geometry\"] = map_score[\"geometry\"].simplify(0.001)\n",
    "\n",
    "    m = map_score.explore(\n",
    "        tiles = \"CartoDB positron\",  # use \"CartoDB positron\" tiles\n",
    "        popup = [\"organisation_name\", \"pipeline\", \"quality_level_label\"],  # add in field names to show in popups\n",
    "        tooltip = False,\n",
    "        color = map_score[\"colour\"]\n",
    "    )\n",
    "\n",
    "    return display(m)\n",
    "\n",
    "\n",
    "# make widget\n",
    "odp_dataset_list = dataset_subset_dict[\"ODP\"]\n",
    "\n",
    "odp_dataset_dropdown = widgets.Dropdown(\n",
    "    options = odp_dataset_list,\n",
    "    value = \"conservation-area\",\n",
    "    description = \"Select Dataset: \",\n",
    ")\n",
    "# map_odp_quality_scores(\"tree\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALISE\n",
    "\n",
    "# color map to use in chart\n",
    "cmap = plt.get_cmap('RdYlGn')\n",
    "colors = [cmap(i / 4) for i in np.arange(1, 5)]\n",
    "\n",
    "def make_quality_overview_chart(subset):\n",
    "    \"\"\"\n",
    "    Uses the qual summary table to display a horizontal bar chart \n",
    "    \"\"\"\n",
    "\n",
    "    qual_summary_subset = qual_summary[qual_summary[\"pipeline\"].isin(dataset_subset_dict[subset])]\n",
    "\n",
    "    # count providers by dataset & quality level\n",
    "    qual_chart = qual_summary_subset.groupby([\"pipeline\", \"quality_level\", \"quality_level_label\"], as_index=False).agg(\n",
    "        n_providers = (\"quality_level\", \"count\")\n",
    "    )\n",
    "\n",
    "    qual_chart.sort_values([\"pipeline\", \"quality_level_label\"], inplace=True)\n",
    "    qual_chart_wide = qual_chart.pivot(columns = \"quality_level_label\", values = \"n_providers\", index = \"pipeline\")\n",
    "    \n",
    "    qual_chart_wide.plot.barh(\n",
    "        stacked = True, \n",
    "        color = colors, \n",
    "        figsize = (9, 6))\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('Count of providers')\n",
    "    plt.ylabel('Dataset')\n",
    "    plt.title('Quality levels for ODP datasets')\n",
    "    plt.legend(title='Quality level')\n",
    "\n",
    "    return plt.show()\n",
    "\n",
    "\n",
    "subset_dropdown = widgets.Dropdown(\n",
    "    options = [\"ODP\"],\n",
    "    # value = dataset_list[0],\n",
    "    description = \"Select Dataset subset: \",\n",
    ")\n",
    "\n",
    "# widgets.interact(make_quality_overview_chart, subset = subset_dropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Present"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data quality overview chart - by dataset groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widgets.interact(make_quality_overview_chart, subset = subset_dropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data quality overview map - for ODP datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widgets.interact(map_odp_quality_scores, dataset = odp_dataset_dropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ODP LPA overview table by dataset & quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odp_lpa_summary_wide.style.apply(make_color_mask_odp_lpa, axis=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset quality scoring detail table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widgets.interact(get_dataset_qual_detail, dataset = dataset_dropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output\n",
    "Save report files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = os.path.join(output_dir, f\"quality_ODP-dataset-scores-by-LPA_{td}.xlsx\")\n",
    "odp_lpa_summary_wide.style.apply(make_color_mask_odp_lpa, axis=None).to_excel(fn, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = os.path.join(output_dir, f\"quality_dataset-quality-detail_{td}.csv\")\n",
    "qual_cat_summary_wide.to_csv(fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdp_jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
