{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import pandas as pd\n",
    "import shapely.wkt\n",
    "from shapely.geometry import shape\n",
    "from shapely.errors import WKTReadingError\n",
    "from shapely.geometry import Point\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_organisations():\n",
    "    params = urllib.parse.urlencode({\n",
    "        \"sql\": f\"\"\"\n",
    "        select organisation, name, entity as organisation_entity, statistical_geography\n",
    "        from organisation\n",
    "        \"\"\",\n",
    "        \"_size\": \"max\"\n",
    "        })\n",
    "    url = f\"https://datasette.planning.data.gov.uk/digital-land.csv?{params}\"\n",
    "    df = pd.read_csv(url)\n",
    "    return df\n",
    "\n",
    "def get_la_district_json(lpa_ref):\n",
    "    params = urllib.parse.urlencode({\n",
    "        \"sql\": f\"\"\"\n",
    "        select json\n",
    "        from entity\n",
    "        where reference = '{lpa_ref}'\n",
    "        \"\"\",\n",
    "        \"_size\": \"max\"\n",
    "        })\n",
    "    url = f\"https://datasette.planning.data.gov.uk/entity.csv?{params}\"\n",
    "    df = pd.read_csv(url)\n",
    "    try:\n",
    "        return df.loc[0,\"json\"]\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "def get_brownfield_sites_for_organisation(organisation_entity_number):\n",
    "    params = urllib.parse.urlencode({\n",
    "        \"sql\": f\"\"\"\n",
    "        select json, point, reference, organisation_entity\n",
    "        from entity\n",
    "        where organisation_entity = '{organisation_entity_number}'\n",
    "        \"\"\",\n",
    "        \"_size\": \"max\"\n",
    "        })\n",
    "    url = f\"https://datasette.planning.data.gov.uk/brownfield-land.csv?{params}\"\n",
    "    df = pd.read_csv(url)\n",
    "    return df\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_LPA_multipolygon(reference):\n",
    "    params = urllib.parse.urlencode({\n",
    "        \"sql\": f\"\"\"\n",
    "        select geometry\n",
    "        from entity\n",
    "        where reference = '{reference}'\n",
    "        \"\"\",\n",
    "        \"_size\": \"max\"\n",
    "        })\n",
    "    url = f\"https://datasette.planning.data.gov.uk/entity.csv?{params}\"\n",
    "    df = pd.read_csv(url)\n",
    "    try:\n",
    "        return df.loc[0,\"geometry\"]\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "def get_site_point(collection_name, entity_number):\n",
    "    params = urllib.parse.urlencode({\n",
    "        \"sql\": f\"\"\"\n",
    "        select point\n",
    "        from entity\n",
    "        where entity = '{entity_number}'\n",
    "        \"\"\",\n",
    "        \"_size\": \"max\"\n",
    "        })\n",
    "    url = f\"https://datasette.planning.data.gov.uk/{collection_name}.csv?{params}\"\n",
    "    df = pd.read_csv(url)\n",
    "    return df.loc[0,\"point\"]\n",
    "\n",
    "def parse_wkt(value):\n",
    "    try:\n",
    "        geometry = shapely.wkt.loads(value)\n",
    "    except WKTReadingError:\n",
    "        try:\n",
    "            geometry = shapely.wkt.loads(shape(json.loads(value)).wkt)\n",
    "            return geometry, \"invalid type geojson\"\n",
    "        except Exception:\n",
    "            return None, \"invalid WKT\"\n",
    "    return geometry, None\n",
    "\n",
    "\n",
    "def make_point(point):\n",
    "    if point.geom_type == \"Point\":\n",
    "        return Point(point)\n",
    "    else:\n",
    "        print(\"Not a point\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "\n",
    "collection=\"brownfield_land\"\n",
    "df_lpa = get_all_organisations()\n",
    "df_brownfield_sites_outside_lpa = pd.DataFrame(columns=[\"reference\", \"organisation\", \"organisation_name\", \"point\", \"google_maps_link\", \"admin_district\"])\n",
    "for lpa in df_lpa.itertuples():\n",
    "    df_brownfield_sites = get_brownfield_sites_for_organisation(lpa.organisation_entity)\n",
    "    df_brownfield_sites = df_brownfield_sites.merge(df_lpa, left_on=\"organisation_entity\", right_on=\"organisation_entity\")\n",
    "    # display(df_brownfield_sites.head())\n",
    "    if (\"local-authority-eng\" in lpa.organisation):\n",
    "        #store the last 3 characters of lpa.organisation\n",
    "        # la_district_ref = lpa.organisation[-3:]\n",
    "        # la_district_json_string = get_la_district_json(la_district_ref)\n",
    "        # if la_district_json_string is not None:\n",
    "        #     la_district_json = json.loads(get_la_district_json(la_district_ref))\n",
    "        #     geometry_ref = la_district_json[\"local-authority-district\"]\n",
    "            # print(geometry_ref)\n",
    "            # print(lpa.statistical_geography)\n",
    "        multipol = get_LPA_multipolygon(lpa.statistical_geography)\n",
    "        if multipol is not None:\n",
    "            area, issue = parse_wkt(multipol)\n",
    "            # print(area, issue)\n",
    "            for site in df_brownfield_sites.itertuples():\n",
    "                # print(site)\n",
    "                if (pd.isnull(site.point) == False):\n",
    "                    # print (site.reference)\n",
    "                    # print(site.point)\n",
    "                    pt = shapely.wkt.loads(site.point)\n",
    "                    if (pt.within(area) == False):\n",
    "                        # print(\"Not within\")\n",
    "                        \n",
    "                        url = f\"https://api.postcodes.io/postcodes?lon={pt.x}&lat={pt.y}\"\n",
    "                        response = urlopen(url)\n",
    "                        data = json.loads(response.read())\n",
    "                        try:\n",
    "                            admin_district = data[\"result\"][0][\"admin_district\"]\n",
    "                        except Exception:\n",
    "                            admin_district = \"None found\"\n",
    "\n",
    "                        google_maps_link = f\"https://maps.google.com/?q={pt.y},{pt.x}\"\n",
    "                        pt_outside_boundary_row = {\"reference\": site.reference, \"organisation\": lpa.organisation, \"organisation_name\": lpa.name, \"point\": site.point, \"google_maps_link\": google_maps_link, \"admin_district\": admin_district}\n",
    "                        \n",
    "                        df_brownfield_sites_outside_lpa = pd.concat([df_brownfield_sites_outside_lpa, pd.DataFrame([pt_outside_boundary_row])] , ignore_index=True)\n",
    "                        # print(pt)\n",
    "                        # print(area)\n",
    "                else:\n",
    "                    pt_no_coord_row = {\"reference\": site.reference, \"organisation\": lpa.organisation, \"organisation_name\": lpa.name, \"point\": \"No coordinate data\"}\n",
    "                    df_brownfield_sites_outside_lpa = pd.concat([df_brownfield_sites_outside_lpa, pd.DataFrame([pt_no_coord_row])] , ignore_index=True)\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>organisation</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>local-authority-eng:CHW</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>local-authority-eng:POR</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>local-authority-eng:NGM</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>local-authority-eng:COV</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>local-authority-eng:STN</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>local-authority-eng:NED</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>local-authority-eng:NDE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>local-authority-eng:IPS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>local-authority-eng:IOW</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>local-authority-eng:NWM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                organisation  count\n",
       "0    local-authority-eng:CHW    237\n",
       "1    local-authority-eng:POR    232\n",
       "2    local-authority-eng:NGM    207\n",
       "3    local-authority-eng:COV    110\n",
       "4    local-authority-eng:STN    103\n",
       "..                       ...    ...\n",
       "172  local-authority-eng:NED      1\n",
       "173  local-authority-eng:NDE      1\n",
       "174  local-authority-eng:IPS      1\n",
       "175  local-authority-eng:IOW      1\n",
       "176  local-authority-eng:NWM      1\n",
       "\n",
       "[177 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_brownfield_sites_outside_lpa_sorted = df_brownfield_sites_outside_lpa[\"organisation\"].value_counts().reset_index()\n",
    "df_brownfield_sites_outside_lpa_sorted.to_csv(\"brownfield_sites_outside_lpa.csv\")\n",
    "display(df_brownfield_sites_outside_lpa_sorted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
