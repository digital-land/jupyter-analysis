{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import pandas as pd\n",
    "import shapely.wkt\n",
    "from shapely.geometry import shape\n",
    "from shapely.errors import WKTReadingError\n",
    "from shapely.geometry import Point\n",
    "import json\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_organisations():\n",
    "    params = urllib.parse.urlencode({\n",
    "        \"sql\": f\"\"\"\n",
    "        select organisation, name, entity as organisation_entity, statistical_geography\n",
    "        from organisation\n",
    "        \"\"\",\n",
    "        \"_size\": \"max\"\n",
    "        })\n",
    "    url = f\"https://datasette.planning.data.gov.uk/digital-land.csv?{params}\"\n",
    "    df = pd.read_csv(url)\n",
    "    return df\n",
    "\n",
    "def get_la_district_json(lpa_ref):\n",
    "    params = urllib.parse.urlencode({\n",
    "        \"sql\": f\"\"\"\n",
    "        select json\n",
    "        from entity\n",
    "        where reference = '{lpa_ref}'\n",
    "        \"\"\",\n",
    "        \"_size\": \"max\"\n",
    "        })\n",
    "    url = f\"https://datasette.planning.data.gov.uk/entity.csv?{params}\"\n",
    "    df = pd.read_csv(url)\n",
    "    try:\n",
    "        return df.loc[0,\"json\"]\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "def get_brownfield_sites_for_organisation(organisation_entity_number):\n",
    "    params = urllib.parse.urlencode({\n",
    "        \"sql\": f\"\"\"\n",
    "        select json, point, reference, organisation_entity\n",
    "        from entity\n",
    "        where organisation_entity = '{organisation_entity_number}'\n",
    "        \"\"\",\n",
    "        \"_size\": \"max\"\n",
    "        })\n",
    "    url = f\"https://datasette.planning.data.gov.uk/brownfield-land.csv?{params}\"\n",
    "    df = pd.read_csv(url)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_LPA_multipolygon(reference):\n",
    "    params = urllib.parse.urlencode({\n",
    "        \"sql\": f\"\"\"\n",
    "        select geometry\n",
    "        from entity\n",
    "        where reference = '{reference}'\n",
    "        \"\"\",\n",
    "        \"_size\": \"max\"\n",
    "        })\n",
    "    url = f\"https://datasette.planning.data.gov.uk/entity.csv?{params}\"\n",
    "    df = pd.read_csv(url)\n",
    "    try:\n",
    "        return df.loc[0,\"geometry\"]\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "def get_site_point(collection_name, entity_number):\n",
    "    params = urllib.parse.urlencode({\n",
    "        \"sql\": f\"\"\"\n",
    "        select point\n",
    "        from entity\n",
    "        where entity = '{entity_number}'\n",
    "        \"\"\",\n",
    "        \"_size\": \"max\"\n",
    "        })\n",
    "    url = f\"https://datasette.planning.data.gov.uk/{collection_name}.csv?{params}\"\n",
    "    df = pd.read_csv(url)\n",
    "    return df.loc[0,\"point\"]\n",
    "\n",
    "def parse_wkt(value):\n",
    "    try:\n",
    "        geometry = shapely.wkt.loads(value)\n",
    "    except WKTReadingError:\n",
    "        try:\n",
    "            geometry = shapely.wkt.loads(shape(json.loads(value)).wkt)\n",
    "            return geometry, \"invalid type geojson\"\n",
    "        except Exception:\n",
    "            return None, \"invalid WKT\"\n",
    "    return geometry, None\n",
    "\n",
    "\n",
    "def make_point(point):\n",
    "    if point.geom_type == \"Point\":\n",
    "        return Point(point)\n",
    "    else:\n",
    "        print(\"Not a point\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_true_location(pt):\n",
    "    if (not pt.x > -7.0 and pt.x < 2.5 and pt.y > 49.5 and pt.y < 56.0):\n",
    "        return \"Not in Great Britain\"\n",
    "    url = f\"https://api.postcodes.io/postcodes?lon={pt.x}&lat={pt.y}\"\n",
    "    response = urlopen(url)\n",
    "    data = json.loads(response.read())\n",
    "    try:\n",
    "        location = data[\"result\"][0][\"admin_district\"]\n",
    "        return location\n",
    "    except Exception:\n",
    "        return \"None found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_null_coordinate_data = False\n",
    "collection=\"brownfield_land\"\n",
    "\n",
    "df_lpa = get_all_organisations()\n",
    "df_brownfield_sites_outside_lpa = pd.DataFrame(columns=[\"Site_Reference\", \"Organisation\", \"Organisation_Name\", \"Point\", \"Maps_Link\", \"Admin_District\", \"distance (Arbitrary Unit)\"])\n",
    "for lpa in df_lpa.itertuples():\n",
    "    df_brownfield_sites = get_brownfield_sites_for_organisation(lpa.organisation_entity)\n",
    "    df_brownfield_sites = df_brownfield_sites.merge(df_lpa, left_on=\"organisation_entity\", right_on=\"organisation_entity\")\n",
    "    if (\"local-authority-eng\" in lpa.organisation):\n",
    "        multipol = get_LPA_multipolygon(lpa.statistical_geography)\n",
    "        if multipol is not None:\n",
    "            area, issue = parse_wkt(multipol)\n",
    "            for site in df_brownfield_sites.itertuples():\n",
    "                if (pd.isnull(site.point) == False):\n",
    "                    pt = shapely.wkt.loads(site.point)\n",
    "                    if (pt.within(area) == False):                       \n",
    "                        url = f\"https://api.postcodes.io/postcodes?lon={pt.x}&lat={pt.y}\"\n",
    "                        response = urlopen(url)\n",
    "                        data = json.loads(response.read())\n",
    "                        admin_district = compute_true_location(pt)\n",
    "                        distance = area.boundary.distance(pt)\n",
    "                        google_maps_link = f\"https://maps.google.com/?q={pt.y},{pt.x}\"\n",
    "                        pt_outside_boundary_row = {\"Site_Reference\": site.reference, \"Organisation\": lpa.organisation, \"Organisation_Name\": lpa.name, \"Point\": site.point, \"Maps_Link\": google_maps_link, \"Admin_District\": admin_district, \"Distance (Arbitrary Unit)\": distance}\n",
    "                        df_brownfield_sites_outside_lpa = pd.concat([df_brownfield_sites_outside_lpa, pd.DataFrame([pt_outside_boundary_row])] , ignore_index=True)\n",
    "                elif (include_null_coordinate_data):\n",
    "                    pt_no_coord_row = {\"Site_Reference\": site.reference, \"Organisation\": lpa.organisation, \"Organisation_Name\": lpa.name, \"Point\": \"No coordinate data\"}\n",
    "                    df_brownfield_sites_outside_lpa = pd.concat([df_brownfield_sites_outside_lpa, pd.DataFrame([pt_no_coord_row])] , ignore_index=True)\n",
    "            \n",
    "# TODO:\n",
    "# change maps link to highlight lpa boundary AND site point\n",
    "# perform checks on points to determine why they are outside lpa, missing -, coords swapped etc.\n",
    "# grab site address from json, use in compute_true_location?\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_brownfield_sites_outside_lpa_sorted = df_brownfield_sites_outside_lpa.sort_values(by=[\"Distance (Arbitrary Unit)\"], ascending=False)\n",
    "# df_brownfield_sites_outside_lpa_counts = df_brownfield_sites_outside_lpa.organisation.value_counts()\n",
    "# df_brownfield_sites_outside_lpa_sorted = df_brownfield_sites_outside_lpa.set_index(\"organisation\").loc[df_brownfield_sites_outside_lpa_counts.index].reset_index()\n",
    "df_brownfield_sites_outside_lpa_sorted = df_brownfield_sites_outside_lpa_sorted.reset_index(drop=True)\n",
    "df_brownfield_sites_outside_lpa_sorted.to_csv(\"brownfield_sites_outside_lpa.csv\")\n",
    "display(df_brownfield_sites_outside_lpa_sorted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
