{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entities out of LPA bounds demo\n",
    "**Author**:  Greg Slater <br>\n",
    "**Date**:  20th August 2024 <br>\n",
    "**Dataset Scope**: all <br>\n",
    "**Report Type**: Ad-hoc analysis <br>\n",
    "\n",
    "## Purpose\n",
    "To hand over to infrastructure team the proposed method of identifying entities outside of expected LPA bounds. Related to [Jira ticket #1335](https://trello.com/c/Xsd2eIAe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import shapely.wkt\n",
    "import urllib\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_organisations():\n",
    "    params = urllib.parse.urlencode({\n",
    "        \"sql\": f\"\"\"\n",
    "        select organisation as org, entity as org_entity, name as org_name, dataset as org_dataset, local_planning_authority as LPACD\n",
    "        from organisation\n",
    "        \"\"\",\n",
    "        \"_size\": \"max\"\n",
    "        })\n",
    "    url = f\"https://datasette.planning.data.gov.uk/digital-land.csv?{params}\"\n",
    "    df = pd.read_csv(url)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_pdp_geo_dataset(dataset, underscore_cols=True, crs_out=27700):\n",
    "\n",
    "    url = f\"https://files.planning.data.gov.uk/dataset/{dataset}.geojson\"\n",
    "    gdf = gpd.read_file(url)\n",
    "\n",
    "    if underscore_cols:\n",
    "        gdf.columns = [x.replace(\"-\", \"_\") for x in gdf.columns]\n",
    "\n",
    "\n",
    "    gdf.set_crs(epsg=4326, inplace=True)\n",
    "    gdf.to_crs(epsg=crs_out, inplace=True)\n",
    "\n",
    "    return gdf\n",
    "\n",
    "\n",
    "def get_provisions():\n",
    "    global provisions_df  \n",
    "    params = urllib.parse.urlencode({\n",
    "        \"sql\": f\"\"\"\n",
    "            SELECT\n",
    "                cohort, notes, organisation, project, provision_reason, start_date\n",
    "            FROM\n",
    "                provision   \n",
    "            WHERE \n",
    "                provision_reason = \"expected\"\n",
    "                AND project = \"open-digital-planning\"\n",
    "            GROUP BY organisation\n",
    "            ORDER BY cohort\n",
    "        \"\"\",\n",
    "        \"_size\": \"max\"\n",
    "    })\n",
    "    url = f\"https://datasette.planning.data.gov.uk/digital-land.csv?{params}\"\n",
    "    provisions_df = pd.read_csv(url)\n",
    "    return provisions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "452\n"
     ]
    }
   ],
   "source": [
    "# get prov\n",
    "provisions_df = get_provisions()\n",
    "\n",
    "# get orgs\n",
    "org_df = get_all_organisations()\n",
    "# flag ODP\n",
    "org_df[\"odp_flag\"] = np.where(org_df[\"org\"].isin(provisions_df[\"organisation\"]), True, False)\n",
    "\n",
    "print(len(org_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8310\n",
      "8310\n"
     ]
    }
   ],
   "source": [
    "# CA from pdp\n",
    "ca_df = pd.read_csv(\"https://files.planning.data.gov.uk/dataset/conservation-area.csv\",\n",
    "                            usecols = [\"entity\", \"name\", \"organisation-entity\", \"reference\", \"entry-date\", \"point\", \"geometry\"])\n",
    "\n",
    "ca_df.columns = [x.replace(\"-\", \"_\") for x in ca_df.columns]\n",
    "\n",
    "ca_df.rename(columns={\"organisation_entity\":\"org_entity\"}, inplace=True)\n",
    "\n",
    "# join organisation name and LPA codes from lookup\n",
    "ca_df = ca_df.merge(\n",
    "    org_df[[\"org_entity\", \"org_name\", \"org_dataset\",  \"LPACD\"]], \n",
    "    how = \"left\",\n",
    "    on = \"org_entity\")\n",
    "\n",
    "# load to gdf, both point and poly versions\n",
    "ca_df[\"point\"] = ca_df[\"point\"].apply(shapely.wkt.loads)\n",
    "ca_point_gdf = gpd.GeoDataFrame(ca_df, geometry=\"point\")\n",
    "\n",
    "ca_df.drop(\"point\", axis=1, inplace=True)\n",
    "\n",
    "ca_df[\"geometry\"] = ca_df[\"geometry\"].apply(shapely.wkt.loads)\n",
    "ca_poly_gdf = gpd.GeoDataFrame(ca_df, geometry=\"geometry\")\n",
    "\n",
    "# Transform to ESPG:27700 for more interpretable area units\n",
    "ca_point_gdf.set_crs(epsg=4326, inplace=True)\n",
    "ca_point_gdf.to_crs(epsg=27700, inplace=True)\n",
    "\n",
    "ca_poly_gdf.set_crs(epsg=4326, inplace=True)\n",
    "ca_poly_gdf.to_crs(epsg=27700, inplace=True)\n",
    "\n",
    "# calculate area\n",
    "ca_poly_gdf[\"area\"] = ca_poly_gdf[\"geometry\"].area\n",
    "\n",
    "print(len(ca_poly_gdf))\n",
    "print(len(ca_point_gdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "337\n"
     ]
    }
   ],
   "source": [
    "# LPA boundaries from PDP site\n",
    "lpa_gdf = get_pdp_geo_dataset(\"local-planning-authority\")\n",
    "\n",
    "lpa_gdf.rename(columns={'name':'lpa_name', 'reference':'LPACD'}, inplace=True)\n",
    "\n",
    "print(len(lpa_gdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "org_dataset              org_name                     \n",
       "government-organisation  Historic England                 6916\n",
       "local-authority          North Dorset District Council      37\n",
       "                         Purbeck District Council          126\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check of the organisations that we don't have an LPA code for\n",
    "ca_df[ca_df[\"LPACD\"].isnull()].groupby([\"org_dataset\", \"org_name\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "# List LPA codes from entity df and check they're all in the LPA gdf\n",
    "lpa_list = ca_df[\"LPACD\"][ca_df[\"LPACD\"].notnull()].drop_duplicates().to_list()\n",
    "\n",
    "# check every one of our entity LPAs is in the LPA gdf\n",
    "print(len(lpa_list))\n",
    "print(len(lpa_gdf[lpa_gdf[\"LPACD\"].isin(lpa_list)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of entities not contained by their expected (and buffered) boundary: 47\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LPACD      org_entity  org_name                   \n",
       "E60000291  92          Cornwall Council               41\n",
       "E60000184  132         East Suffolk Council            4\n",
       "E60000163  268         Rochford District Council       1\n",
       "E60000283  80          Chichester District Council     1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities_beyond = []         # to store list of entities outside boundary \n",
    "BOUNDARY_BUFFER_DISTANCE = 50   # to set distance outside of expected boundary entity must exceed to be flagged\n",
    "\n",
    "# loop through LPA codes and for each check whether any conservation areas with that code are not within the buffered LPA boundary\n",
    "for lpa_code in lpa_list:\n",
    "\n",
    "    cons_areas = ca_poly_gdf.loc[ca_poly_gdf[\"LPACD\"] == lpa_code]\n",
    "    lpa_boundary = lpa_gdf.loc[lpa_gdf[\"LPACD\"] == lpa_code].reset_index().geometry[0]\n",
    "    \n",
    "    # 2. Exceeds by x metres version\n",
    "    lpa_boundary_buff = lpa_boundary.buffer(BOUNDARY_BUFFER_DISTANCE)\n",
    "    cons_areas_beyond = cons_areas.geometry.within(lpa_boundary_buff)\n",
    "\n",
    "    # add areas which don't intersect to the list\n",
    "    entities_beyond.extend(cons_areas.loc[~cons_areas_beyond][\"entity\"].to_list())\n",
    "\n",
    "\n",
    "entity_outside_LPA_df = ca_df[ca_df[\"entity\"].isin(entities_beyond)]\n",
    "\n",
    "# list of LPAs with entities outside them\n",
    "LPAs_with_bads = entity_outside_LPA_df[\"LPACD\"].drop_duplicates().to_list()\n",
    "\n",
    "print(f\"No. of entities not contained by their expected (and buffered) boundary: {len(entity_outside_LPA_df):,}\")\n",
    "entity_outside_LPA_df.groupby([\"LPACD\", \"org_entity\", \"org_name\"]).size().sort_values(ascending=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdp_jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
