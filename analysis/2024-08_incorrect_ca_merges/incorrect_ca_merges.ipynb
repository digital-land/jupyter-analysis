{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import os\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import time\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import shapely.wkt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILES_URL = 'https://datasette.planning.data.gov.uk/'\n",
    "\n",
    "def download_dataset(dataset, output_dir_path, overwrite=False):\n",
    "    dataset_file_name = f'{dataset}.db'\n",
    "    \n",
    "    if not os.path.exists(output_dir_path):\n",
    "        os.makedirs(output_dir_path)\n",
    "    \n",
    "    output_file_path = os.path.join(output_dir_path, dataset_file_name)\n",
    "\n",
    "    if overwrite is False and os.path.exists(output_file_path):\n",
    "        return\n",
    "    \n",
    "    final_url = os.path.join(FILES_URL, dataset_file_name)\n",
    "    print(f'downloading data from {final_url}')\n",
    "    print(f'to: {output_file_path}')\n",
    "    urllib.request.urlretrieve(final_url, os.path.join(output_dir_path, dataset_file_name))\n",
    "    print('download complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_sqlite(db_path, query_string):\n",
    "\n",
    "    with sqlite3.connect(db_path) as con:\n",
    "            \n",
    "        cursor = con.execute(query_string)\n",
    "        cols = [column[0] for column in cursor.description]\n",
    "        results_df = pd.DataFrame.from_records(data=cursor.fetchall(), columns=cols)\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_organisations():\n",
    "    params = urllib.parse.urlencode({\n",
    "        \"sql\": f\"\"\"\n",
    "        select entity as org_entity, name as org_name, organisation, dataset\n",
    "        from organisation\n",
    "        \"\"\",\n",
    "        \"_size\": \"max\"\n",
    "        })\n",
    "    url = f\"https://datasette.planning.data.gov.uk/digital-land.csv?{params}\"\n",
    "    df = pd.read_csv(url)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../../data/db_downloads/\"\n",
    "os.makedirs(data_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download_dataset(\"digital-land\", data_dir, overwrite=True)\n",
    "# download_dataset(\"conservation-area\", data_dir, overwrite=True)\n",
    "\n",
    "dl_db_path = os.path.join(data_dir, \"digital-land.db\")\n",
    "ca_db_path = os.path.join(data_dir, \"conservation-area.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_df = get_all_organisations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each entity get all geometry factsand the resources they've come from\n",
    "\n",
    "q = \"\"\"\n",
    "    with facts_latest_resource as (\n",
    "\n",
    "        select f.entity, f.fact, fr.resource, f.field, fr.entry_date, f.value as geometry, row_number() over (partition by f.fact order by fr.entry_date desc) as res_rank\n",
    "        from fact f\n",
    "        inner join fact_resource fr on f.fact = fr.fact\n",
    "        where f.field = 'geometry'\n",
    "        )\n",
    "  \n",
    "    select * \n",
    "    from facts_latest_resource\n",
    "    where res_rank = 1\n",
    "\"\"\"\n",
    "\n",
    "ca_geom_facts = query_sqlite(ca_db_path, q)\n",
    "\n",
    "print(len(ca_geom_facts))\n",
    "ca_geom_facts.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get resource to org lookup and join on other org details\n",
    "\n",
    "q = \"\"\"\n",
    "    select * from resource_organisation\n",
    "\"\"\"\n",
    "\n",
    "res_org_lookup = query_sqlite(dl_db_path, q)\n",
    "\n",
    "res_org_lookup[\"organisation\"] = res_org_lookup[\"organisation\"].apply(lambda x: x.replace(\"-eng\", \"\"))\n",
    "\n",
    "res_org_lookup = res_org_lookup.merge(\n",
    "    org_df[[\"organisation\", \"org_name\", \"dataset\"]],\n",
    "    how = \"left\",\n",
    "    on = \"organisation\"\n",
    ")\n",
    "\n",
    "res_org_lookup.rename(columns={\"dataset\":\"org_type\"}, inplace = True)\n",
    "\n",
    "\n",
    "print(len(res_org_lookup))\n",
    "print(len(res_org_lookup.drop_duplicates()))\n",
    "print(len(res_org_lookup[\"resource\"].drop_duplicates()))\n",
    "res_org_lookup.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find resources which are duplicated across orgs\n",
    "# res_org_count = res_org_lookup.groupby([\"resource\"]).size().reset_index(name = \"count\")\n",
    "# res_dupes = res_org_count[res_org_count[\"count\"] > 1]\n",
    "\n",
    "# res_org_lookup[res_org_lookup[\"resource\"].isin(res_dupes[\"resource\"])].sort_values(\"resource\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ca_geom_facts))\n",
    "\n",
    "# join resouce org lookup to entity_fact_resource table\n",
    "ca_geom_facts_org = ca_geom_facts.merge(\n",
    "    res_org_lookup,\n",
    "    how = \"left\",\n",
    "    on = \"resource\"\n",
    ")\n",
    "\n",
    "# make gdf for mapping later\n",
    "ca_geom_facts_org[\"geometry\"] = ca_geom_facts_org[\"geometry\"].apply(shapely.wkt.loads)\n",
    "ca_geom_facts_org = gpd.GeoDataFrame(ca_geom_facts_org, geometry=\"geometry\")\n",
    "\n",
    "ca_geom_facts_org.set_crs(4326, inplace=True)\n",
    "\n",
    "print(len(ca_geom_facts_org))\n",
    "ca_geom_facts_org.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of org_types and org per entity\n",
    "ent_fact_org_count = ca_geom_facts_org.groupby(\n",
    "        [\"entity\"], as_index=False\n",
    "    ).agg(\n",
    "        n_org_types = (\"org_type\", \"nunique\"),\n",
    "        n_orgs = (\"organisation\", \"nunique\")\n",
    "    )\n",
    "\n",
    "# issues are when we have a higher number of organisations than org types (e.g. two different LPA resources for just one entity)\n",
    "bad_ents = ent_fact_org_count[ent_fact_org_count[\"n_orgs\"] > ent_fact_org_count[\"n_org_types\"]]\n",
    "print(len(bad_ents))\n",
    "bad_ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_ents_gdf = ca_geom_facts_org[ca_geom_facts_org[\"entity\"].isin(bad_ents.entity)].sort_values(\"entity\")\n",
    "bad_ents_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each entity, flag the geometry facts which don't intersect with any of the others (i.e. they're likely here from a bad merge)\n",
    "def flag_non_intersecting(group):\n",
    "    group['non_intersecting'] = ~group.geometry.apply(lambda x: group.geometry.intersects(x).sum() > 1)\n",
    "    return group\n",
    "\n",
    "# Apply the function to each group\n",
    "bad_ents_gdf_flagged = bad_ents_gdf.groupby('entity').apply(flag_non_intersecting).reset_index(drop=True)\n",
    "\n",
    "# save\n",
    "bad_ents_gdf_flagged[[\"entity\", \"org_name\", \"non_intersecting\", \"geometry\"]].to_csv(\"conservation-area_entity-bad-merges.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check facts for specific entity\n",
    "# bad_ents_gdf_flagged[bad_ents_gdf_flagged[\"entity\"] == 44009929]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map entity fact\n",
    "# bad_ents_gdf_flagged[bad_ents_gdf_flagged[\"entity\"] == 44009916].iloc[[0]].explore(  #\n",
    "#     column = \"org_name\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map all entity facts\n",
    "# bad_ents_gdf_flagged[bad_ents_gdf_flagged[\"entity\"] == 44009916].explore(  #\n",
    "#     column = \"org_name\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdp_jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
