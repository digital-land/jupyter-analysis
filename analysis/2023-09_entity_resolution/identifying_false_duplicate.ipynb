{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44fdd92e",
   "metadata": {},
   "source": [
    "## Identifying false duplicates\n",
    "As there are duplicates in the dataset there may be occasions that either through incorrect manual changes or by errors in the specification or pipeline configurations errors are introduced and data is compiled into the same entity where it's not appropriate. This notebook aims to download a dataset and examine the facts against an entity to check whether it needs correcting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7b06041",
   "metadata": {},
   "outputs": [],
   "source": [
    "from download_data import download_dataset\n",
    "from data import get_organisation_summary\n",
    "from plot import plot_map\n",
    "import spatialite\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import itertools\n",
    "import shapely.wkt\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d012145",
   "metadata": {},
   "source": [
    "Download the sqlite file to run the tests against. This is set not to overwrite the data if it exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2170fe53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define required variables\n",
    "dataset = 'conservation-area'\n",
    "collection = 'conservation-area-collection'\n",
    "data_dir = os.path.join('../data/entity_resolution',dataset)\n",
    "dataset_path = os.path.join(data_dir,f'{dataset}.sqlite3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f41c0381",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_dataset(dataset,collection,data_dir,overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48002371",
   "metadata": {},
   "source": [
    "#### Testing WIP\n",
    "I have started to create a query that can compare all of the entities against themselves. Last time i tried to run this it didn't finish overnight so a new approach probably needs to be taken. This may even be more efficient using pandas and running through for each individual entity. Worth playing around with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e0cefae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_false_duplicates(dataset_path):    \n",
    "    sql = f\"\"\"\n",
    "            SELECT a.fact As primary_fact,\n",
    "                a.entity AS primary_entity,\n",
    "                a.value AS primary_value,\n",
    "                b.fact AS secondry_fact,\n",
    "                b.entity AS secondary_entity,\n",
    "                b.value AS secondary_value,\n",
    "                100 *(ST_Area(ST_Intersection(GeomFromText(a.value), GeomFromText(b.value)))/ MIN(ST_Area(GeomFromText(a.value)), ST_Area(GeomFromText(b.value)))) AS pct_overlap\n",
    "            FROM\n",
    "                (SELECT fact,\n",
    "                        entity,\n",
    "                        field,\n",
    "                        value\n",
    "                FROM fact\n",
    "                WHERE field = 'geometry' \n",
    "                AND ST_IsValid(GeomFromText(value))) a\n",
    "            JOIN\n",
    "                (SELECT fact,\n",
    "                        entity,\n",
    "                        field,\n",
    "                        value\n",
    "                FROM fact\n",
    "                WHERE field = 'geometry' \n",
    "                AND ST_IsValid(GeomFromText(value))) b \n",
    "            ON a.entity <> b.entity\n",
    "            AND ST_Intersects(GeomFromText(a.value), GeomFromText(b.value))\n",
    "            WHERE 100 *(ST_Area(ST_Intersection(GeomFromText(a.value), GeomFromText(b.value)))/ MIN(ST_Area(GeomFromText(a.value)), ST_Area(GeomFromText(b.value)))) > 95;\n",
    "        \"\"\"\n",
    "    with spatialite.connect(dataset_path) as con:\n",
    "        cursor = con.execute(sql)\n",
    "        cols = [column[0] for column in cursor.description]\n",
    "        results = pd.DataFrame.from_records(data=cursor.fetchall(), columns=cols)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a496719f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = get_false_duplicates(dataset_path)\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
