{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import shapely.wkt\n",
    "import urllib\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"output/\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_organisations():\n",
    "    params = urllib.parse.urlencode({\n",
    "        \"sql\": f\"\"\"\n",
    "        select entity as organisation_entity, name, organisation, dataset, local_planning_authority\n",
    "        from organisation\n",
    "        \"\"\",\n",
    "        \"_size\": \"max\"\n",
    "        })\n",
    "    url = f\"https://datasette.planning.data.gov.uk/digital-land.csv?{params}\"\n",
    "    df = pd.read_csv(url)\n",
    "    return df\n",
    "\n",
    "def get_pdp_geo_dataset(dataset, underscore_cols=True, crs_out=27700):\n",
    "\n",
    "    url = f\"https://files.planning.data.gov.uk/dataset/{dataset}.geojson\"\n",
    "    gdf = gpd.read_file(url)\n",
    "\n",
    "    if underscore_cols:\n",
    "        gdf.columns = [x.replace(\"-\", \"_\") for x in gdf.columns]\n",
    "\n",
    "\n",
    "    gdf.set_crs(epsg=4326, inplace=True)\n",
    "    gdf.to_crs(epsg=crs_out, inplace=True)\n",
    "\n",
    "    return gdf\n",
    "\n",
    "def get_provisions():\n",
    "    global provisions_df  \n",
    "    params = urllib.parse.urlencode({\n",
    "        \"sql\": f\"\"\"\n",
    "            SELECT\n",
    "                cohort, notes, organisation, project, provision_reason, start_date\n",
    "            FROM\n",
    "                provision   \n",
    "            WHERE \n",
    "                provision_reason = \"expected\"\n",
    "                AND project = \"open-digital-planning\"\n",
    "            GROUP BY organisation\n",
    "            ORDER BY cohort\n",
    "        \"\"\",\n",
    "        \"_size\": \"max\"\n",
    "    })\n",
    "    url = f\"https://datasette.planning.data.gov.uk/digital-land.csv?{params}\"\n",
    "    provisions_df = pd.read_csv(url)\n",
    "    return provisions_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get prov\n",
    "provisions_df = get_provisions()\n",
    "\n",
    "# get orgs\n",
    "org_df = get_all_organisations()\n",
    "# flag ODP\n",
    "org_df[\"odp_flag\"] = np.where(org_df[\"organisation\"].isin(provisions_df[\"organisation\"]), True, False)\n",
    "\n",
    "print(len(org_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in manual count sheet\n",
    "con_count_df = pd.read_csv(\"https://docs.google.com/spreadsheets/d/e/2PACX-1vSGZIudsGx0ez4cU-4wSvymvXIFfpDb_qfbS3uW5RiuBkJrJQ9D8k0HBUPtgncRXA/pub?gid=485605871&single=true&output=csv\")\n",
    "con_count_df.columns = [x.replace(\"-\", \"_\") for x in con_count_df.columns]\n",
    "\n",
    "# join on organisation names and LPA codes\n",
    "con_count_lpa_df = con_count_df.merge(\n",
    "    org_df[[\"organisation_entity\", \"name\", \"organisation\", \"local_planning_authority\", \"odp_flag\"]],\n",
    "    how = \"left\",\n",
    "    on = \"organisation_entity\"\n",
    ")\n",
    "\n",
    "print(len(con_count_lpa_df))\n",
    "# con_count_lpa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CA from pdp\n",
    "ca_df = pd.read_csv(\"https://files.planning.data.gov.uk/dataset/conservation-area.csv\",\n",
    "                            usecols = [\"entity\", \"name\", \"organisation-entity\", \"reference\", \"entry-date\", \"point\", \"geometry\"])\n",
    "\n",
    "ca_df.columns = [x.replace(\"-\", \"_\") for x in ca_df.columns]\n",
    "\n",
    "# load to gdf\n",
    "ca_df[\"point\"] = ca_df[\"point\"].apply(shapely.wkt.loads)\n",
    "ca_gdf = gpd.GeoDataFrame(ca_df, geometry='point')\n",
    "\n",
    "# Transform to ESPG:27700 for more interpretable area units\n",
    "ca_gdf.set_crs(epsg=4326, inplace=True)\n",
    "ca_gdf.to_crs(epsg=27700, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latest ONS LPA file, for flagging whether pdp LPAs are 2023 or not\n",
    "# ons_lpa_gpd = gpd.read_file(\"https://services1.arcgis.com/ESMARspQHYMw9BZ9/arcgis/rest/services/Local_Planning_Authorities_April_2023_Boundaries_UK_BGC/FeatureServer/0/query?outFields=*&where=1%3D1&f=geojson\",)\n",
    "\n",
    "# print(len(ons_lpa_gpd))\n",
    "# ons_lpa_gpd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LPA boundaries from PDP site\n",
    "# lpa_gdf = get_pdp_geo_dataset(\"local-planning-authority\")\n",
    "\n",
    "lpa_gdf[\"lpa_2023\"] = np.where(lpa_gdf[\"reference\"].isin(ons_lpa_gpd[\"LPA23CD\"]), True, False)\n",
    "lpa_gdf.rename(columns={'name':'lpa_name'}, inplace=True)\n",
    "\n",
    "print(len(lpa_gdf))\n",
    "print(len(lpa_gdf[lpa_gdf[\"lpa_2023\"]]))\n",
    "# lpa_gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial joining - LPA boundaries to conservation area points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join LPAs to all conservation areas, then join on the names of supplying organisations for matching conservation areas\n",
    "lpa_ca_join = gpd.sjoin(\n",
    "    lpa_gdf[[\"reference\", \"lpa_name\", \"lpa_2023\", \"geometry\"]],\n",
    "    ca_gdf[[\"entity\", \"organisation_entity\", \"point\"]],\n",
    "    how = \"left\",\n",
    "    predicate = \"intersects\"\n",
    ").merge(\n",
    "    org_df[[\"organisation_entity\", \"name\"]],\n",
    "    how = \"left\",\n",
    "    on = \"organisation_entity\"\n",
    ")\n",
    "\n",
    "# force name to string type \n",
    "lpa_ca_join[\"name\"] = lpa_ca_join[\"name\"].astype(str)\n",
    "\n",
    "# flag the providing org type - ranking so when we group and count we can count areas with LPA and Historic England providing as LPA\n",
    "lpa_ca_join[\"org_type_rank\"] = np.select(\n",
    "    [\n",
    "        (lpa_ca_join[\"organisation_entity\"] != 16) & (lpa_ca_join[\"organisation_entity\"].notnull()),\n",
    "        lpa_ca_join[\"organisation_entity\"] == 16\n",
    "    ],\n",
    "    [1, 2],\n",
    "    default = 3)\n",
    "\n",
    "print(len(lpa_ca_join))\n",
    "# lpa_ca_join.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count no. of conservation areas per LPA then join on the manual counts\n",
    "lpa_ca_join_count = lpa_ca_join.groupby(\n",
    "        [\"reference\", \"lpa_name\", \"lpa_2023\"]\n",
    "    ).agg(\n",
    "        {\"entity\" : \"count\",\n",
    "         \"name\" : lambda x: ', '.join(set(x)),\n",
    "         \"organisation_entity\" : \"nunique\",\n",
    "         \"org_type_rank\" : \"min\"}\n",
    "    ).reset_index(    \n",
    "    ).merge(\n",
    "        con_count_lpa_df[[\"local_planning_authority\", \"name\", \"conservation_area_count\", \"odp_flag\"]],\n",
    "        how = \"left\",\n",
    "        left_on = \"reference\",\n",
    "        right_on = \"local_planning_authority\"\n",
    "    )\n",
    "\n",
    "# rename cols\n",
    "lpa_ca_join_count.rename(columns=\n",
    "                         {\"entity\":\"count_platform\", \n",
    "                          \"name_x\":\"platform_data_providers\", \n",
    "                          \"organisation_entity\" : \"n_platform_data_providers\",\n",
    "                          \"conservation_area_count\":\"count_manual\",\n",
    "                          \"name_y\":\"lpa_name_manual\"}, inplace = True)\n",
    "\n",
    "# calculate count comparison delta\n",
    "lpa_ca_join_count[\"count_delta\"] = (lpa_ca_join_count[\"count_platform\"] - lpa_ca_join_count[\"count_manual\"]) / lpa_ca_join_count[\"count_manual\"]\n",
    "lpa_ca_join_count[\"count_delta_abs\"] = abs(lpa_ca_join_count[\"count_delta\"])\n",
    "# use org type rank to flag the best provider for an area\n",
    "lpa_ca_join_count[\"provider_org_type\"] = lpa_ca_join_count[\"org_type_rank\"].map({1:\"LPA\", 2:\"Historic England\", 3:\"None\"})\n",
    "lpa_ca_join_count[\"provider_org_type_s\"] = np.where(lpa_ca_join_count[\"n_platform_data_providers\"] > 1, \"Historic England & LPA\", lpa_ca_join_count[\"provider_org_type\"])\n",
    "\n",
    "# lpa_ca_join_count.to_csv(os.path.join(output_dir, \"LPA_conservation_area_count_comparison.csv\"), index = False)\n",
    "\n",
    "# lpa_ca_join_count.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get single LPA layers\n",
    "\n",
    "Where we have manual CA counts from organisations which are now technically \"retired\" LPAs (i.e. replaced by a newer LPA), it indicates that the data is still divided and provided by these historic orgs. In these cases we don't want to show the new 2023 LPA on the map at the same time as it overlaps and is confusing as we haven't technically collected data from this new org.\n",
    "\n",
    "So we want to find the new 2023 LPAs which sit over retired LPAs that have supplied us with data, so we can remove them from the map and get a single contiguous layer which is a mix of historic and current LPA boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create gdf of the match counts for all LPAs\n",
    "lpa_ca_join_count_gdf = lpa_gdf[[\"reference\", \"geometry\"]].merge(\n",
    "    lpa_ca_join_count,\n",
    "    how = \"left\",\n",
    "    on = \"reference\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old lpas = those which are not a 2023 boundary and we have data on the platform for\n",
    "old_lpas = lpa_ca_join_count_gdf[(lpa_ca_join_count_gdf[\"lpa_2023\"] == False) & (lpa_ca_join_count_gdf[\"count_manual\"].notnull())]\n",
    "\n",
    "# buffer the boundaries of new 2023 lpas a bit, so we can find which old ones are contained within them\n",
    "buffered_new_lpas = lpa_ca_join_count_gdf[(lpa_ca_join_count_gdf[\"lpa_2023\"] == True)][[\"reference\", \"lpa_name\", \"geometry\"]].copy()\n",
    "buffered_new_lpas[\"geometry\"] = buffered_new_lpas[\"geometry\"].buffer(100)\n",
    "\n",
    "# new 2023 lpas to flag are those which have an \"old\" lpa within them\n",
    "new_lpas = gpd.sjoin(\n",
    "    old_lpas[[\"reference\", \"lpa_name\", \"lpa_2023\", \"geometry\"]],\n",
    "    buffered_new_lpas,\n",
    "    how = \"inner\",\n",
    "    predicate = \"within\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_lpas_incl_list = old_lpas[\"reference\"].drop_duplicates().values\n",
    "new_lpas_excl_list = new_lpas[\"reference_right\"].drop_duplicates().values\n",
    "\n",
    "lpa_ca_join_count_gdf[\"old_lpa_combo_display\"] = np.select(\n",
    "    [\n",
    "        # is in old exclude list - show\n",
    "        lpa_ca_join_count_gdf[\"reference\"].isin(old_lpas_incl_list),\n",
    "        # is new and not in the new exclude list - show \n",
    "        (lpa_ca_join_count_gdf[\"lpa_2023\"] == True) & (~lpa_ca_join_count_gdf[\"reference\"].isin(new_lpas_excl_list))\n",
    "    ],\n",
    "    [True, True],\n",
    "    default = False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test whether new flag gives consistent single layer\n",
    "\n",
    "# lpa_ca_join_count_gdf[lpa_ca_join_count_gdf[\"old_lpa_combo_display\"] == True].explore(\n",
    "#     color = \"blue\",\n",
    "#     tooltip = False,\n",
    "#     # popup = [\"name\", \"LPACD\"],\n",
    "#         style_kwds = {\n",
    "#         \"fillOpacity\" : \"0.1\"\n",
    "#         }\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show both on a map\n",
    "\n",
    "# old_lpas_list = old_lpas[\"reference\"].drop_duplicates().values\n",
    "# new_lpas_list = new_lpas[\"reference_right\"].drop_duplicates().values\n",
    "\n",
    "\n",
    "# map_entities = lpa_ca_join_count_gdf[lpa_ca_join_count_gdf[\"reference\"].isin(old_lpas_list)].explore(\n",
    "#     color = \"red\",\n",
    "#     tooltip = False,\n",
    "#     # popup = [\"organisation_name\", \"entity\", \"name\", \"reference\"],\n",
    "#     tiles = \"CartoDB positron\",  # use \"CartoDB positron\" tiles\n",
    "#     # highlight = False,\n",
    "#     style_kwds = {\n",
    "#     \"fillOpacity\" : \"0.1\"\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# buffered_new_lpas[buffered_new_lpas[\"reference\"].isin(new_lpas_list)].explore(\n",
    "#     m = map_entities,\n",
    "#     color = \"blue\",\n",
    "#     tooltip = False,\n",
    "#     # popup = [\"name\", \"LPACD\"],\n",
    "#         style_kwds = {\n",
    "#         \"fillOpacity\" : \"0\"\n",
    "#         }\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary matching figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_mixed = lpa_ca_join_count_gdf[lpa_ca_join_count_gdf[\"old_lpa_combo_display\"] == True].copy()\n",
    "\n",
    "n_lpas_total = len(count_mixed)\n",
    "n_lpas_on_pdp = len(count_mixed[count_mixed[\"count_platform\"] > 0])\n",
    "n_lpas_not_on_pdp = len(count_mixed[count_mixed[\"count_platform\"] == 0])\n",
    "n_perfect_matches = len(count_mixed[count_mixed[\"count_delta\"] == 0])\n",
    "n_within_10_pct = len(count_mixed[abs(count_mixed[\"count_delta\"]) <= .1])\n",
    "\n",
    "print(f\"Total LPAs (Old/New LPA combo): {n_lpas_total}\")\n",
    "print(f\"n LPAs with CA data on the site: {n_lpas_on_pdp} ({n_lpas_on_pdp/n_lpas_total:.0%} pct of total LPAs)\")\n",
    "print(f\"n LPAs without CA data on the site: {n_lpas_not_on_pdp} ({n_lpas_not_on_pdp/n_lpas_total:.0%} pct of total LPAs)\")\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(f\"n LPAs where count of CAs for site and manual check matches exactly: {n_perfect_matches} ({n_perfect_matches/n_lpas_on_pdp:.0%} pct of LPAs with data on the site)\")\n",
    "print(f\"n LPAs where count of CAs for site and manual check is within +/- 10%: {n_within_10_pct} ({n_within_10_pct/n_lpas_on_pdp:.0%}  pct of LPAs with data on the site)\")\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "n_cas = sum(count_mixed[\"count_platform\"])\n",
    "mean_ca_per_lpa = n_cas / n_lpas_on_pdp\n",
    "projected_missing = mean_ca_per_lpa * n_lpas_not_on_pdp\n",
    "counted_missing = count_mixed[count_mixed[\"count_platform\"] == 0][\"count_manual\"].sum()\n",
    "\n",
    "print(f\"Total CAs on site (within Old/New LPA combo LPA boundaries): {n_cas:,}\")\n",
    "print(f\"mean no. of CAs per LPA on site: {mean_ca_per_lpa:.3g}\")\n",
    "print(f\"projected CAs still to add: ~{projected_missing:,.0f}\")\n",
    "print(f\"counted CAs still to add: {counted_missing:,.0f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_count = count_mixed.groupby([\"provider_org_type_s\"]).size().reset_index(name = \"count\")\n",
    "source_count[\"pct\"] = source_count[\"count\"] / source_count[\"count\"].sum()\n",
    "\n",
    "source_count.sort_values(by = \"pct\", inplace= True)\n",
    "source_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = source_count.plot.barh(x = \"provider_org_type_s\", y = \"pct\",\n",
    "                  color = [\"#A285D1\", \"#F46A25\", \"grey\",\"#28A197\"],\n",
    "                  title = \"% of English LPAs by conservation-area data provider type\",\n",
    "                  ylabel = \"\",\n",
    "                  legend = False,\n",
    "                  xlim = [0, 0.8]\n",
    "                  )\n",
    "\n",
    "ax.bar_label(ax.containers[0], fmt='{:,.0%}', padding = 4)\n",
    "ax.tick_params(\n",
    "    axis='x',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,      # ticks along the bottom edge are off\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    labelbottom=False) # labels along the bottom edge are off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.containers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_mixed.groupby([\"provider_org_type\"]).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entity merging and history\n",
    "Aim here is to flag when entities are those which have been merged with data from another org, or have had another entity redirected to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in old-entity and lookup csvs\n",
    "ca_old_ent = pd.read_csv(\"https://raw.githubusercontent.com/digital-land/config/main/pipeline/conservation-area/old-entity.csv\")\n",
    "ca_lookup = pd.read_csv(\"https://raw.githubusercontent.com/digital-land/config/main/pipeline/conservation-area/lookup.csv\")\n",
    "\n",
    "ca_old_ent.columns = [x.replace(\"-\", \"_\") for x in ca_old_ent.columns]\n",
    "ca_lookup.columns = [x.replace(\"-\", \"_\") for x in ca_lookup.columns]\n",
    "\n",
    "# create org lookup with \"-eng\" in organisation field\n",
    "org_eng_sub = org_df[org_df[\"dataset\"] == \"local-authority\"].copy()\n",
    "org_eng_sub[\"organisation\"] = org_eng_sub[\"organisation\"].apply(lambda x: x.split(\":\")[0] + \"-eng:\" + x.split(\":\")[1])\n",
    "\n",
    "# org_lookup: need to join a version with normal organisation field and an \"-eng\" organisation field into a lookup table, as CA lookup.csv contains both types\n",
    "org_eng_lookup = pd.concat([\n",
    "    org_df[[\"organisation\", \"organisation_entity\", \"dataset\"]].copy(),\n",
    "    org_eng_sub[[\"organisation\", \"organisation_entity\", \"dataset\"]]\n",
    "])\n",
    "\n",
    "ca_lookup = ca_lookup.merge(\n",
    "    org_eng_lookup[[\"organisation_entity\", \"organisation\", \"dataset\"]], \n",
    "    how = \"left\",\n",
    "    on = \"organisation\"\n",
    ")\n",
    "\n",
    "print(len(ca_old_ent))\n",
    "print(len(ca_lookup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flag LPA or Historic England supplier\n",
    "ca_lookup[\"supplier_flag\"] = np.select([\n",
    "    ca_lookup[\"organisation_entity\"] == 16,\n",
    "    ca_lookup[\"dataset\"] == \"local-authority\"\n",
    "    ],\n",
    "    [\"HE\", \"LPA\"],\n",
    "    default = np.nan)\n",
    "\n",
    "# ca_lookup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# breaking down multiple entries in the lookup file with the same entity number, and where the supplier for duplicates is from HE or LPA\n",
    "entity_count = ca_lookup.groupby(\n",
    "        [\"entity\"]\n",
    "    ).agg(\n",
    "        {\"reference\" : \"count\",\n",
    "         \"organisation_entity\" : \"nunique\",\n",
    "         \"supplier_flag\" : lambda x: ', '.join(set(x))}\n",
    "    ).reset_index()\n",
    "\n",
    "entity_count.rename(columns={\n",
    "    \"reference\" : \"n_references\",\n",
    "    \"organisation_entity\" : \"n_orgs_distinct\",\n",
    "    \"supplier_flag\" : \"supplier_list\"}, inplace = True)\n",
    "\n",
    "# list of all entities which have an entry for both an LPA and HE\n",
    "he_lpa_ent_dupes = entity_count[entity_count[\"supplier_list\"] == \"LPA, HE\"]\n",
    "\n",
    "# show breakdown\n",
    "entity_count[entity_count[\"n_references\"] > 1].groupby([\"n_references\", \"n_orgs_distinct\", \"supplier_list\"]).size().reset_index(name = \"n_instances\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick check of total no. of entities with multiple lookups in the CA file from PDP\n",
    "# ca_df[\"he_lpa_dupe\"] =np.where(ca_df[\"entity\"].isin(he_lpa_ent_dupes[\"entity\"].values), True, False)\n",
    "# ca_df.groupby(\"he_lpa_dupe\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick check of how many are redirects\n",
    "# print(len(ca_df))\n",
    "# print(len(ca_df[ca_df[\"entity\"].isin(ca_old_ent[\"entity\"])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create count of conservation areas and supplying orgs per LPA (granular), with dupe and redirect flags in\n",
    "lpa_ca_join[\"he_lpa_merged\"] =np.where(lpa_ca_join[\"entity\"].isin(he_lpa_ent_dupes[\"entity\"].values), 1, 0)\n",
    "lpa_ca_join[\"is_redirect\"] = np.where(lpa_ca_join[\"entity\"].isin(ca_old_ent[ca_old_ent[\"entity\"].notnull()][\"entity\"]), 1, 0)\n",
    "\n",
    "lpa_ca_join_count_granular = lpa_ca_join.groupby(\n",
    "        [\"reference\", \"lpa_name\", \"lpa_2023\", \"organisation_entity\", \"name\"],\n",
    "        dropna=False\n",
    "    ).agg(\n",
    "        {\"entity\" : \"count\",\n",
    "         \"he_lpa_merged\" : \"sum\",\n",
    "         \"is_redirect\" : \"sum\"}\n",
    "    ).reset_index(    \n",
    "    ).merge(\n",
    "        con_count_lpa_df[[\"local_planning_authority\", \"name\", \"organisation\", \"conservation_area_count\", \"odp_flag\"]],\n",
    "        how = \"left\",\n",
    "        left_on = \"reference\",\n",
    "        right_on = \"local_planning_authority\"\n",
    "    )\n",
    "\n",
    "# rename cols\n",
    "lpa_ca_join_count_granular.rename(columns=\n",
    "                         {\"entity\":\"count_platform\", \n",
    "                          \"he_lpa_merged\":\"n_he_lpa_merged\",\n",
    "                          \"is_redirect\":\"n_ent_redirects\",\n",
    "                          \"name_x\":\"platform_data_providers\", \n",
    "                          \"conservation_area_count\":\"count_manual\",\n",
    "                          \"name_y\":\"lpa_name_manual\"}, inplace = True)\n",
    "\n",
    "# add old/new combo layer LPA flag\n",
    "lpa_ca_join_count_granular[\"old_lpa_combo_display\"] = np.select(\n",
    "    [\n",
    "        # is in old exclude list - show\n",
    "        lpa_ca_join_count_granular[\"reference\"].isin(old_lpas_incl_list),\n",
    "        # is new and not in the new exclude list - show \n",
    "        (lpa_ca_join_count_granular[\"lpa_2023\"] == True) & (~lpa_ca_join_count_granular[\"reference\"].isin(new_lpas_excl_list))\n",
    "    ],\n",
    "    [True, True],\n",
    "    default = False\n",
    ")\n",
    "\n",
    "lpa_ca_join_count_granular\n",
    "\n",
    "lpa_ca_join_count_granular.head()\n",
    "lpa_ca_join_count_granular.to_csv(os.path.join(output_dir, \"LPA_conservation_area_count_comparison - granular.csv\"), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-do LPA count to include the merge/redirect info, plus the single LPA layer flag\n",
    "lpa_ca_join_count2 = lpa_ca_join.groupby(\n",
    "        [\"reference\", \"lpa_name\", \"lpa_2023\"]\n",
    "    ).agg(\n",
    "        {\"entity\" : \"count\",\n",
    "         \"he_lpa_merged\" : \"sum\",\n",
    "         \"is_redirect\" : \"sum\",\n",
    "         \"name\" : lambda x: ', '.join(set(x)),\n",
    "         \"organisation_entity\" : \"nunique\",\n",
    "         \"org_type_rank\" : \"min\"}\n",
    "    ).reset_index(    \n",
    "    ).merge(\n",
    "        con_count_lpa_df[[\"local_planning_authority\", \"name\", \"conservation_area_count\", \"odp_flag\"]],\n",
    "        how = \"left\",\n",
    "        left_on = \"reference\",\n",
    "        right_on = \"local_planning_authority\"\n",
    "    )\n",
    "\n",
    "# rename cols\n",
    "lpa_ca_join_count2.rename(columns=\n",
    "                         {\"entity\":\"count_platform\", \n",
    "                          \"he_lpa_merged\":\"n_he_lpa_merged\",\n",
    "                          \"is_redirect\":\"n_ent_redirects\",\n",
    "                          \"name_x\":\"platform_data_providers\", \n",
    "                          \"organisation_entity\" : \"n_platform_data_providers\",\n",
    "                          \"conservation_area_count\":\"count_manual\",\n",
    "                          \"name_y\":\"lpa_name_manual\"}, inplace = True)\n",
    "\n",
    "lpa_ca_join_count2[\"old_lpa_combo_display\"] = np.select(\n",
    "    [\n",
    "        # is in old exclude list - show\n",
    "        lpa_ca_join_count2[\"reference\"].isin(old_lpas_incl_list),\n",
    "        # is new and not in the new exclude list - show \n",
    "        (lpa_ca_join_count2[\"lpa_2023\"] == True) & (~lpa_ca_join_count2[\"reference\"].isin(new_lpas_excl_list))\n",
    "    ],\n",
    "    [True, True],\n",
    "    default = False\n",
    ")\n",
    "\n",
    "# calculate count comparison delta\n",
    "lpa_ca_join_count2[\"count_delta\"] = (lpa_ca_join_count2[\"count_platform\"] - lpa_ca_join_count2[\"count_manual\"]) / lpa_ca_join_count2[\"count_manual\"]\n",
    "lpa_ca_join_count2[\"count_delta_abs\"] = abs(lpa_ca_join_count2[\"count_delta\"])\n",
    "# use org type rank to flag the best provider for an area\n",
    "lpa_ca_join_count2[\"provider_org_type\"] = lpa_ca_join_count2[\"org_type_rank\"].map({1:\"LPA\", 2:\"Historic England\", 3:\"None\"})\n",
    "\n",
    "lpa_ca_join_count2.to_csv(os.path.join(output_dir, \"LPA_conservation_area_count_comparison.csv\"), index = False)\n",
    "\n",
    "lpa_ca_join_count2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging problem summary stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_lpas_count = lpa_ca_join_count_gdf[lpa_ca_join_count_gdf[\"old_lpa_combo_display\"] == True]\n",
    "\n",
    "n_total_lpas = len(combo_lpas_count)\n",
    "\n",
    "n_lpas_with_multiple_provs = len(combo_lpas_count[combo_lpas_count[\"n_platform_data_providers\"] > 1])\n",
    "\n",
    "n_lpas_with_multiple_provs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpa_ca_join_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ODP Summary stats\n",
    "\n",
    "odp_lpas = lpa_ca_join_count_granular[lpa_ca_join_count_granular[\"odp_flag\"] == True]\n",
    "\n",
    "# flag lpas which have supplied data at some point \n",
    "# (data comes from not-HE, or is showing as HE but has merge or redirect flags, indicating entities for LPA were also created at some point)\n",
    "odp_providers = odp_lpas[\n",
    "    (\n",
    "        (odp_lpas[\"organisation_entity\"] != 16) &\n",
    "        (odp_lpas[\"count_platform\"] > 0)\n",
    "     ) |\n",
    "    (\n",
    "        (odp_lpas[\"organisation_entity\"] == 16) &\n",
    "        (\n",
    "            (odp_lpas[\"n_he_lpa_merged\"] > 0 ) |\n",
    "            (odp_lpas[\"n_ent_redirects\"] > 0 )\n",
    "        )\n",
    "    )\n",
    "]\n",
    "\n",
    "odp_providers_prov_count = odp_providers.groupby(\n",
    "        [\"reference\", \"lpa_name\"]\n",
    "    ).agg(\n",
    "        {\n",
    "            \"platform_data_providers\" : \"count\",\n",
    "            \"count_platform\" : \"sum\",\n",
    "            \"n_he_lpa_merged\" : \"sum\",\n",
    "            \"n_ent_redirects\" : \"sum\"\n",
    "        }\n",
    "    ).reset_index()\n",
    "\n",
    "odp_dist = odp_lpas[\"lpa_name\"].drop_duplicates()\n",
    "odp_provs_dist = odp_providers[\"lpa_name\"].drop_duplicates()\n",
    "\n",
    "odp_provs_w_multi = odp_providers_prov_count[odp_providers_prov_count[\"platform_data_providers\"] > 1]\n",
    "odp_provs_w_merges = odp_providers_prov_count[\n",
    "    (odp_providers_prov_count[\"platform_data_providers\"] == 1) &\n",
    "    (odp_providers_prov_count[\"n_he_lpa_merged\"] + odp_providers_prov_count[\"n_ent_redirects\"] > 0)\n",
    "]\n",
    "\n",
    "odp_provs_clean = odp_providers_prov_count[\n",
    "    (odp_providers_prov_count[\"platform_data_providers\"] == 1) &\n",
    "    (odp_providers_prov_count[\"n_he_lpa_merged\"] + odp_providers_prov_count[\"n_ent_redirects\"] == 0)\n",
    "]\n",
    "\n",
    "print(f\"n ODP LPAs : {len(odp_dist)}\")\n",
    "print(f\"n ODP LPAs who've supplied data ever: {len(odp_provs_dist)}\")\n",
    "print(f\"n ODP LPAs (supplying data) with multiple providers: {len(odp_provs_w_multi)}\")\n",
    "print(f\"n ODP LPAs (supplying data) with single provider but merges: {len(odp_provs_w_merges)}\")\n",
    "print(f\"n ODP LPAs (supplying data) with single provider and no merges: {len(odp_provs_clean)}\")\n",
    "\n",
    "# show summary table\n",
    "# odp_providers_prov_count[odp_providers_prov_count[\"platform_data_providers\"] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check single example in granular summary\n",
    "lpa_ca_join_count_granular[lpa_ca_join_count_granular[\"reference\"] == \"E60000279\"]\n",
    "# lpa_ca_join[lpa_ca_join[\"reference\"] == \"E60000279\"].sort_values(by = [\"name\", \"he_lpa_merged\", \"is_redirect\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting some data to map for Waverley example\n",
    "ex_wav = lpa_ca_join[lpa_ca_join[\"reference\"] == \"E60000279\"].copy()\n",
    "\n",
    "ex_wav[\"merge_lab\"] = ex_wav[\"he_lpa_merged\"].map({1:\"_merged\", 0:\"\"})\n",
    "ex_wav[\"redirect_lab\"] = ex_wav[\"is_redirect\"].map({1:\"_redirect\", 0:\"\"})\n",
    "ex_wav[\"provider_flag\"] = ex_wav[\"name\"] + ex_wav[\"merge_lab\"] + ex_wav[\"redirect_lab\"]\n",
    "\n",
    "# ex_wav\n",
    "# ca_df[[\"entity\", \"geometry\"]].merge(\n",
    "#     ex_wav[[\"entity\", \"name\", \"provider_flag\"]]\n",
    "# ).to_csv(os.path.join(output_dir, \"entity_merging_example_waverly.csv\"), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking entity-level data for some LPAs - Doncaster\n",
    "lpa_ca_join[lpa_ca_join[\"reference\"] == \"E60000065\"].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking entity-level data for some LPAs - Somerset\n",
    "# lpa_ca_join[lpa_ca_join[\"reference\"] == \"E60000337\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdp_jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
