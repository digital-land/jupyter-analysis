{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Provision data quality report\n",
    "**Author**:  Greg Slater <br>\n",
    "**Date**:  November 2024 <br>\n",
    "**Dataset Scope**: all datasets <br>\n",
    "**Report Type**: Ad-hoc <br>\n",
    "\n",
    "## Purpose\n",
    "The purpose of this report is to measure the quality of the data that makes up each data provision on the platform, by applying a data quality framework that sets out criteria that must be met in order to reach one of 4 different quality levels. These levels are based around the quality requirements of the ODP software which uses platform data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import os\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import ipywidgets as widgets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILES_URL = 'https://datasette.planning.data.gov.uk/'\n",
    "\n",
    "def download_dataset(dataset, output_dir_path, overwrite=False):\n",
    "    dataset_file_name = f'{dataset}.db'\n",
    "    \n",
    "    if not os.path.exists(output_dir_path):\n",
    "        os.makedirs(output_dir_path)\n",
    "    \n",
    "    output_file_path = os.path.join(output_dir_path, dataset_file_name)\n",
    "\n",
    "    if overwrite is False and os.path.exists(output_file_path):\n",
    "        return\n",
    "    \n",
    "    final_url = os.path.join(FILES_URL, dataset_file_name)\n",
    "    print(f'downloading data from {final_url}')\n",
    "    print(f'to: {output_file_path}')\n",
    "    urllib.request.urlretrieve(final_url, os.path.join(output_dir_path, dataset_file_name))\n",
    "    print('download complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_sqlite(db_path, query_string):\n",
    "\n",
    "    with sqlite3.connect(db_path) as con:\n",
    "            \n",
    "        cursor = con.execute(query_string)\n",
    "        cols = [column[0] for column in cursor.description]\n",
    "        results_df = pd.DataFrame.from_records(data=cursor.fetchall(), columns=cols)\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def datasette_query(db, sql_string):\n",
    "    params = urllib.parse.urlencode({\n",
    "        \"sql\": sql_string,\n",
    "        \"_size\": \"max\"\n",
    "        })\n",
    "    url = f\"https://datasette.planning.data.gov.uk/{db}.csv?{params}\"\n",
    "    df = pd.read_csv(url)\n",
    "    return df\n",
    "\n",
    "def get_issue_lookup():\n",
    "    \n",
    "    q = \"\"\"\n",
    "    select issue_type, severity, responsibility\n",
    "    from issue_type\n",
    "\"\"\"\n",
    "    return datasette_query(\"digital-land\", q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../../data/db_downloads/\"\n",
    "os.makedirs(data_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_dataset(\"performance\", data_dir, overwrite=True)\n",
    "# download_dataset(\"article-4-direction-area\", data_dir, overwrite=True)\n",
    "# download_dataset(\"tree-preservation-zone\", data_dir, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_issue_qual = pd.read_csv(\"data/issue_type_quality.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_subset_dict = dict({\n",
    "        \"ODP\" : [\"conservation-area\", \"conservation-area-document\", \"article-4-direction-area\", \"article-4-direction\", \"listed-building-outline\", \"tree\", \"tree-preservation-zone\", \"tree-preservation-order\"],\n",
    "        \"BFL\" : [\"brownfield-land\"],\n",
    "        \"Developers\" : [\"developer-agreement\", \"developer-agreement-contribution\", \"developer-agreement-transaction\"]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE TABLE\n",
    "\n",
    "# get table of active endpoints and resources, with issue summaries per resource joined on\n",
    "q = f\"\"\"\n",
    "    SELECT \n",
    "        rhe.organisation, rhe.name as organisation_name, \n",
    "        rhe.collection, rhe.pipeline, rhe.endpoint, rhe.resource, rhe.latest_status, rhe.endpoint_entry_date, rhe.resource_start_date, \n",
    "        CAST(JULIANDAY('now') - JULIANDAY(rhe.resource_start_date) AS int) as resource_age_days,\n",
    "        its.issue_type, its.count_issues, its.severity, its.responsibility\n",
    "    FROM reporting_historic_endpoints rhe\n",
    "    LEFT JOIN endpoint_dataset_issue_type_summary its on rhe.resource = its.resource\n",
    "    WHERE 1=1\n",
    "        AND rhe.endpoint_end_date = \"\"\n",
    "        AND rhe.resource_end_date = \"\"\n",
    "        AND rhe.latest_status = 200\n",
    "\"\"\"\n",
    "\n",
    "ep_res_issues = query_sqlite(os.path.join(data_dir, \"performance.db\"), q)\n",
    "\n",
    "print(len(ep_res_issues))\n",
    "ep_res_issues.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provision lookups\n",
    "\n",
    "q = f\"\"\"\n",
    "    SELECT \n",
    "        distinct organisation, pipeline, cohort\n",
    "    FROM endpoint_dataset_resource_summary\n",
    "\"\"\"\n",
    "\n",
    "# get organisation, pipeline and cohort flag from performance table\n",
    "lookup_provision = query_sqlite(os.path.join(data_dir, \"performance.db\"), q)\n",
    "\n",
    "# lists for ODP datasets and orgs\n",
    "lookup_odp_datasets = lookup_provision[lookup_provision[\"cohort\"].str.contains(\"ODP\")][\"pipeline\"].drop_duplicates().to_list()\n",
    "lookup_odp_orgs = lookup_provision[lookup_provision[\"cohort\"].str.contains(\"ODP\")][\"organisation\"].drop_duplicates().to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup base tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FRESHNESS TABLE - flagging when provisions haven't been updated in last year\n",
    "\n",
    "# create table of old resources and flag quality level as 5\n",
    "ep_res_fresh_qual = ep_res_issues[ep_res_issues[\"resource_age_days\"] > 365][[\"collection\", \"pipeline\", \"organisation\", \"organisation_name\"]]\n",
    "\n",
    "ep_res_fresh_qual[\"issue_type\"] = \"not_fresh\"\n",
    "ep_res_fresh_qual[\"quality_category\"] = \"1 - endpoint not updated in last year\"\n",
    "ep_res_fresh_qual[\"quality_level\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ISSUES TABLE - flagging when provisions have data quality issues\n",
    "\n",
    "# join on quality key and restrict fields\n",
    "ep_res_issues_qual = ep_res_issues.merge(\n",
    "    lookup_issue_qual[[\"issue_type\", \"quality_category\", \"quality_level\"]],\n",
    "    how = \"left\",\n",
    "    on = \"issue_type\"\n",
    ")[[\"collection\", \"pipeline\", \"organisation\", \"organisation_name\", \"issue_type\", \"quality_category\", \"quality_level\"]]\n",
    "\n",
    "print(len(ep_res_issues))\n",
    "print(len(ep_res_issues_qual))\n",
    "\n",
    "# ep_res_issues_qual.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL QUALITY CATEGORIES TABLE - joining all records of quality categories (freshness & DQ issues) into one long table \n",
    "# concat tables for each type\n",
    "ep_res_qual_all = pd.concat([ep_res_issues_qual, ep_res_fresh_qual])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCORING - using quality framework levels to assign a quality level to each provision\n",
    "\n",
    "# summarise by provision, taking max quality level for each\n",
    "qual_summary = ep_res_qual_all.groupby([\n",
    "    \"collection\", \"pipeline\", \"organisation\", \"organisation_name\"\n",
    "    ],\n",
    "as_index=False,\n",
    "dropna=False\n",
    ").agg(\n",
    "    quality_level = (\"quality_level\", \"min\")\n",
    ")\n",
    "\n",
    "qual_summary.replace(np.nan, 4, inplace=True)\n",
    "\n",
    "level_map = {\n",
    "    4: \"4. excellent\",\n",
    "    3: \"3. good for ODP\",\n",
    "    2: \"2. improve\",\n",
    "    1: \"1. update\"}\n",
    "\n",
    "qual_summary[\"quality_level_label\"] = qual_summary[\"quality_level\"].map(level_map)\n",
    "print(len(qual_summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LPA and dataset table summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ODP LPA x Dataset quality table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qual_summary\n",
    "\n",
    "lookup_provision_odp = lookup_provision[\n",
    "    lookup_provision[\"cohort\"].str.contains(\"ODP\")\n",
    "    ][[\"organisation\", \"pipeline\"]].drop_duplicates()\n",
    "\n",
    " # subset and pivot\n",
    "odp_lpa_summary = qual_summary.merge(\n",
    "    lookup_provision_odp,\n",
    "    how = \"inner\",\n",
    "    on = [\"organisation\", \"pipeline\"]\n",
    ").pivot(\n",
    "    columns = \"pipeline\",\n",
    "    values = \"quality_level_label\",\n",
    "    index = [\"organisation\", \"organisation_name\"]\n",
    ").reset_index()\n",
    "\n",
    "odp_lpa_summary.replace(np.nan, \"no data\", inplace=True)\n",
    "# odp_lpa_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_colours = {\n",
    "    \"4. excellent\" : \"background-color: #1a6837\",\n",
    "    \"3. good for ODP\" : \"background-color: #87cb67\",\n",
    "    \"2. improve\" : \"background-color: #fefebf\",\n",
    "    \"1. update\" : \"background-color: #f78c51\"\n",
    "    }\n",
    "\n",
    "\n",
    "def make_color_mask_odp_lpa(df):\n",
    "    #DataFrame with same index and columns names as original filled empty strings\n",
    "    df_color_map =  pd.DataFrame(\"\", index=df.index, columns=df.columns)\n",
    "\n",
    "    flag_slice = df.columns[2:]\n",
    "    for s in flag_slice:\n",
    "        df_color_map[s] = df[s].map(level_colours)\n",
    "\n",
    "    return df_color_map\n",
    "\n",
    "# odp_lpa_summary.style.apply(make_color_mask_odp_lpa, axis=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset x quality categories table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count issues by the quality category key\n",
    "qual_cat_count = ep_res_qual_all.groupby(\n",
    "        [\"pipeline\", \"organisation\", \"organisation_name\", \"quality_category\"],\n",
    "        as_index=False\n",
    "    ).agg(\n",
    "        n_issues = (\"quality_level\", \"count\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a base table with each quality category key for each provision\n",
    "prov = ep_res_qual_all[[\"pipeline\", \"organisation\", \"organisation_name\"]].drop_duplicates()\n",
    "prov[\"key\"] = 1\n",
    "\n",
    "qual_cat = ep_res_qual_all[ep_res_qual_all[\"quality_category\"].notnull()][[\"quality_category\"]].drop_duplicates()\n",
    "qual_cat[\"key\"] = 1\n",
    "\n",
    "qual_cat_summary = prov.merge(\n",
    "    qual_cat,\n",
    "    how = \"left\",\n",
    "    on = \"key\"\n",
    ")\n",
    "print(len(qual_cat_summary))\n",
    "\n",
    "# left join on the counts to the base table\n",
    "qual_cat_summary = qual_cat_summary.merge(\n",
    "    qual_cat_count,\n",
    "    how = \"left\",\n",
    "    on = ['pipeline', 'organisation', 'organisation_name', 'quality_category']\n",
    ")\n",
    "\n",
    "# create boolean flag for each category\n",
    "qual_cat_summary[\"issue_flag\"] = np.where(qual_cat_summary[\"n_issues\"] > 0, True, False)\n",
    "print(len(qual_cat_summary))\n",
    "# qual_cat_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "level_colours = {\n",
    "        \"4. excellent\" : \"background-color: #1a6837\",\n",
    "        \"3. good for ODP\" : \"background-color: #87cb67\",\n",
    "        \"2. improve\" : \"background-color: #fefebf\",\n",
    "        \"1. update\" : \"background-color: #f78c51\"\n",
    "    }\n",
    "\n",
    "flag_colours = {\n",
    "        True : \"color:red\",\n",
    "        False : \"color:green\"\n",
    "    }\n",
    "\n",
    "def make_color_mask_dataset_lpa(df):\n",
    "    #DataFrame with same index and columns names as original filled empty strings\n",
    "    df_color_map =  pd.DataFrame(\"\", index=df.index, columns=df.columns)\n",
    "    # turn label column into colours\n",
    "    df_color_map[\"quality_level_label\"] = df[\"quality_level_label\"].map(level_colours)\n",
    "\n",
    "    flag_slice = df.columns[3:-1]\n",
    "    for s in flag_slice:\n",
    "        df_color_map[s] = df[s].map(flag_colours)\n",
    "\n",
    "    return df_color_map\n",
    "\n",
    "\n",
    "def get_dataset_lpa_summary(dataset):\n",
    "    \"\"\"\n",
    "    Given a dataset, will get a dataset subset from qual_cat_summary, \n",
    "    pivot it to have each quality category as a column, and then join\n",
    "    on the overall quality score from qual_summary.\n",
    "    \"\"\"\n",
    "\n",
    "    # subset and pivot\n",
    "    df_wide = qual_cat_summary[\n",
    "        qual_cat_summary[\"pipeline\"] == dataset\n",
    "    ].pivot(\n",
    "        columns = \"quality_category\",\n",
    "        values = \"issue_flag\",\n",
    "        index = [\"pipeline\", \"organisation\", \"organisation_name\"]\n",
    "    ).reset_index()\n",
    "\n",
    "    # join on the quality category for the provision\n",
    "    df_wide_flagged = df_wide.merge(\n",
    "        qual_summary[[\"pipeline\", \"organisation\", \"quality_level_label\"]],\n",
    "        how = \"left\",\n",
    "        on = [\"pipeline\", \"organisation\"]\n",
    "    )\n",
    "\n",
    "    return df_wide_flagged.style.apply(make_color_mask_dataset_lpa, axis=None)\n",
    "\n",
    "\n",
    "dataset_list = qual_cat_summary[\"pipeline\"].sort_values().drop_duplicates().values\n",
    "\n",
    "dataset_dropdown = widgets.Dropdown(\n",
    "    options = dataset_list,\n",
    "    value = \"conservation-area\",\n",
    "    description = \"Select Dataset: \",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALISE\n",
    "\n",
    "# qual_summary_subset = qual_summary[qual_summary[\"pipeline\"].isin(subset_bfl)]\n",
    "# qual_summary_subset = qual_summary[qual_summary[\"pipeline\"].isin(subset_dvl)]\n",
    "\n",
    "# color map to use in chart\n",
    "cmap = plt.get_cmap('RdYlGn')\n",
    "colors = [cmap(i / 4) for i in np.arange(1, 5)]\n",
    "\n",
    "def make_quality_overview_chart(subset):\n",
    "    \"\"\"\n",
    "    Uses the qual summary table to display a horizontal bar chart \n",
    "    \"\"\"\n",
    "\n",
    "    qual_summary_subset = qual_summary[qual_summary[\"pipeline\"].isin(dataset_subset_dict[subset])]\n",
    "\n",
    "    # count providers by dataset & quality level\n",
    "    qual_chart = qual_summary_subset.groupby([\"pipeline\", \"quality_level\", \"quality_level_label\"], as_index=False).agg(\n",
    "        n_providers = (\"quality_level\", \"count\")\n",
    "    )\n",
    "\n",
    "    qual_chart.sort_values([\"pipeline\", \"quality_level_label\"], inplace=True)\n",
    "    qual_chart_wide = qual_chart.pivot(columns = \"quality_level_label\", values = \"n_providers\", index = \"pipeline\")\n",
    "    \n",
    "    qual_chart_wide.plot.barh(\n",
    "        stacked = True, \n",
    "        color = colors, \n",
    "        figsize = (9, 6))\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('Count of providers')\n",
    "    plt.ylabel('Dataset')\n",
    "    plt.title('Quality levels for ODP datasets')\n",
    "    plt.legend(title='Quality level')\n",
    "\n",
    "    return plt.show()\n",
    "\n",
    "\n",
    "subset_dropdown = widgets.Dropdown(\n",
    "    options = dataset_subset_dict.keys(),\n",
    "    # value = dataset_list[0],\n",
    "    description = \"Select Dataset subset: \",\n",
    ")\n",
    "\n",
    "# widgets.interact(make_quality_overview_chart, subset = subset_dropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data quality overview chart - by dataset groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widgets.interact(make_quality_overview_chart, subset = subset_dropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ODP LPA overview table by dataset & quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odp_lpa_summary.style.apply(make_color_mask_odp_lpa, axis=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset quality scoring detail table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widgets.interact(get_dataset_lpa_summary, dataset = dataset_dropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quality investigations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qual_summary_subset[qual_summary_subset[\"pipeline\"] == \"tree\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qual_chart.groupby([\"quality_level\", \"quality_level_label\"], as_index = False).agg(\n",
    "    total = (\"n_providers\", \"sum\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check some specifics - conservation area \"update\"\n",
    "\n",
    "dataset = \"conservation-area\"\n",
    "level = 4\n",
    "\n",
    "level_provisions = ep_res_qual_all[\n",
    "    (ep_res_qual_all[\"pipeline\"] == dataset) & \n",
    "    (ep_res_qual_all[\"quality_level\"] == level)][\n",
    "        [\"pipeline\", \"organisation\"]\n",
    "    ].drop_duplicates()\n",
    "\n",
    "level_prov_all_issues = level_provisions.merge(\n",
    "    ep_res_qual_all,\n",
    "    how = \"left\", \n",
    "    on = [\"pipeline\", \"organisation\"]\n",
    "    )\n",
    "\n",
    "level_prov_all_issues[level_prov_all_issues[\"quality_level\"].notnull()].drop_duplicates().groupby([\"issue_type\"], as_index=False).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check some specifics - conservation area \"update\"\n",
    "\n",
    "dataset = \"tree-preservation-zone\"\n",
    "level = 3\n",
    "\n",
    "level_provisions = qual_summary[\n",
    "    (qual_summary[\"pipeline\"] == dataset) & \n",
    "    (qual_summary[\"quality_level\"] == level)][\n",
    "        [\"pipeline\", \"organisation\"]\n",
    "    ].drop_duplicates()\n",
    "\n",
    "level_prov_all_issues = level_provisions.merge(\n",
    "    ep_res_qual_all,\n",
    "    how = \"left\", \n",
    "    on = [\"pipeline\", \"organisation\"]\n",
    "    )\n",
    "\n",
    "level_prov_all_issues[level_prov_all_issues[\"quality_level\"].notnull()].drop_duplicates().groupby([\"issue_type\"], as_index=False).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provision view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prov_summary_now = ep_res_issues[[\"organisation\", \"organisation_name\", \"collection\", \"pipeline\"]].drop_duplicates().groupby(\n",
    "    [\"collection\", \"pipeline\"], as_index=False\n",
    "    ).agg(\n",
    "    n_providers = (\"organisation\", \"size\")\n",
    ")\n",
    "\n",
    "prov_summary_now.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get table of active endpoints and resources, with issue summaries per resource joined on\n",
    "q = f\"\"\"\n",
    "    SELECT \n",
    "        organisation, organisation_name, dataset, active_endpoint_count,\n",
    "        CASE WHEN active_endpoint_count > 0 then 1 else 0 end as active_endpoint_flag\n",
    "    FROM provision_summary \n",
    "\"\"\"\n",
    "\n",
    "prov_all = query_sqlite(os.path.join(data_dir, \"performance.db\"), q)\n",
    "prov_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prov_summary_now = prov_all.groupby(\n",
    "    [\"dataset\"], as_index=False\n",
    "    ).agg(\n",
    "    n_providers = (\"active_endpoint_flag\", \"sum\"),\n",
    "    n_expected = (\"active_endpoint_flag\", \"size\")\n",
    ")\n",
    "\n",
    "prov_summary_now[\"trusted_data\"] = prov_summary_now[\"n_providers\"]\n",
    "prov_summary_now[\"no_data\"] = prov_summary_now[\"n_expected\"] - prov_summary_now[\"n_providers\"]\n",
    "\n",
    "prov_summary_now.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prov_summary_chart = prov_summary_now[prov_summary_now[\"dataset\"].isin(subset_odp)]\n",
    "\n",
    "prov_summary_chart[[\"dataset\", \"trusted_data\", \"no_data\"]].plot.bar(x = \"dataset\", stacked = True, color = [\"black\", \"#d4d4d4\"])\n",
    "\n",
    "plt.ylabel('n providers')\n",
    "plt.title(f'Current provision for ODP datasets')\n",
    "plt.legend(title='Data type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Historic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_active_endpoints(dataset, date):\n",
    "\n",
    "    q = f\"\"\"\n",
    "        select distinct pipeline as dataset, name, DATE('{date}') as active_date, endpoint_entry_date, endpoint_end_date\n",
    "        from reporting_historic_endpoints \n",
    "        where\n",
    "            pipeline = '{dataset}'\n",
    "            and endpoint_entry_date <= DATE('{date}')\n",
    "            and (\n",
    "                endpoint_end_date > DATE('{date}')\n",
    "                or endpoint_end_date = \"\")\n",
    "\"\"\"\n",
    "    \n",
    "    df = query_sqlite(os.path.join(data_dir, \"performance.db\"), q)\n",
    "\n",
    "    return df\n",
    "\n",
    "# test = get_active_endpoints(\"tree-preservation-zone\", \"2024-07-11\")\n",
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"brownfield-land\"\n",
    "\n",
    "date_range = pd.date_range(end = \"20241001\", periods = 24, freq = \"MS\").format(\"%Y-%m-%d\")\n",
    "\n",
    "prov_hist = [get_active_endpoints(dataset, d) for d in date_range[1:-1]]\n",
    "prov_hist_df = pd.concat(prov_hist)\n",
    "\n",
    "prov_summary_hist = prov_hist_df[[\"dataset\", \"name\", \"active_date\"]].drop_duplicates().groupby([\"active_date\", \"dataset\"], as_index = False).agg(\n",
    "    n_providers = (\"dataset\", \"size\")\n",
    ")\n",
    "\n",
    "print(len(prov_summary_hist))\n",
    "prov_summary_hist = prov_summary_hist.merge(\n",
    "    prov_summary_now[[\"dataset\", \"n_expected\"]],\n",
    "    how = \"left\",\n",
    "    on = \"dataset\"\n",
    ")\n",
    "\n",
    "prov_summary_hist[\"trusted_data\"] = prov_summary_hist[\"n_providers\"]\n",
    "prov_summary_hist[\"no_data\"] = prov_summary_hist[\"n_expected\"] - prov_summary_hist[\"n_providers\"]\n",
    "\n",
    "print(len(prov_summary_hist))\n",
    "# prov_summary_hist\n",
    "prov_summary_hist[[\"dataset\", \"active_date\", \"trusted_data\", \"no_data\"]].plot.area(x = \"active_date\", stacked = True, color = [\"black\", \"#d4d4d4\"])\n",
    "\n",
    "plt.xlabel('date')\n",
    "plt.ylabel('n providers')\n",
    "plt.title(f'Historic provision for: {dataset}')\n",
    "plt.legend(title='Data type')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdp_jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
