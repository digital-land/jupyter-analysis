{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d259be9-807c-4bf2-87d4-f5c88caf55e9",
   "metadata": {},
   "source": [
    "## Examining duplication Between Organisations\n",
    "\n",
    "In our data we often recieve multiple data sources per dataset. unfortunately this leads to duplication of geometries and other data points in the datasets. this notebook looks to investigate identifying these duplications between organisations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a279bd2a-487f-4496-8a2e-ba50e8de9070",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from download_data import download_dataset\n",
    "# from data import get_entity_dataset, nrow\n",
    "# from plot import plot_map, plot_issues_map\n",
    "import spatialite\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import itertools\n",
    "import shapely.wkt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import urllib\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aefbc24",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ddc2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nrow(df):\n",
    "    return print(f\"No. of records in df: {len(df):,}\")\n",
    "\n",
    "\n",
    "def plot_issues_map(gdf:gpd.GeoDataFrame, entity_list, chloro_var, palette):\n",
    "\n",
    "    if type(gdf) != gpd.GeoDataFrame:\n",
    "        logging.error('input is not a GeodataFrame')\n",
    "    \n",
    "    base = gdf[gdf[\"entity\"].isin(entity_list)].explore(\n",
    "        column = chloro_var,  # make choropleth based on \"BoroName\" column\n",
    "        cmap = palette,\n",
    "        tooltip = False,\n",
    "        popup = [\"organisation_name\", \"entity\", \"name\", \"reference\"],\n",
    "        tiles = \"CartoDB positron\",  # use \"CartoDB positron\" tiles\n",
    "        highlight = False,\n",
    "        style_kwds = {\n",
    "        \"fillOpacity\" : \"0.1\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c4f722",
   "metadata": {},
   "source": [
    "### Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade8f0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_organisations():\n",
    "    params = urllib.parse.urlencode({\n",
    "        \"sql\": f\"\"\"\n",
    "        select organisation, name, entity as organisation_entity, statistical_geography\n",
    "        from organisation\n",
    "        \"\"\",\n",
    "        \"_size\": \"max\"\n",
    "        })\n",
    "    url = f\"https://datasette.planning.data.gov.uk/digital-land.csv?{params}\"\n",
    "    df = pd.read_csv(url)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f4a672",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_org = get_all_organisations()\n",
    "\n",
    "lookup_org[\"organisation_entity\"] = lookup_org[\"organisation_entity\"].astype(str)\n",
    "lookup_org.columns = [\"organisation\", \"organisation_name\", \"organisation_entity\", \"statistical_geography\"]\n",
    "\n",
    "nrow(lookup_org)\n",
    "lookup_org.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fcc39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LAD boundary\n",
    "\n",
    "LAD_boundary_df_all = pd.read_csv(\"https://files.planning.data.gov.uk/dataset/local-authority-district.csv\")\n",
    "LAD_boundary_df = LAD_boundary_df_all[[\"name\", \"reference\", \"geometry\"]]\n",
    "LAD_boundary_df.columns = [\"LAD20NM\", \"LAD20CD\", \"geometry\"]\n",
    "\n",
    "\n",
    "# load geometry and create GDF\n",
    "LAD_boundary_df['geometry'] = LAD_boundary_df['geometry'].apply(shapely.wkt.loads)\n",
    "LAD_boundary_gdf = gpd.GeoDataFrame(LAD_boundary_df, geometry='geometry')\n",
    "\n",
    "# Transform to ESPG:27700 for more interpretable area units\n",
    "LAD_boundary_gdf.set_crs(epsg=4326, inplace=True)\n",
    "LAD_boundary_gdf.to_crs(epsg=27700, inplace=True)\n",
    "nrow(LAD_boundary_gdf)\n",
    "LAD_boundary_gdf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4f9db0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load conservation area entity dataset into geopandas and transform CRS to EPSG:27700\n",
    "\n",
    "entity_df_all = pd.read_csv(\"https://files.planning.data.gov.uk/dataset/conservation-area.csv\")\n",
    "            \n",
    "# entity_df.head()\n",
    "entity_df_all.columns = [x.replace(\"-\", \"_\") for x in entity_df_all.columns]\n",
    "\n",
    "entity_df = entity_df_all[[\"entity\", \"name\", \"organisation_entity\", \"reference\", \"geometry\"]]\n",
    "\n",
    "\n",
    "# set entity to string, helpful for sorting and joining later\n",
    "entity_df[\"entity\"] = entity_df[\"entity\"].astype(str)\n",
    "entity_df[\"organisation_entity\"] = entity_df[\"organisation_entity\"].astype(str)\n",
    "\n",
    "# join organisation name\n",
    "entity_df = entity_df.merge(\n",
    "    lookup_org.iloc[:, 1:4], \n",
    "    how = \"left\",\n",
    "    on = \"organisation_entity\")\n",
    "\n",
    "# load geometry and create GDF\n",
    "entity_df['geometry'] = entity_df['geometry'].apply(shapely.wkt.loads)\n",
    "entity_gdf = gpd.GeoDataFrame(entity_df, geometry='geometry')\n",
    "\n",
    "# Transform to ESPG:27700 for more interpretable area units\n",
    "entity_gdf.set_crs(epsg=4326, inplace=True)\n",
    "entity_gdf.to_crs(epsg=27700, inplace=True)\n",
    "\n",
    "# calculate area\n",
    "entity_gdf[\"area\"] = entity_gdf[\"geometry\"].area\n",
    "\n",
    "\n",
    "nrow(entity_gdf)\n",
    "entity_gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e509bf8b",
   "metadata": {},
   "source": [
    "# Identifying geographical duplicates\n",
    "\n",
    "## #1 - Duplication within organisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a708a928",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Overlay all non-Heritage England entities\n",
    "LPA_LPA_join = gpd.overlay(\n",
    "    entity_gdf[entity_gdf[\"organisation_entity\"] != \"16\"],\n",
    "    entity_gdf[entity_gdf[\"organisation_entity\"] != \"16\"],\n",
    "    how = \"intersection\", keep_geom_type=False \n",
    ")\n",
    "\n",
    "# remove entity self-intersections and intersections across organisations\n",
    "LPA_LPA_join = LPA_LPA_join[(LPA_LPA_join[\"organisation_entity_1\"] == LPA_LPA_join[\"organisation_entity_2\"]) &\n",
    "             (LPA_LPA_join[\"entity_1\"] != LPA_LPA_join[\"entity_2\"])]\n",
    "\n",
    "# each intersection will be in there twice because we're joining the same dataset \n",
    "# (e.g. polygon1-polygon2 and polygon2-polygon1), so remove these\n",
    "LPA_LPA_join[\"entity_join\"] = LPA_LPA_join.apply(lambda x: '-'.join(sorted(x[[\"entity_1\", \"entity_2\"]])), axis=1)\n",
    "LPA_LPA_join.drop_duplicates(subset=\"entity_join\", inplace = True) #Drop them by name\n",
    "\n",
    "# calculate overlap %'s\n",
    "\n",
    "LPA_LPA_join[\"area_intersection\"] = LPA_LPA_join[\"geometry\"].area\n",
    "\n",
    "# LPA_LPA_join[\"p_pct_intersect\"] = LPA_LPA_join[\"area_intersection\"] / LPA_LPA_join[\"area_1\"]\n",
    "# LPA_LPA_join[\"pct_intersection\"] = LPA_LPA_join[\"area_intersection\"] / (LPA_LPA_join[\"area_1\"] + LPA_LPA_join[\"area_2\"] - LPA_LPA_join[\"area_intersection\"])\n",
    "# LPA_LPA_join[\"s_pct_intersect\"] = LPA_LPA_join[\"area_intersection\"] / LPA_LPA_join[\"area_2\"]\n",
    "\n",
    "# intersection area as % of smallest primary or secondary area\n",
    "LPA_LPA_join[\"pct_min_intersection\"] = LPA_LPA_join[\"area_intersection\"] / LPA_LPA_join[[\"area_1\", \"area_2\"]].min(axis = 1)\n",
    "\n",
    "nrow(LPA_LPA_join)\n",
    "LPA_LPA_join.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9621e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick check of distribution to check how many are edges vs. major overlaps\n",
    "plt.hist(LPA_LPA_join[\"pct_min_intersection\"], bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc648ba9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# how many entities with a greater than 10% intersection?\n",
    "nrow(LPA_LPA_join[(LPA_LPA_join[\"pct_min_intersection\"] > 0.1)])\n",
    "\n",
    "LPA_LPA_join[(LPA_LPA_join[\"pct_min_intersection\"] > 0.1)].sort_values(\"pct_min_intersection\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ed5bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "LPA_LPA_join[(LPA_LPA_join[\"pct_min_intersection\"] > 0.1)].groupby([\"organisation_name_1\"]).size().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2b3dff",
   "metadata": {},
   "source": [
    "**notes from run through with Swati**\n",
    "\n",
    "solution - go back to LPA\n",
    "possible explanation - data is coming from different endpoint, and first one is not retired. Need to rule this out before we go back to LPA.\n",
    "\n",
    "When new endpoint is added, we want to keep both. Want to keep record of data over time. Platform should only present latest version.\n",
    "Need to understand entity creation process a little bit more to understand how geo duplicates could get made - talk to Kena."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc37eaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect example\n",
    "plot_issues_map(entity_gdf, [\"44008830\", \"44006848\"], \"entity\", \"Accent\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3c8c32",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_issues_map(entity_gdf, [\"44007790\", \"44007829\"], \"entity\", \"Accent\")\n",
    "# inspect_issues_map(entity_gdf, [\"44000557\", \"44000556\"], \"Accent\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5f3016",
   "metadata": {},
   "source": [
    "## #2 - Intersection across different LPAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ff4559",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Overlay all non-Heritage England entities\n",
    "LPA_cross_join = gpd.overlay(\n",
    "    entity_gdf[entity_gdf[\"organisation_entity\"] != \"16\"],\n",
    "    entity_gdf[entity_gdf[\"organisation_entity\"] != \"16\"],\n",
    "    how = \"intersection\", keep_geom_type=False \n",
    ")\n",
    "\n",
    "# filter to join across organisations and entities\n",
    "LPA_cross_join = LPA_cross_join[(LPA_cross_join[\"organisation_entity_1\"] != LPA_cross_join[\"organisation_entity_2\"]) &\n",
    "             (LPA_cross_join[\"entity_1\"] != LPA_cross_join[\"entity_2\"])]\n",
    "\n",
    "# each intersection will be in there twice because we're joining the same dataset \n",
    "# (e.g. polygon1-polygon2 and polygon2-polygon1), so remove these\n",
    "LPA_cross_join[\"entity_join\"] = LPA_cross_join.apply(lambda x: '-'.join(sorted(x[[\"entity_1\", \"entity_2\"]])), axis=1)\n",
    "LPA_cross_join.drop_duplicates(subset=\"entity_join\", inplace = True) #Drop them by name\n",
    "\n",
    "# # calculate overlap %'s\n",
    "\n",
    "LPA_cross_join[\"area_intersection\"] = LPA_cross_join[\"geometry\"].area\n",
    "\n",
    "# # LPA_LPA_join[\"p_pct_intersect\"] = LPA_LPA_join[\"area_intersection\"] / LPA_LPA_join[\"area_1\"]\n",
    "# # LPA_LPA_join[\"pct_intersection\"] = LPA_LPA_join[\"area_intersection\"] / (LPA_LPA_join[\"area_1\"] + LPA_LPA_join[\"area_2\"] - LPA_LPA_join[\"area_intersection\"])\n",
    "# # LPA_LPA_join[\"s_pct_intersect\"] = LPA_LPA_join[\"area_intersection\"] / LPA_LPA_join[\"area_2\"]\n",
    "\n",
    "# intersection area as % of smallest primary or secondary area\n",
    "LPA_cross_join[\"pct_min_intersection\"] = LPA_cross_join[\"area_intersection\"] / LPA_cross_join[[\"area_1\", \"area_2\"]].min(axis = 1)\n",
    "\n",
    "nrow(LPA_cross_join)\n",
    "LPA_cross_join.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dac7d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at distribution to check how many are edges vs. major overlaps\n",
    "plt.hist(LPA_cross_join[\"pct_min_intersection\"], bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d22cedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many entities which have issues of intersection > 10%? \n",
    "LPA_cross_join[(LPA_cross_join[\"pct_min_intersection\"] > 0.1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11c7ca5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "e = \"44009059\"\n",
    "ents = LPA_cross_join[(LPA_cross_join[\"entity_1\"] == e)][[\"entity_1\", \"entity_2\"]].iloc[0, :].values\n",
    "\n",
    "plot_issues_map(entity_gdf, ents, \"organisation_name\", \"Accent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e1f00b",
   "metadata": {},
   "source": [
    "**notes from run-through with Swati**   \n",
    "feed in LPA boundaries here to make sure we contact the right LPA - change this query to use LPA boundaries.\n",
    "check with Carlos for how it's been done for brownfield"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacffd08",
   "metadata": {},
   "source": [
    "## #2.b - Beyond-border data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc89557d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab proper geography codes for entities and restrict to those which are actually in the LAD file\n",
    "\n",
    "dataset_orgs = entity_df[[\"organisation_entity\", \"organisation_name\"]].drop_duplicates()\n",
    "\n",
    "org_geog_code_lookup = dataset_orgs.merge(\n",
    "    lookup_org, how = \"inner\", on = \"organisation_entity\"\n",
    "    ).merge(\n",
    "        LAD_boundary_gdf[[\"LAD20CD\"]], how = \"inner\", left_on = \"statistical_geography\", right_on=\"LAD20CD\"\n",
    "    )\n",
    "\n",
    "# how many organisations don't have a geog code in the LAD file?\n",
    "dataset_orgs_no_code = dataset_orgs[~dataset_orgs[\"organisation_entity\"].isin(org_geog_code_lookup[\"organisation_entity\"])]\n",
    "\n",
    "print(f\"total orgs in dataset: {len(dataset_orgs)}\")\n",
    "print(f\"total orgs in dataset without 2020 LAD geog code: {len(dataset_orgs_no_code)}\")\n",
    "\n",
    "\n",
    "nrow(org_geog_code_lookup)\n",
    "org_geog_code_lookup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ee03f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cons_boundary_merge = entity_gdf.merge(org_geog_code_lookup[[\"organisation_entity\", \"LAD20CD\"]], how = \"inner\", on = \"organisation_entity\")\n",
    "\n",
    "nrow(entity_gdf)\n",
    "nrow(cons_boundary_merge)\n",
    "\n",
    "LAD_boundaries_merge = LAD_boundary_gdf[LAD_boundary_gdf[\"LAD20CD\"].isin(org_geog_code_lookup[\"LAD20CD\"])]\n",
    "\n",
    "nrow(LAD_boundary_gdf)\n",
    "nrow(LAD_boundaries_merge)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119bb35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull through geog code to entity table and also restict to just entities with a geog which exists in the LAD table\n",
    "cons_boundary_merge = entity_gdf.merge(\n",
    "    org_geog_code_lookup[[\"organisation_entity\", \"LAD20CD\"]], \n",
    "    how = \"inner\", \n",
    "    on = \"organisation_entity\")\n",
    "\n",
    "# buffer LAD boundaries by 50m (this is to allow for some edge intersections)\n",
    "# LAD_boundaries_buf_gdf = LAD_boundary_gdf\n",
    "# LAD_boundaries_buf_gdf[\"geometry\"] = LAD_boundaries_buf_gdf[\"geometry\"].buffer(50)\n",
    "\n",
    "geogs_out_entities = []\n",
    "\n",
    "for code in list(org_geog_code_lookup[\"LAD20CD\"]):\n",
    "\n",
    "    cons_areas = cons_boundary_merge[cons_boundary_merge[\"LAD20CD\"] == code]\n",
    "    mask = cons_areas.geometry.intersects(LAD_boundary_gdf[LAD_boundary_gdf[\"LAD20CD\"] == code].iloc[0].geometry)\n",
    "\n",
    "    geogs_out_entities.extend(cons_areas.loc[~mask][\"entity\"].to_list())\n",
    "\n",
    "print(len(geogs_out_entities))\n",
    "entity_outside_LPA_df = cons_boundary_merge[cons_boundary_merge[\"entity\"].isin(geogs_out_entities)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e564f1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of LADs with entities outside them\n",
    "LADs_with_bads = entity_outside_LPA_df[\"LAD20CD\"].drop_duplicates().to_list()\n",
    "\n",
    "print(len(LADs_with_bads))\n",
    "entity_outside_LPA_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44663791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# areas with weird ones: Babergh (3)\n",
    "\n",
    "# map for LAD with entities outside it\n",
    "\n",
    "LAD_code = LADs_with_bads[0]\n",
    "\n",
    "base = entity_outside_LPA_df[entity_outside_LPA_df[\"LAD20CD\"] == LAD_code].explore(\n",
    "        # column = chloro_var,  # make choropleth based on \"BoroName\" column\n",
    "        # cmap = palette,\n",
    "    color = \"red\",\n",
    "        # tooltip = False,\n",
    "        # popup = [\"organisation_name\", \"entity\", \"name\", \"reference\"],\n",
    "        tiles = \"CartoDB positron\",  # use \"CartoDB positron\" tiles\n",
    "        highlight = False,\n",
    "        style_kwds = {\n",
    "        \"fillOpacity\" : \"0.1\"\n",
    "        }\n",
    ")\n",
    "\n",
    "LAD_boundary_gdf[LAD_boundary_gdf[\"LAD20CD\"] == LAD_code].explore(\n",
    "    m = base,\n",
    "    color = \"blue\",\n",
    "        style_kwds = {\n",
    "        \"fillOpacity\" : \"0\"\n",
    "        }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d192b28f",
   "metadata": {},
   "source": [
    "## Issue #3 LPA => Historic England intersections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1772ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = time.time()\n",
    "\n",
    "LPA_HE_join = gpd.overlay(\n",
    "    entity_gdf[entity_gdf[\"organisation_entity\"] != \"16\"],\n",
    "    entity_gdf[entity_gdf[\"organisation_entity\"] == \"16\"],\n",
    "    how = \"intersection\", keep_geom_type=False\n",
    ")\n",
    "\n",
    "LPA_HE_join[\"area_intersection\"] = LPA_HE_join[\"geometry\"].area\n",
    "\n",
    "LPA_HE_join[\"p_pct_intersect\"] = LPA_HE_join[\"area_intersection\"] / LPA_HE_join[\"area_1\"]\n",
    "LPA_HE_join[\"pct_intersection\"] = LPA_HE_join[\"area_intersection\"] / (LPA_HE_join[\"area_1\"] + LPA_HE_join[\"area_2\"] - LPA_HE_join[\"area_intersection\"])\n",
    "LPA_HE_join[\"s_pct_intersect\"] = LPA_HE_join[\"area_intersection\"] / LPA_HE_join[\"area_2\"]\n",
    "\n",
    "\n",
    "# intersection area as % of smallest primary or secondary area\n",
    "LPA_HE_join[\"pct_min_intersection\"] = LPA_HE_join[\"area_intersection\"] / LPA_HE_join[[\"area_1\", \"area_2\"]].min(axis = 1)\n",
    "\n",
    "\n",
    "# end_time = time.time()\n",
    "\n",
    "# elapsed_time = (end_time - start_time) \n",
    "# print(f\"Elapsed time: {elapsed_time:.2f} \")\n",
    "\n",
    "nrow(LPA_HE_join)\n",
    "LPA_HE_join.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dc94b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the issues by the amount the two entities which make up each issue intersect each other\n",
    "# this is useful to start to define categories for the types of issues they represent\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.grid()\n",
    "plt.scatter(LPA_HE_join[\"p_pct_intersect\"], LPA_HE_join[\"s_pct_intersect\"], s = 8, alpha=0.6)\n",
    "fig.suptitle('Entity intersection %s', fontsize=14)\n",
    "plt.xlabel('% of LPA entity intersected', fontsize=10)\n",
    "plt.ylabel('% of Historic England entity intersected', fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8644be09",
   "metadata": {},
   "source": [
    "By the number of points on the far right of the chart we can see that there are a lot of LPA entities which are entirely or almost entirely contained within an HE entity, but how closely the HE area matches varies from not at all to almost exactly.\n",
    "\n",
    "Bottom left is a cluster of tiny edge intersections, and there are a small number of instances where HE entities are contained within LPA ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9964944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flag issue types - defined to pick up main issue clusters on chart above and using a 90% or 10% intersection cutoffs\n",
    "\n",
    "LPA_HE_join[\"issue_type\"] = np.select(\n",
    "    [\n",
    "        (LPA_HE_join[\"p_pct_intersect\"] >= 0.9) & (LPA_HE_join[\"s_pct_intersect\"] >= 0.9),\n",
    "        (LPA_HE_join[\"p_pct_intersect\"] <= 0.1) & (LPA_HE_join[\"s_pct_intersect\"] <= 0.1),\n",
    "        (LPA_HE_join[\"p_pct_intersect\"] >= 0.9),\n",
    "        (LPA_HE_join[\"s_pct_intersect\"] >= 0.9)\n",
    "    ],\n",
    "    [\n",
    "        \"LPA and HE cover each other\", \"edge intersection\", \"LPA covered by HE\", \"LPA covers HE\"\n",
    "    ],\n",
    "    default = \"-\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb861676",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# LPA_HE_join[(LPA_HE_join[\"pct_intersection\"] >= 0.9)].sort_values(\"pct_intersection\")\n",
    "# LPA_HE_join[(LPA_HE_join[\"issue_type\"] == \"LPA covers HE\")].sort_values(\"pct_intersection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81d94cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# count of issue types (where cover is defined as >=90% intersection, and edge as <=10%)\n",
    "LPA_HE_join.groupby([\"issue_type\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c200296c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LPAs with most non-intersection issues\n",
    "LPA_HE_join[(LPA_HE_join[\"issue_type\"] != \"edge intersection\")].groupby([\"organisation_name_1\"]).size().sort_values(ascending = False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d277ab",
   "metadata": {},
   "source": [
    "### Issue examples by type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35de951",
   "metadata": {},
   "source": [
    "#### LPA and HE cover each other (almost perfect matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e285dd",
   "metadata": {},
   "source": [
    "- need to get to the bottom of authority here, who can create conservation areas\n",
    "- could we just switch off HE conservation areas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0099304",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "e = \"44008960\"\n",
    "ents = LPA_HE_join[(LPA_HE_join[\"entity_1\"] == e)][[\"entity_1\", \"entity_2\"]].iloc[0, :].values\n",
    "\n",
    "plot_issues_map(entity_gdf, ents, \"organisation_name\", \"Accent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85e4960",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = \"44008960\"\n",
    "LPA_HE_join[(LPA_HE_join[\"entity_1\"] == e)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6dac94",
   "metadata": {},
   "source": [
    "\n",
    "#### LPA covered by HE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbffcf2e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "e = \"44000540\"\n",
    "ents = LPA_HE_join[(LPA_HE_join[\"entity_1\"] == e)][[\"entity_1\", \"entity_2\"]].iloc[0, :].values\n",
    "\n",
    "plot_issues_map(entity_gdf, ents, \"organisation_name\", \"Accent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc97495",
   "metadata": {},
   "source": [
    "\n",
    "#### LPA covers HE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69f21b7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "e = \"44009160\"\n",
    "ents = LPA_HE_join[(LPA_HE_join[\"entity_1\"] == e)][[\"entity_1\", \"entity_2\"]].iloc[0, :].values\n",
    "\n",
    "plot_issues_map(entity_gdf, ents, \"organisation_name\", \"Accent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dbbb6a",
   "metadata": {},
   "source": [
    "#### Edge intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115bed8d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "e = \"44006512\"\n",
    "ents = LPA_HE_join[(LPA_HE_join[\"entity_1\"] == e)][[\"entity_1\", \"entity_2\"]].iloc[0, :].values\n",
    "\n",
    "plot_issues_map(entity_gdf, ents, \"organisation_name\", \"Accent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56523059",
   "metadata": {},
   "source": [
    "#### Entities with multiple issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f87f919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LPA_HE_join[(LPA_HE_join[\"entity_1\"] == \"44006512\")]\n",
    "\n",
    "entity_count = LPA_HE_join.groupby([\"entity_1\"]).size().reset_index()\n",
    "entity_count.columns = [\"entity_1\", \"count\"]\n",
    "entity_count[entity_count[\"count\"] > 1].sort_values('count', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e790c295",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = LPA_HE_join[LPA_HE_join[\"entity_1\"] == \"44009667\"]\n",
    "\n",
    "# grab all entities that have an issue with  44009667\n",
    "te = np.concatenate((\n",
    "    t[\"entity_1\"].drop_duplicates().values,\n",
    "    t[\"entity_2\"].drop_duplicates().values\n",
    "))\n",
    "\n",
    "plot_issues_map(entity_gdf, te, \"organisation_name\", \"Accent\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e95126",
   "metadata": {},
   "source": [
    "#### Entities with non-classified issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f5e87f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# these are really just entities which have overlaps > 10% but less than 90% in one form \n",
    "LPA_HE_join[(LPA_HE_join[\"issue_type\"] == \"-\")].sort_values(\"pct_min_intersection\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa917918",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d95dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a7916e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at entity re-directs\n",
    "entity_df[entity_df[\"entity\"].isin([\"44000549\", \"44008664\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30049c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# e = \"44000540\"\n",
    "# ents = LPA_HE_join[(LPA_HE_join[\"entity_1\"] == e)][[\"entity_1\", \"entity_2\"]].iloc[0, :].values\n",
    "\n",
    "plot_issues_map(entity_gdf, [\"44000549\", \"44008664\"], \"organisation_name\", \"Accent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c765062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at entity re-directs\n",
    "entity_df[entity_df[\"organisation_name\"] == \"London Borough of Lambeth\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8215628",
   "metadata": {},
   "outputs": [],
   "source": [
    "LPA_HE_join[LPA_HE_join[\"organisation_name_1\"] == \"London Borough of Lambeth\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1716950c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cce91c47",
   "metadata": {},
   "source": [
    "## Questions to resolve\n",
    "* how to find endpoint / resource for each entity?\n",
    "* what existing issues / replacements have been documented for the dataset?\n",
    "* which entity takes precedence? Oldest / newest?\n",
    "* what threshold to set for removing duplicates?\n",
    "* how to extract data required for updating through lookups file\n",
    "* how to replicate this check in endpoint checker with a new dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdp_jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
