{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d259be9-807c-4bf2-87d4-f5c88caf55e9",
   "metadata": {},
   "source": [
    "## Examining duplication Between Organisations\n",
    "\n",
    "In our data we often recieve multiple data sources per dataset. unfortunately this leads to duplication of geometries and other data points in the datasets. this notebook looks to investigate identifying these duplications between organisations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a279bd2a-487f-4496-8a2e-ba50e8de9070",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from download_data import download_dataset\n",
    "# from data import get_entity_dataset, nrow\n",
    "# from plot import plot_map, plot_issues_map\n",
    "import spatialite\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import itertools\n",
    "import shapely.wkt\n",
    "import logging\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import urllib\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "022dabbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if running on Colab, uncomment and run this line below too:\n",
    "# !pip install mapclassify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aefbc24",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "73ddc2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nrow(df):\n",
    "    return print(f\"No. of records in df: {len(df):,}\")\n",
    "\n",
    "\n",
    "def plot_issues_map(gdf:gpd.GeoDataFrame, entity_link, chloro_var, palette):\n",
    "\n",
    "    if type(gdf) != gpd.GeoDataFrame:\n",
    "        logging.error('input is not a GeodataFrame')\n",
    "\n",
    "    entity_list = entity_link.split('-')\n",
    "    \n",
    "    base = gdf[gdf[\"entity\"].isin(entity_list)].explore(\n",
    "        column = chloro_var,  # make choropleth based on \"BoroName\" column\n",
    "        cmap = palette,\n",
    "        tooltip = False,\n",
    "        popup = [\"organisation_name\", \"entity\", \"name\", \"entry_date\", \"reference\"],\n",
    "        tiles = \"CartoDB positron\",  # use \"CartoDB positron\" tiles\n",
    "        highlight = False,\n",
    "        style_kwds = {\n",
    "        \"fillOpacity\" : \"0.1\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return base\n",
    "\n",
    "def get_all_organisations():\n",
    "    params = urllib.parse.urlencode({\n",
    "        \"sql\": f\"\"\"\n",
    "        select organisation, name, entity as organisation_entity, statistical_geography\n",
    "        from organisation\n",
    "        \"\"\",\n",
    "        \"_size\": \"max\"\n",
    "        })\n",
    "    url = f\"https://datasette.planning.data.gov.uk/digital-land.csv?{params}\"\n",
    "    df = pd.read_csv(url)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_old_entity(collection_name):\n",
    "    params = urllib.parse.urlencode({\n",
    "        \"sql\": f\"\"\"\n",
    "        select *\n",
    "        from old_entity\n",
    "        \"\"\",\n",
    "        \"_size\": \"max\"\n",
    "        })\n",
    "    url = f\"https://datasette.planning.data.gov.uk/{collection_name}.csv?{params}\"\n",
    "    df = pd.read_csv(url)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c4f722",
   "metadata": {},
   "source": [
    "### Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "61a7b5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of records in df: 376\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>organisation_entity</th>\n",
       "      <th>LADCD</th>\n",
       "      <th>LPACD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>E07000223</td>\n",
       "      <td>E60000281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>E07000026</td>\n",
       "      <td>E60000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>E07000032</td>\n",
       "      <td>E60000077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>E07000224</td>\n",
       "      <td>E60000282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>E07000105</td>\n",
       "      <td>E60000253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   organisation_entity      LADCD      LPACD\n",
       "0                   26  E07000223  E60000281\n",
       "1                   27  E07000026  E60000019\n",
       "2                   28  E07000032  E60000077\n",
       "3                   29  E07000224  E60000282\n",
       "4                   30  E07000105  E60000253"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get LAD to LPA lookup from github\n",
    "lookup_lad_lpa = pd.read_csv(\"https://github.com/digital-land/organisation-collection/raw/main/data/local-authority.csv\",\n",
    "                             usecols = [\"entity\", \"local-authority-district\", \"local-planning-authority\"])\n",
    "\n",
    "lookup_lad_lpa.columns = [\"organisation_entity\", \"LADCD\", \"LPACD\"]\n",
    "\n",
    "nrow(lookup_lad_lpa)\n",
    "lookup_lad_lpa.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875da976",
   "metadata": {},
   "source": [
    "**Note on LAD to LPA mapping**   \n",
    "Currently this [lookup file from github](https://github.com/digital-land/organisation-collection/raw/main/data/local-authority.csv) just records a 1:1 link between LADs and LPAs, but according to the ONS this relationship is actually 1:many. \n",
    "See [2020 lookup file](https://geoportal.statistics.gov.uk/datasets/ons::local-planning-authority-to-local-authority-district-april-2020-in-the-united-kingdom-lookup-1/about) and the example of Ryedale [`E07000167`], which is mapped to the following two LPAs:\n",
    "\n",
    "* Ryedale LPA [`E60000061`]\n",
    "* North York Moors National Park LPA [`E60000322`]\n",
    "\n",
    "We need to agree some validation rules around this, i.e. can we expect Ryedale to submit data that might sit within either of these LPA areas, or for any London Boroughs to submit within the \"London Legacy Development Corporation LPA\" area?\n",
    "But for simplicity's sake at the moment to get things up and running (as per Owen's advice), will test with existing 1:1 mapping and aim to develop logic once there is more clarity about multiple area handling.\n",
    "\n",
    "The git lookup file also seems to be missing some areas, e.g. \"Peak District National Park Authority\" entity 405."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "42f4a672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of records in df: 441\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>organisation</th>\n",
       "      <th>organisation_name</th>\n",
       "      <th>organisation_entity</th>\n",
       "      <th>statistical_geography</th>\n",
       "      <th>organisation_type</th>\n",
       "      <th>LADCD</th>\n",
       "      <th>LPACD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>development-corporation:Q20648596</td>\n",
       "      <td>Old Oak and Park Royal Development Corporation</td>\n",
       "      <td>1</td>\n",
       "      <td>E51000002</td>\n",
       "      <td>development-corporation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>development-corporation:Q4916714</td>\n",
       "      <td>Birmingham Heartlands Development Corporation</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>development-corporation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>development-corporation:Q6670544</td>\n",
       "      <td>London Legacy Development Corporation</td>\n",
       "      <td>3</td>\n",
       "      <td>E51000001</td>\n",
       "      <td>development-corporation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>development-corporation:Q6670837</td>\n",
       "      <td>London Thames Gateway Development Corporation</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>development-corporation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>development-corporation:Q72456968</td>\n",
       "      <td>South Tees Development Corporation</td>\n",
       "      <td>5</td>\n",
       "      <td>E51000004</td>\n",
       "      <td>development-corporation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        organisation  \\\n",
       "0  development-corporation:Q20648596   \n",
       "1   development-corporation:Q4916714   \n",
       "2   development-corporation:Q6670544   \n",
       "3   development-corporation:Q6670837   \n",
       "4  development-corporation:Q72456968   \n",
       "\n",
       "                                organisation_name  organisation_entity  \\\n",
       "0  Old Oak and Park Royal Development Corporation                    1   \n",
       "1   Birmingham Heartlands Development Corporation                    2   \n",
       "2           London Legacy Development Corporation                    3   \n",
       "3   London Thames Gateway Development Corporation                    4   \n",
       "4              South Tees Development Corporation                    5   \n",
       "\n",
       "  statistical_geography        organisation_type LADCD LPACD  \n",
       "0             E51000002  development-corporation   NaN   NaN  \n",
       "1                   NaN  development-corporation   NaN   NaN  \n",
       "2             E51000001  development-corporation   NaN   NaN  \n",
       "3                   NaN  development-corporation   NaN   NaN  \n",
       "4             E51000004  development-corporation   NaN   NaN  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get org data from datasette\n",
    "lookup_org = get_all_organisations()\n",
    "\n",
    "# lookup_org[\"organisation_entity\"] = lookup_org[\"organisation_entity\"].astype(str)\n",
    "lookup_org.columns = [\"organisation\", \"organisation_name\", \"organisation_entity\", \"statistical_geography\"]\n",
    "\n",
    "# split out org type and join on LPA codes from LAD to LPA lookup\n",
    "lookup_org[\"organisation_type\"] = lookup_org[\"organisation\"].apply(lambda x: x.split(\":\")[0])\n",
    "lookup_org = lookup_org.merge(lookup_lad_lpa, how = \"left\", on = \"organisation_entity\")\n",
    "\n",
    "nrow(lookup_org)\n",
    "lookup_org.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f5112710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of records in df: 108\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "organisation_type\n",
       "development-corporation          14\n",
       "government-organisation          20\n",
       "local-authority                   4\n",
       "local-authority-eng              43\n",
       "national-park-authority          10\n",
       "nonprofit                         1\n",
       "passenger-transport-executive     1\n",
       "public-authority                  1\n",
       "regional-park-authority           1\n",
       "transport-authority               8\n",
       "waste-authority                   5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check what types of org are missing the LPA code\n",
    "nrow(lookup_org[lookup_org[\"LPACD\"].isnull()])\n",
    "lookup_org[lookup_org[\"LPACD\"].isnull()].groupby(\"organisation_type\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c238946a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of records in df: 337\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>name</th>\n",
       "      <th>LPACD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MULTIPOLYGON (((428366.003 554230.393, 428288....</td>\n",
       "      <td>County Durham LPA</td>\n",
       "      <td>E60000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MULTIPOLYGON (((436388.046 522354.244, 436372....</td>\n",
       "      <td>Darlington LPA</td>\n",
       "      <td>E60000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MULTIPOLYGON (((449073.036 536806.421, 448888....</td>\n",
       "      <td>Hartlepool LPA</td>\n",
       "      <td>E60000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MULTIPOLYGON (((451894.321 521145.352, 451858....</td>\n",
       "      <td>Middlesbrough LPA</td>\n",
       "      <td>E60000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MULTIPOLYGON (((429247.025 604972.344, 429241....</td>\n",
       "      <td>Northumberland LPA</td>\n",
       "      <td>E60000005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            geometry                name  \\\n",
       "0  MULTIPOLYGON (((428366.003 554230.393, 428288....   County Durham LPA   \n",
       "1  MULTIPOLYGON (((436388.046 522354.244, 436372....      Darlington LPA   \n",
       "2  MULTIPOLYGON (((449073.036 536806.421, 448888....      Hartlepool LPA   \n",
       "3  MULTIPOLYGON (((451894.321 521145.352, 451858....   Middlesbrough LPA   \n",
       "4  MULTIPOLYGON (((429247.025 604972.344, 429241....  Northumberland LPA   \n",
       "\n",
       "       LPACD  \n",
       "0  E60000001  \n",
       "1  E60000002  \n",
       "2  E60000003  \n",
       "3  E60000004  \n",
       "4  E60000005  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LPA boundary data from planning.data.gov\n",
    "\n",
    "LPA_boundary_df = pd.read_csv(\"https://files.planning.data.gov.uk/dataset/local-planning-authority.csv\", \n",
    "                                  usecols = [\"reference\", \"name\", \"geometry\"])\n",
    "\n",
    "LPA_boundary_df.columns = [\"geometry\", \"name\", \"LPACD\"]\n",
    "\n",
    "\n",
    "# load geometry and create GDF\n",
    "LPA_boundary_df['geometry'] = LPA_boundary_df['geometry'].apply(shapely.wkt.loads)\n",
    "LPA_boundary_gdf = gpd.GeoDataFrame(LPA_boundary_df, geometry='geometry')\n",
    "\n",
    "# Transform to ESPG:27700 for more interpretable area units\n",
    "LPA_boundary_gdf.set_crs(epsg=4326, inplace=True)\n",
    "LPA_boundary_gdf.to_crs(epsg=27700, inplace=True)\n",
    "\n",
    "nrow(LPA_boundary_gdf)\n",
    "LPA_boundary_gdf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1f4f9db0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of records in df: 8,923\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>entry_date</th>\n",
       "      <th>geometry</th>\n",
       "      <th>name</th>\n",
       "      <th>organisation_entity</th>\n",
       "      <th>reference</th>\n",
       "      <th>organisation_name</th>\n",
       "      <th>organisation_type</th>\n",
       "      <th>LPACD</th>\n",
       "      <th>area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44000001</td>\n",
       "      <td>2022-04-12</td>\n",
       "      <td>MULTIPOLYGON (((516981.159 204270.242, 516973....</td>\n",
       "      <td>Napsbury</td>\n",
       "      <td>16</td>\n",
       "      <td>5080</td>\n",
       "      <td>Historic England</td>\n",
       "      <td>government-organisation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>495087.300218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44000002</td>\n",
       "      <td>2022-04-12</td>\n",
       "      <td>MULTIPOLYGON (((512390.333 209659.962, 512382....</td>\n",
       "      <td>Shafford Mill</td>\n",
       "      <td>16</td>\n",
       "      <td>5071</td>\n",
       "      <td>Historic England</td>\n",
       "      <td>government-organisation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136187.979619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44000003</td>\n",
       "      <td>2022-04-12</td>\n",
       "      <td>MULTIPOLYGON (((511610.510 205098.079, 511611....</td>\n",
       "      <td>Potters Crouch</td>\n",
       "      <td>16</td>\n",
       "      <td>5074</td>\n",
       "      <td>Historic England</td>\n",
       "      <td>government-organisation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34603.675292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44000004</td>\n",
       "      <td>2022-04-12</td>\n",
       "      <td>MULTIPOLYGON (((512515.275 200300.431, 512520....</td>\n",
       "      <td>Old Brickett Wood</td>\n",
       "      <td>16</td>\n",
       "      <td>5075</td>\n",
       "      <td>Historic England</td>\n",
       "      <td>government-organisation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55128.469061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44000005</td>\n",
       "      <td>2022-04-12</td>\n",
       "      <td>MULTIPOLYGON (((520248.830 206717.191, 520410....</td>\n",
       "      <td>Sleapshyde</td>\n",
       "      <td>16</td>\n",
       "      <td>5078</td>\n",
       "      <td>Historic England</td>\n",
       "      <td>government-organisation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44167.433073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     entity  entry_date                                           geometry  \\\n",
       "0  44000001  2022-04-12  MULTIPOLYGON (((516981.159 204270.242, 516973....   \n",
       "1  44000002  2022-04-12  MULTIPOLYGON (((512390.333 209659.962, 512382....   \n",
       "2  44000003  2022-04-12  MULTIPOLYGON (((511610.510 205098.079, 511611....   \n",
       "3  44000004  2022-04-12  MULTIPOLYGON (((512515.275 200300.431, 512520....   \n",
       "4  44000005  2022-04-12  MULTIPOLYGON (((520248.830 206717.191, 520410....   \n",
       "\n",
       "                name  organisation_entity reference organisation_name  \\\n",
       "0           Napsbury                   16      5080  Historic England   \n",
       "1      Shafford Mill                   16      5071  Historic England   \n",
       "2     Potters Crouch                   16      5074  Historic England   \n",
       "3  Old Brickett Wood                   16      5075  Historic England   \n",
       "4         Sleapshyde                   16      5078  Historic England   \n",
       "\n",
       "         organisation_type LPACD           area  \n",
       "0  government-organisation   NaN  495087.300218  \n",
       "1  government-organisation   NaN  136187.979619  \n",
       "2  government-organisation   NaN   34603.675292  \n",
       "3  government-organisation   NaN   55128.469061  \n",
       "4  government-organisation   NaN   44167.433073  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load conservation area entity dataset from planning.data.gov into geopandas and transform CRS to EPSG:27700\n",
    "\n",
    "entity_df = pd.read_csv(\"https://files.planning.data.gov.uk/dataset/conservation-area.csv\",\n",
    "                            usecols = [\"entity\", \"name\", \"organisation-entity\", \"reference\", \"entry-date\", \"geometry\"])\n",
    "            \n",
    "# entity_df.head()\n",
    "entity_df.columns = [x.replace(\"-\", \"_\") for x in entity_df.columns]\n",
    "\n",
    "\n",
    "\n",
    "# set entity to string, needed later to sort and remove duplicate self intersections\n",
    "entity_df[\"entity\"] = entity_df[\"entity\"].astype(str)\n",
    "# entity_df[\"organisation_entity\"] = entity_df[\"organisation_entity\"].astype(str)\n",
    "\n",
    "# join organisation name and LPA codes from lookup\n",
    "entity_df = entity_df.merge(\n",
    "    lookup_org[[\"organisation_name\", \"organisation_type\", \"organisation_entity\", \"LPACD\"]], \n",
    "    how = \"left\",\n",
    "    on = \"organisation_entity\")\n",
    "\n",
    "# load geometry and create GDF\n",
    "entity_df['geometry'] = entity_df['geometry'].apply(shapely.wkt.loads)\n",
    "entity_gdf = gpd.GeoDataFrame(entity_df, geometry='geometry')\n",
    "\n",
    "# Transform to ESPG:27700 for more interpretable area units\n",
    "entity_gdf.set_crs(epsg=4326, inplace=True)\n",
    "entity_gdf.to_crs(epsg=27700, inplace=True)\n",
    "\n",
    "# calculate area\n",
    "entity_gdf[\"area\"] = entity_gdf[\"geometry\"].area\n",
    "\n",
    "nrow(entity_gdf)\n",
    "entity_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "155b018f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "organisation_type        organisation_name                    \n",
       "development-corporation  London Legacy Development Corporation       2\n",
       "government-organisation  Historic England                         7077\n",
       "local-authority-eng      North Dorset District Council              37\n",
       "                         Purbeck District Council                  126\n",
       "national-park-authority  Peak District National Park Authority      21\n",
       "dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check of the organisations that we don't have an LPA code for\n",
    "entity_df[entity_df[\"LPACD\"].isnull()].groupby([\"organisation_type\", \"organisation_name\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b60ea77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of records in df: 529\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>end_date</th>\n",
       "      <th>entity</th>\n",
       "      <th>entry_date</th>\n",
       "      <th>notes</th>\n",
       "      <th>old_entity</th>\n",
       "      <th>start_date</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>44009617</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44008389</td>\n",
       "      <td>NaN</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>44009617</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44008390</td>\n",
       "      <td>NaN</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>44009621</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44008391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>44009621</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44008392</td>\n",
       "      <td>NaN</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>44009621</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44008393</td>\n",
       "      <td>NaN</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   end_date    entity  entry_date  notes old_entity  start_date  status\n",
       "0       NaN  44009617         NaN    NaN   44008389         NaN     301\n",
       "1       NaN  44009617         NaN    NaN   44008390         NaN     301\n",
       "2       NaN  44009621         NaN    NaN   44008391         NaN     301\n",
       "3       NaN  44009621         NaN    NaN   44008392         NaN     301\n",
       "4       NaN  44009621         NaN    NaN   44008393         NaN     301"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_entity_df = get_old_entity(\"conservation-area\")\n",
    "old_entity_df[\"entity\"] = old_entity_df[\"entity\"].astype('str')\n",
    "old_entity_df[\"old_entity\"] = old_entity_df[\"old_entity\"].astype('str')\n",
    "\n",
    "nrow(old_entity_df)\n",
    "old_entity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "345af70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.concat([old_entity_df[\"entity\"], old_entity_df[\"old_entity\"]], ignore_index=True).drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d294572",
   "metadata": {},
   "source": [
    "# Checking expected bounds of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d200f0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List LPA codes from entity df and check they're all in the LPA gdf\n",
    "lpa_list = entity_df[\"LPACD\"][entity_df[\"LPACD\"].notnull()].drop_duplicates().to_list()\n",
    "\n",
    "# check every one of our entity LPAs is in the LPA gdf\n",
    "print(len(lpa_list))\n",
    "nrow(LPA_boundary_gdf[LPA_boundary_gdf[\"LPACD\"].isin(lpa_list)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db67b1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "geogs_out_entities = []\n",
    "\n",
    "# loop through LPA codes and for each check whether any conservation areas with that code don't intersect at all with the LPA boundary\n",
    "for lpa_code in lpa_list:\n",
    "\n",
    "    cons_areas = entity_gdf[entity_gdf[\"LPACD\"] == lpa_code]\n",
    "    cons_areas_intersect = cons_areas.geometry.intersects(LPA_boundary_gdf[LPA_boundary_gdf[\"LPACD\"] == lpa_code].iloc[0].geometry)\n",
    "\n",
    "    # add areas which don't intersect to the list\n",
    "    geogs_out_entities.extend(cons_areas.loc[~cons_areas_intersect][\"entity\"].to_list())\n",
    "\n",
    "\n",
    "entity_outside_LPA_df = entity_df[entity_df[\"entity\"].isin(geogs_out_entities)]\n",
    "\n",
    "# list of LPAs with entities outside them\n",
    "LPAs_with_bads = entity_outside_LPA_df[\"LPACD\"].drop_duplicates().to_list()\n",
    "\n",
    "print(f\"No. of bad entities found: {len(entity_outside_LPA_df):,}\")\n",
    "entity_outside_LPA_df.groupby(\"organisation_name\").size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf2d1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_outside_LPA_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6123c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map for LPA with entities outside it\n",
    "\n",
    "LPA_code = LADs_with_bads[0]\n",
    "bad_ents = entity_outside_LPA_df[\"entity\"][entity_outside_LPA_df[\"LPACD\"] == LPA_code]\n",
    "\n",
    "\n",
    "map_entities = entity_gdf[entity_gdf[\"entity\"].isin(bad_ents)].explore(\n",
    "        # column = chloro_var,  # make choropleth based on \"BoroName\" column\n",
    "        # cmap = palette,\n",
    "    color = \"red\",\n",
    "        # tooltip = False,\n",
    "        # popup = [\"organisation_name\", \"entity\", \"name\", \"reference\"],\n",
    "        tiles = \"CartoDB positron\",  # use \"CartoDB positron\" tiles\n",
    "        highlight = False,\n",
    "        style_kwds = {\n",
    "        \"fillOpacity\" : \"0.1\"\n",
    "        }\n",
    ")\n",
    "\n",
    "LPA_boundary_gdf[LPA_boundary_gdf[\"LPACD\"] == LPA_code].explore(\n",
    "    m = map_entities,\n",
    "    color = \"blue\",\n",
    "        style_kwds = {\n",
    "        \"fillOpacity\" : \"0\"\n",
    "        }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ceb3197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map for LPA with entities outside it\n",
    "\n",
    "LPA_code = LADs_with_bads[2]\n",
    "bad_ents = entity_outside_LPA_df[\"entity\"][entity_outside_LPA_df[\"LPACD\"] == LPA_code]\n",
    "\n",
    "\n",
    "map_entities = entity_gdf[entity_gdf[\"entity\"].isin(bad_ents)].explore(\n",
    "        # column = chloro_var,  # make choropleth based on \"BoroName\" column\n",
    "        # cmap = palette,\n",
    "    color = \"red\",\n",
    "        # tooltip = False,\n",
    "        # popup = [\"organisation_name\", \"entity\", \"name\", \"reference\"],\n",
    "        tiles = \"CartoDB positron\",  # use \"CartoDB positron\" tiles\n",
    "        highlight = False,\n",
    "        style_kwds = {\n",
    "        \"fillOpacity\" : \"0.1\"\n",
    "        }\n",
    ")\n",
    "\n",
    "LPA_boundary_gdf[LPA_boundary_gdf[\"LPACD\"] == LPA_code].explore(\n",
    "    m = map_entities,\n",
    "    color = \"blue\",\n",
    "        style_kwds = {\n",
    "        \"fillOpacity\" : \"0\"\n",
    "        }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e509bf8b",
   "metadata": {},
   "source": [
    "# Identifying geographical duplicates  \n",
    "## Report\n",
    "\n",
    "Aim of this is to quickly categorise the overlaps based on whether they fall into the following groups:\n",
    "\n",
    "Entity overlaps with another: \n",
    "\n",
    "1. within the same organisation\n",
    "    \n",
    "2. from a different organisation   \n",
    "\n",
    "    a. LPA entity overlaps with entity from another LPA\n",
    "        \n",
    "    b. LPA entity overlaps with entity from Historic England\n",
    "\n",
    "Within some of these categories (1. and 2.b) there are distinctions made on the type of overlap that's occuring, with different actions recommended for different types\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "964e3900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of records in df: 2,786\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_1</th>\n",
       "      <th>entry_date_1</th>\n",
       "      <th>name_1</th>\n",
       "      <th>organisation_entity_1</th>\n",
       "      <th>reference_1</th>\n",
       "      <th>organisation_name_1</th>\n",
       "      <th>organisation_type_1</th>\n",
       "      <th>LPACD_1</th>\n",
       "      <th>area_1</th>\n",
       "      <th>entity_2</th>\n",
       "      <th>...</th>\n",
       "      <th>int_org_match</th>\n",
       "      <th>int_org_types</th>\n",
       "      <th>date_match</th>\n",
       "      <th>entity_old</th>\n",
       "      <th>area_intersection</th>\n",
       "      <th>p_pct_intersect</th>\n",
       "      <th>pct_intersection</th>\n",
       "      <th>s_pct_intersect</th>\n",
       "      <th>pct_min_intersection</th>\n",
       "      <th>issue_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>44000009</td>\n",
       "      <td>2022-04-12</td>\n",
       "      <td>Childwickbury</td>\n",
       "      <td>16</td>\n",
       "      <td>5063</td>\n",
       "      <td>Historic England</td>\n",
       "      <td>government-organisation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.885513e+06</td>\n",
       "      <td>44000007</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>HE - HE</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2.170036</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>4.225103e-07</td>\n",
       "      <td>6.675918e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>tiny edge - ignore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>44000732</td>\n",
       "      <td>2022-04-12</td>\n",
       "      <td>Bodenham Road</td>\n",
       "      <td>16</td>\n",
       "      <td>5104</td>\n",
       "      <td>Historic England</td>\n",
       "      <td>government-organisation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.678147e+04</td>\n",
       "      <td>44000016</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>HE - HE</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2.162021</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>5.452397e-06</td>\n",
       "      <td>7.212809e-06</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>tiny edge - ignore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>44000770</td>\n",
       "      <td>2022-04-12</td>\n",
       "      <td>Leominster Town</td>\n",
       "      <td>16</td>\n",
       "      <td>2499</td>\n",
       "      <td>Historic England</td>\n",
       "      <td>government-organisation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.556232e+05</td>\n",
       "      <td>44000017</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>HE - HE</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2.033437</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>4.665495e-06</td>\n",
       "      <td>1.128278e-05</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>tiny edge - ignore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>44000043</td>\n",
       "      <td>2022-04-12</td>\n",
       "      <td>Butterworth Hall</td>\n",
       "      <td>16</td>\n",
       "      <td>7716</td>\n",
       "      <td>Historic England</td>\n",
       "      <td>government-organisation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.968792e+04</td>\n",
       "      <td>44000042</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>HE - HE</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>tiny edge - ignore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>44003132</td>\n",
       "      <td>2022-04-12</td>\n",
       "      <td>Worcester and Birmingham Canal</td>\n",
       "      <td>16</td>\n",
       "      <td>449</td>\n",
       "      <td>Historic England</td>\n",
       "      <td>government-organisation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.539313e+05</td>\n",
       "      <td>44000050</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>HE - HE</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4.129991</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>7.315925e-06</td>\n",
       "      <td>1.329709e-05</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>tiny edge - ignore</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    entity_1 entry_date_1                          name_1  \\\n",
       "7   44000009   2022-04-12                   Childwickbury   \n",
       "18  44000732   2022-04-12                   Bodenham Road   \n",
       "22  44000770   2022-04-12                 Leominster Town   \n",
       "50  44000043   2022-04-12                Butterworth Hall   \n",
       "60  44003132   2022-04-12  Worcester and Birmingham Canal   \n",
       "\n",
       "    organisation_entity_1 reference_1 organisation_name_1  \\\n",
       "7                      16        5063    Historic England   \n",
       "18                     16        5104    Historic England   \n",
       "22                     16        2499    Historic England   \n",
       "50                     16        7716    Historic England   \n",
       "60                     16         449    Historic England   \n",
       "\n",
       "        organisation_type_1 LPACD_1        area_1  entity_2  ...  \\\n",
       "7   government-organisation     NaN  1.885513e+06  44000007  ...   \n",
       "18  government-organisation     NaN  9.678147e+04  44000016  ...   \n",
       "22  government-organisation     NaN  2.556232e+05  44000017  ...   \n",
       "50  government-organisation     NaN  2.968792e+04  44000042  ...   \n",
       "60  government-organisation     NaN  2.539313e+05  44000050  ...   \n",
       "\n",
       "   int_org_match int_org_types  date_match entity_old area_intersection  \\\n",
       "7           True       HE - HE        True      False          2.170036   \n",
       "18          True       HE - HE        True      False          2.162021   \n",
       "22          True       HE - HE        True      False          2.033437   \n",
       "50          True       HE - HE        True      False          0.000000   \n",
       "60          True       HE - HE        True      False          4.129991   \n",
       "\n",
       "   p_pct_intersect pct_intersection  s_pct_intersect pct_min_intersection  \\\n",
       "7         0.000001     4.225103e-07     6.675918e-07             0.000001   \n",
       "18        0.000022     5.452397e-06     7.212809e-06             0.000022   \n",
       "22        0.000008     4.665495e-06     1.128278e-05             0.000011   \n",
       "50        0.000000     0.000000e+00     0.000000e+00             0.000000   \n",
       "60        0.000016     7.315925e-06     1.329709e-05             0.000016   \n",
       "\n",
       "            issue_type  \n",
       "7   tiny edge - ignore  \n",
       "18  tiny edge - ignore  \n",
       "22  tiny edge - ignore  \n",
       "50  tiny edge - ignore  \n",
       "60  tiny edge - ignore  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATCH_LOWER_THRESH = 0.9  # defines the lower limit of the shared overlap between two entities to be called a match\n",
    "EDGE_UPPER_THRESH = 0.1   # defines the upper limit of the shared overlap between two entities to be called an edge intersection\n",
    "EDGE_LOWER_THRESH = 0.01   # defines the lower limit of the shared overlap between two entities to be called an edge intersection\n",
    "\n",
    "\n",
    "# full join of all geometries\n",
    "entity_join_all = gpd.overlay(\n",
    "    entity_gdf, \n",
    "    entity_gdf,\n",
    "    how = \"intersection\", keep_geom_type=False \n",
    ")\n",
    "\n",
    "\n",
    "# remove self-intersections and duplicates of the same intersections\n",
    "entity_join_all = entity_join_all[entity_join_all[\"entity_1\"] != entity_join_all[\"entity_2\"]]\n",
    "\n",
    "entity_join_all[\"entity_join\"] = entity_join_all.apply(lambda x: '-'.join(sorted(x[[\"entity_1\", \"entity_2\"]])), axis=1)\n",
    "\n",
    "# extra sort to make sure matches to Historic England always show as Historic England as org 2 \n",
    "entity_join_all[\"name_for_sort\"] = np.where(entity_join_all[\"organisation_entity_1\"] == 16, \"Z\", \"A\")\n",
    "entity_join_all.sort_values([\"entity_join\", \"name_for_sort\"], ascending=True, inplace=True)\n",
    "\n",
    "entity_join_all.drop_duplicates(subset=\"entity_join\", inplace = True,   ) #Drop them by name\n",
    "\n",
    "# nrow(entity_join_all)\n",
    "\n",
    "# flag the types of intersections between organisations\n",
    "# is org the same\n",
    "entity_join_all[\"int_org_match\"] = np.where(entity_join_all[\"organisation_entity_1\"] == entity_join_all[\"organisation_entity_2\"], True, False)\n",
    "\n",
    "# the types of org-org matches\n",
    "entity_join_all[\"int_org_types\"] = np.select(\n",
    "    [\n",
    "        (entity_join_all[\"organisation_entity_1\"] == 16) & (entity_join_all[\"organisation_entity_2\"] == 16),\n",
    "        (entity_join_all[\"organisation_entity_1\"] != 16) & (entity_join_all[\"organisation_entity_2\"] != 16),\n",
    "        ((entity_join_all[\"organisation_entity_1\"] != 16) & (entity_join_all[\"organisation_entity_2\"] == 16)) |\n",
    "        ((entity_join_all[\"organisation_entity_1\"] == 16) & (entity_join_all[\"organisation_entity_2\"] != 16))\n",
    "    ],\n",
    "    [\"HE - HE\", \"LPA - LPA\", \"HE - other\"],\n",
    "    default = \"-\"\n",
    ")\n",
    "\n",
    "# does the entity entry date match?\n",
    "entity_join_all[\"date_match\"] = np.where(entity_join_all[\"entry_date_1\"] == entity_join_all[\"entry_date_2\"], True, False)\n",
    "\n",
    "# has one of the intersected entities already been re-mapped?\n",
    "entity_join_all[\"entity_old\"] = np.where(entity_join_all[\"entity_1\"].isin(old_entity_df[\"old_entity\"]) |\n",
    "                                         entity_join_all[\"entity_2\"].isin(old_entity_df[\"old_entity\"]), True, False)\n",
    "\n",
    "\n",
    "# calculate overlap %'s\n",
    "\n",
    "entity_join_all[\"area_intersection\"] = entity_join_all[\"geometry\"].area\n",
    "\n",
    "entity_join_all[\"p_pct_intersect\"] = entity_join_all[\"area_intersection\"] / entity_join_all[\"area_1\"]\n",
    "entity_join_all[\"pct_intersection\"] = entity_join_all[\"area_intersection\"] / (entity_join_all[\"area_1\"] + entity_join_all[\"area_2\"] - entity_join_all[\"area_intersection\"])\n",
    "entity_join_all[\"s_pct_intersect\"] = entity_join_all[\"area_intersection\"] / entity_join_all[\"area_2\"]\n",
    "\n",
    "# intersection area as % of smallest primary or secondary area\n",
    "entity_join_all[\"pct_min_intersection\"] = entity_join_all[\"area_intersection\"] / entity_join_all[[\"area_1\", \"area_2\"]].min(axis = 1)\n",
    "\n",
    "\n",
    "entity_join_all[\"issue_type\"] = np.select(\n",
    "    [\n",
    "        (entity_join_all[\"p_pct_intersect\"] >= MATCH_LOWER_THRESH) & (entity_join_all[\"s_pct_intersect\"] >= MATCH_LOWER_THRESH),\n",
    "        # (entity_join_all[\"p_pct_intersect\"] <= EDGE_UPPER_THRESH) & (entity_join_all[\"s_pct_intersect\"] <= EDGE_UPPER_THRESH),\n",
    "        (entity_join_all[\"pct_min_intersection\"] <= EDGE_UPPER_THRESH) & (entity_join_all[\"pct_min_intersection\"] >= EDGE_LOWER_THRESH),\n",
    "        (entity_join_all[\"pct_min_intersection\"] < EDGE_LOWER_THRESH),\n",
    "        ((entity_join_all[\"p_pct_intersect\"] >= MATCH_LOWER_THRESH) | (entity_join_all[\"s_pct_intersect\"] >= MATCH_LOWER_THRESH)),\n",
    "        \n",
    "    ],\n",
    "    [\n",
    "        \"> 90% combined match\", \"edge intersection\", \"tiny edge - ignore\", \"> 90% single match\"\n",
    "    ],\n",
    "    default = \"unclassified\"\n",
    ")\n",
    "\n",
    "nrow(entity_join_all)\n",
    "entity_join_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "054c37ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int_org_match  int_org_types  organisation_entity_1  organisation_entity_2\n",
       "False          HE - other     3                      16                        1\n",
       "                              33                     16                        2\n",
       "                              43                     16                       14\n",
       "                              65                     16                       38\n",
       "                              67                     16                        1\n",
       "                                                                              ..\n",
       "True           LPA - LPA      309                    309                       2\n",
       "                              319                    319                       3\n",
       "                              329                    329                      28\n",
       "                              352                    352                       1\n",
       "                              376                    376                       4\n",
       "Length: 133, dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the flagging or intersections between different org types is correct\n",
    "entity_join_all.groupby([\"int_org_match\", \"int_org_types\", \"organisation_entity_1\", \"organisation_entity_2\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "9f636ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "issue_type\n",
       "> 90% combined match     317\n",
       "> 90% single match       310\n",
       "edge intersection         52\n",
       "tiny edge - ignore      2068\n",
       "unclassified              39\n",
       "dtype: int64"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_join_all.groupby(\"issue_type\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "86cb607a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "entity_old  int_org_match  int_org_types  date_match  issue_type          \n",
       "False       False          HE - other     False       > 90% combined match    301\n",
       "                                                      > 90% single match      233\n",
       "                                                      edge intersection        17\n",
       "                                                      unclassified             19\n",
       "                           LPA - LPA      False       edge intersection         4\n",
       "                                          True        unclassified              1\n",
       "            True           HE - HE        False       > 90% combined match      1\n",
       "                                                      > 90% single match        4\n",
       "                                                      edge intersection         6\n",
       "                                                      unclassified              2\n",
       "                                          True        > 90% combined match      4\n",
       "                                                      > 90% single match       36\n",
       "                                                      edge intersection        21\n",
       "                                                      unclassified             14\n",
       "                           LPA - LPA      False       > 90% combined match     10\n",
       "                                                      > 90% single match       13\n",
       "                                                      edge intersection         3\n",
       "                                                      unclassified              3\n",
       "                                          True        > 90% single match       23\n",
       "                                                      edge intersection         1\n",
       "True        False          HE - other     False       > 90% combined match      1\n",
       "            True           HE - HE        False       > 90% single match        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count of issues by type breakdown\n",
    "entity_join_all[entity_join_all[\"issue_type\"] != \"tiny edge - ignore\"].groupby(['entity_old', 'int_org_match', 'int_org_types', 'date_match', 'issue_type']).size()\n",
    "\n",
    "# write to csv to add in further descriptions\n",
    "# entity_join_all.groupby(['entity_old', 'int_org_match', 'int_org_types', 'date_match', 'issue_type']).size().to_csv(\"temp_issue_mapping_table.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "ad180052",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "d2652fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['high', 'high', 'low']"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "dda6ebcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLAGGING ISSUE DETAILS\n",
    "\n",
    "# Action\n",
    "entity_join_all[\"action\"] = np.select(\n",
    "    [\n",
    "        (entity_join_all[\"issue_type\"] == \"tiny edge - ignore\"),\n",
    "        (entity_join_all[\"int_org_match\"] == True) & (entity_join_all[\"int_org_types\"] == \"HE - HE\"),\n",
    "        (entity_join_all[\"int_org_match\"] == False) & (entity_join_all[\"int_org_types\"] == \"HE - other\") & (entity_join_all[\"issue_type\"] == \"> 90% combined match\") \n",
    "\n",
    "    ],\n",
    "    [\"ignore\", \"ignore\", \"remap\"],\n",
    "    default = \"investigate\"\n",
    ")\n",
    "\n",
    "# Priority and hint\n",
    "issue_priority_mapping = {\n",
    "    \"> 90% combined match\" : \"high\",\n",
    "    \"> 90% single match\" : \"medium\",\n",
    "    \"edge intersection\" : \"low\",\n",
    "    \"unclassified\" : \"low\",\n",
    "    \"tiny edge - ignore\" : \"\"\n",
    "}\n",
    "\n",
    "issue_hint_mapping = {\n",
    "    True : \"raise with LPA\",\n",
    "    False : \"check endpoints\"\n",
    "}\n",
    "\n",
    "entity_join_all[\"priority\"] = [issue_priority_mapping[data[\"issue_type\"]] if data[\"action\"] != \"ignore\" else \"\" for (index, data) in entity_join_all.iterrows()]\n",
    "entity_join_all[\"hint\"] = [issue_hint_mapping[data[\"date_match\"]] if \n",
    "                           (data[\"int_org_match\"] == True) & (data[\"int_org_types\"] == \"LPA - LPA\") & (data[\"action\"] != \"ignore\") \n",
    "                           else \"\" for (index, data) in entity_join_all.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "d7efbbe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "entity_old  int_org_match  int_org_types  date_match  issue_type            action       priority  hint           \n",
       "False       False          HE - other     False       > 90% combined match  remap        high                         301\n",
       "                                                      > 90% single match    investigate  medium                       233\n",
       "                                                      edge intersection     investigate  low                           17\n",
       "                                                      tiny edge - ignore    ignore                                    467\n",
       "                                                      unclassified          investigate  low                           19\n",
       "                           LPA - LPA      False       edge intersection     investigate  low                            4\n",
       "                                                      tiny edge - ignore    ignore                                     28\n",
       "                                          True        tiny edge - ignore    ignore                                     15\n",
       "                                                      unclassified          investigate  low                            1\n",
       "            True           HE - HE        False       > 90% combined match  ignore                                      1\n",
       "                                                      > 90% single match    ignore                                      4\n",
       "                                                      edge intersection     ignore                                      6\n",
       "                                                      tiny edge - ignore    ignore                                    123\n",
       "                                                      unclassified          ignore                                      2\n",
       "                                          True        > 90% combined match  ignore                                      4\n",
       "                                                      > 90% single match    ignore                                     36\n",
       "                                                      edge intersection     ignore                                     21\n",
       "                                                      tiny edge - ignore    ignore                                    872\n",
       "                                                      unclassified          ignore                                     14\n",
       "                           LPA - LPA      False       > 90% combined match  investigate  high      check endpoints     10\n",
       "                                                      > 90% single match    investigate  medium    check endpoints     13\n",
       "                                                      edge intersection     investigate  low       check endpoints      3\n",
       "                                                      tiny edge - ignore    ignore                                     24\n",
       "                                                      unclassified          investigate  low       check endpoints      3\n",
       "                                          True        > 90% single match    investigate  medium    raise with LPA      23\n",
       "                                                      edge intersection     investigate  low       raise with LPA       1\n",
       "                                                      tiny edge - ignore    ignore                                    538\n",
       "True        False          HE - other     False       > 90% combined match  remap        high                           1\n",
       "            True           HE - HE        False       > 90% single match    ignore                                      1\n",
       "                                                      tiny edge - ignore    ignore                                      1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count of issues by type breakdown\n",
    "entity_join_all.groupby(['entity_old', 'int_org_match', 'int_org_types', 'date_match', 'issue_type', 'action', 'priority', 'hint']).size().head(40)\n",
    "\n",
    "# write to csv to add in further descriptions\n",
    "# entity_join_all.groupby(['entity_old', 'int_org_match', 'int_org_types', 'date_match', 'issue_type']).size().to_csv(\"temp_issue_mapping_table.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7245500d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read back in issue flag mapping table with extra fields\n",
    "# issue_mapping_df = pd.read_csv(\"temp_issue_mapping_table.csv\")\n",
    "\n",
    "# check join works\n",
    "nrow(entity_join_all)\n",
    "nrow(entity_join_all.merge(\n",
    "        issue_mapping_df, \n",
    "        how = \"inner\", \n",
    "        on = ['entity_old', 'int_org_match', 'int_org_types', 'date_match', 'issue_type']))\n",
    "\n",
    "entity_join_all = entity_join_all.merge(\n",
    "        issue_mapping_df, \n",
    "        how = \"inner\", \n",
    "        on = ['entity_old', 'int_org_match', 'int_org_types', 'date_match', 'issue_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "783c403f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write full report table to csv\n",
    "\n",
    "nicecols = [\n",
    "    'entity_join', 'entity_1', 'entity_2', 'entry_date_1', 'name_1', 'organisation_entity_1',\n",
    "    'reference_1', 'organisation_name_1', 'organisation_type_1',\n",
    "    'entry_date_2', 'name_2', 'organisation_entity_2',\n",
    "    'reference_2', 'organisation_name_2', 'organisation_type_2',\n",
    "    'p_pct_intersect', 'pct_intersection', 's_pct_intersect', 'pct_min_intersection',\n",
    "    'int_org_match', 'int_org_types', 'date_match', 'entity_old',\n",
    "    'issue_type'\n",
    "    # , 'issue_description', 'action'\n",
    "    ]\n",
    "\n",
    "# entity_join_all[nicecols].to_csv(\"issues_report_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "0933e132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['entity_1', 'entry_date_1', 'name_1', 'organisation_entity_1',\n",
       "       'reference_1', 'organisation_name_1', 'organisation_type_1', 'LPACD_1',\n",
       "       'area_1', 'entity_2', 'entry_date_2', 'name_2', 'organisation_entity_2',\n",
       "       'reference_2', 'organisation_name_2', 'organisation_type_2', 'LPACD_2',\n",
       "       'area_2', 'geometry', 'entity_join', 'name_for_sort', 'int_org_match',\n",
       "       'int_org_types', 'date_match', 'entity_old', 'area_intersection',\n",
       "       'p_pct_intersect', 'pct_intersection', 's_pct_intersect',\n",
       "       'pct_min_intersection', 'issue_type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_join_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d04c8cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int_org_types  organisation_name_1                   \n",
       "HE - other     Buckinghamshire Council                    1\n",
       "               Canterbury City Council                   97\n",
       "               Doncaster Metropolitan Borough Council    45\n",
       "               Gloucester City Council                   14\n",
       "               Great Yarmouth Borough Council            21\n",
       "               London Borough of Lambeth                  7\n",
       "               London Borough of Redbridge                4\n",
       "               London Borough of Southwark                2\n",
       "               London Borough of Waltham Forest           1\n",
       "               Medway Council                            24\n",
       "               Royal Borough of Kingston upon Thames      4\n",
       "LPA - LPA      Buckinghamshire Council                    1\n",
       "               Epsom and Ewell Borough Council            7\n",
       "               London Borough of Lambeth                  8\n",
       "               London Borough of Southwark                5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lpa_fund_list = ['Buckinghamshire Council','Doncaster Metropolitan Borough Council','Gloucester City Council','London Borough of Camden','London Borough of Lambeth','London Borough of Southwark','Medway Council','Newcastle City Council','Birmingham City Council','Canterbury City Council','Epsom and Ewell Borough Council','London Borough of Barnet','Gateshead Metropolitan Borough Council','Great Yarmouth Borough Council','Royal Borough of Kingston upon Thames','St Albans City and District Council','Tewkesbury Borough Council','West Berkshire Council','Dorset District Council','Dover District Council','Liverpool City Council','London Borough of Redbridge','London Borough of Waltham Forest','North Lincolnshire Council','North Somerset Council','Salford City Council','Wirral Borough Council']\n",
    "\n",
    "entity_join_all[\n",
    "    (entity_join_all[\"organisation_name_1\"].isin(lpa_fund_list) | entity_join_all[\"organisation_name_2\"].isin(lpa_fund_list)) &\n",
    "    # (entity_join_all[\"pct_min_intersection\"] > 0.01) &\n",
    "    (entity_join_all[\"issue_type\"] != \"edge intersection\")\n",
    "    ].groupby([\"int_org_types\", \"organisation_name_1\"]).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0791e3ef",
   "metadata": {},
   "source": [
    "## #1 - Intersection within organisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a708a928",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Overlay all non-Heritage England entities (conservation area HE publish contains overlaps so not trying to flag here)\n",
    "LPA_LPA_join = gpd.overlay(\n",
    "    # entity_gdf, entity_gdf,\n",
    "    entity_gdf[entity_gdf[\"organisation_entity\"] != 16],\n",
    "    entity_gdf[entity_gdf[\"organisation_entity\"] != 16],\n",
    "    how = \"intersection\", keep_geom_type=False \n",
    ")\n",
    "\n",
    "# remove entity self-intersections and intersections across organisations\n",
    "LPA_LPA_join = LPA_LPA_join[(LPA_LPA_join[\"organisation_entity_1\"] == LPA_LPA_join[\"organisation_entity_2\"]) &\n",
    "             (LPA_LPA_join[\"entity_1\"] != LPA_LPA_join[\"entity_2\"])]\n",
    "\n",
    "nrow(LPA_LPA_join)\n",
    "# each intersection will be in there twice because we're joining the same dataset \n",
    "# (e.g. polygon1-polygon2 and polygon2-polygon1), so remove these\n",
    "LPA_LPA_join[\"entity_join\"] = LPA_LPA_join.apply(lambda x: '-'.join(sorted(x[[\"entity_1\", \"entity_2\"]])), axis=1)\n",
    "LPA_LPA_join.drop_duplicates(subset=\"entity_join\", inplace = True) #Drop them by name\n",
    "\n",
    "# calculate overlap %'s\n",
    "\n",
    "LPA_LPA_join[\"area_intersection\"] = LPA_LPA_join[\"geometry\"].area\n",
    "\n",
    "LPA_LPA_join[\"p_pct_intersect\"] = LPA_LPA_join[\"area_intersection\"] / LPA_LPA_join[\"area_1\"]\n",
    "LPA_LPA_join[\"pct_intersection\"] = LPA_LPA_join[\"area_intersection\"] / (LPA_LPA_join[\"area_1\"] + LPA_LPA_join[\"area_2\"] - LPA_LPA_join[\"area_intersection\"])\n",
    "LPA_LPA_join[\"s_pct_intersect\"] = LPA_LPA_join[\"area_intersection\"] / LPA_LPA_join[\"area_2\"]\n",
    "\n",
    "# intersection area as % of smallest primary or secondary area\n",
    "LPA_LPA_join[\"pct_min_intersection\"] = LPA_LPA_join[\"area_intersection\"] / LPA_LPA_join[[\"area_1\", \"area_2\"]].min(axis = 1)\n",
    "\n",
    "LPA_LPA_join[\"issue_type\"] = np.select(\n",
    "    [\n",
    "        (LPA_LPA_join[\"p_pct_intersect\"] >= 0.9) & (LPA_LPA_join[\"s_pct_intersect\"] >= 0.9),\n",
    "        (LPA_LPA_join[\"p_pct_intersect\"] <= 0.1) & (LPA_LPA_join[\"s_pct_intersect\"] <= 0.1),\n",
    "        ((LPA_LPA_join[\"p_pct_intersect\"] >= 0.9) | (LPA_LPA_join[\"s_pct_intersect\"] >= 0.9)),\n",
    "        \n",
    "    ],\n",
    "    [\n",
    "        \"> 90% combined match\", \"edge intersection\", \"> 90% single match\"\n",
    "    ],\n",
    "    default = \"-\"\n",
    ")\n",
    "\n",
    "LPA_LPA_join[\"date_match\"] = np.where(LPA_LPA_join[\"entry_date_1\"] == LPA_LPA_join[\"entry_date_2\"], True, False)\n",
    "\n",
    "LPA_LPA_join = LPA_LPA_join[['entity_1', 'entry_date_1', 'name_1', 'organisation_entity_1',\n",
    "       'reference_1', 'organisation_name_1', 'entity_2', 'entry_date_2', 'name_2', 'organisation_entity_2',\n",
    "       'reference_2', 'organisation_name_2', \n",
    "       'geometry', 'entity_join', 'area_intersection',\n",
    "       'p_pct_intersect', 'pct_intersection', 's_pct_intersect',\n",
    "       'pct_min_intersection', 'date_match', 'issue_type']]\n",
    "\n",
    "nrow(LPA_LPA_join)\n",
    "LPA_LPA_join.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc648ba9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# how many entities with a greater than 10% intersection?\n",
    "nrow(LPA_LPA_join[(LPA_LPA_join[\"pct_min_intersection\"] > 0.1)])\n",
    "\n",
    "# LPA_LPA_join[(LPA_LPA_join[\"pct_min_intersection\"] > 0.1)].sort_values(\"pct_min_intersection\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6af3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "LPA_LPA_join.groupby([\"date_match\", \"issue_type\", \"organisation_name_1\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ed5bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count by organisation of entities with intersections > 10%\n",
    "LPA_LPA_join[(LPA_LPA_join[\"pct_min_intersection\"] > 0.1)].groupby([\"organisation_name_1\"]).size().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2b3dff",
   "metadata": {},
   "source": [
    "**notes from run through with Swati**\n",
    "\n",
    "solution - go back to LPA\n",
    "possible explanation - data is coming from different endpoint, and first one is not retired. Need to rule this out before we go back to LPA.\n",
    "\n",
    "When new endpoint is added, we want to keep both. Want to keep record of data over time. Platform should only present latest version.\n",
    "Need to understand entity creation process a little bit more to understand how geo duplicates could get made - talk to Kena."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e67e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect example\n",
    "# plot_issues_map(entity_gdf, [\"44005062\", \"44002577\"], \"name\", \"Accent\")\n",
    "plot_issues_map(entity_gdf, \"44000171-44000170\", \"name\", \"Accent\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc37eaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect example\n",
    "plot_issues_map(entity_gdf, \"44008830-44006848\", \"name\", \"Accent\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9fdcd4",
   "metadata": {},
   "source": [
    "## 2 - Intersection across organisations\n",
    "   \n",
    "### 2.a LPA entity overlaps with entity from another LPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106178b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlay all non-Heritage England entities\n",
    "LPA_cross_join = gpd.overlay(\n",
    "    entity_gdf[entity_gdf[\"organisation_entity\"] != 16],\n",
    "    entity_gdf[entity_gdf[\"organisation_entity\"] != 16],\n",
    "    how = \"intersection\", keep_geom_type=False \n",
    ")\n",
    "\n",
    "# filter to join across organisations and entities\n",
    "LPA_cross_join = LPA_cross_join[(LPA_cross_join[\"organisation_entity_1\"] != LPA_cross_join[\"organisation_entity_2\"]) &\n",
    "             (LPA_cross_join[\"entity_1\"] != LPA_cross_join[\"entity_2\"])]\n",
    "\n",
    "# each intersection will be in there twice because we're joining the same dataset \n",
    "# (e.g. polygon1-polygon2 and polygon2-polygon1), so remove these\n",
    "LPA_cross_join[\"entity_join\"] = LPA_cross_join.apply(lambda x: '-'.join(sorted(x[[\"entity_1\", \"entity_2\"]])), axis=1)\n",
    "LPA_cross_join.drop_duplicates(subset=\"entity_join\", inplace = True) #Drop them by name\n",
    "\n",
    "# # calculate overlap %'s\n",
    "\n",
    "LPA_cross_join[\"area_intersection\"] = LPA_cross_join[\"geometry\"].area\n",
    "\n",
    "# # LPA_LPA_join[\"p_pct_intersect\"] = LPA_LPA_join[\"area_intersection\"] / LPA_LPA_join[\"area_1\"]\n",
    "# # LPA_LPA_join[\"pct_intersection\"] = LPA_LPA_join[\"area_intersection\"] / (LPA_LPA_join[\"area_1\"] + LPA_LPA_join[\"area_2\"] - LPA_LPA_join[\"area_intersection\"])\n",
    "# # LPA_LPA_join[\"s_pct_intersect\"] = LPA_LPA_join[\"area_intersection\"] / LPA_LPA_join[\"area_2\"]\n",
    "\n",
    "# intersection area as % of smallest primary or secondary area\n",
    "LPA_cross_join[\"pct_min_intersection\"] = LPA_cross_join[\"area_intersection\"] / LPA_cross_join[[\"area_1\", \"area_2\"]].min(axis = 1)\n",
    "\n",
    "nrow(LPA_cross_join)\n",
    "LPA_cross_join.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314917c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at distribution to check how many are edges vs. major overlaps\n",
    "plt.hist(LPA_cross_join[\"pct_min_intersection\"], bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13770849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many entities which have issues of intersection > 10%? \n",
    "LPA_cross_join[(LPA_cross_join[\"pct_min_intersection\"] > 0.1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9224445",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_issues_map(entity_gdf, \"44009059-44008830\", \"organisation_name\", \"Accent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d192b28f",
   "metadata": {},
   "source": [
    "### 2.b LPA entity overlaps with entity from Historic England "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1772ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = time.time()\n",
    "\n",
    "LPA_HE_join = gpd.overlay(\n",
    "    entity_gdf[entity_gdf[\"organisation_entity\"] != 16],\n",
    "    entity_gdf[entity_gdf[\"organisation_entity\"] == 16],\n",
    "    how = \"intersection\", keep_geom_type=False\n",
    ")\n",
    "\n",
    "LPA_HE_join[\"area_intersection\"] = LPA_HE_join[\"geometry\"].area\n",
    "\n",
    "LPA_HE_join[\"p_pct_intersect\"] = LPA_HE_join[\"area_intersection\"] / LPA_HE_join[\"area_1\"]\n",
    "LPA_HE_join[\"pct_intersection\"] = LPA_HE_join[\"area_intersection\"] / (LPA_HE_join[\"area_1\"] + LPA_HE_join[\"area_2\"] - LPA_HE_join[\"area_intersection\"])\n",
    "LPA_HE_join[\"s_pct_intersect\"] = LPA_HE_join[\"area_intersection\"] / LPA_HE_join[\"area_2\"]\n",
    "\n",
    "\n",
    "# intersection area as % of smallest primary or secondary area\n",
    "LPA_HE_join[\"pct_min_intersection\"] = LPA_HE_join[\"area_intersection\"] / LPA_HE_join[[\"area_1\", \"area_2\"]].min(axis = 1)\n",
    "\n",
    "\n",
    "# end_time = time.time()\n",
    "\n",
    "# elapsed_time = (end_time - start_time) \n",
    "# print(f\"Elapsed time: {elapsed_time:.2f} \")\n",
    "\n",
    "nrow(LPA_HE_join)\n",
    "LPA_HE_join.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dc94b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the issues by the amount the two entities which make up each issue intersect each other\n",
    "# this is useful to start to define categories for the types of issues they represent\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.grid()\n",
    "plt.scatter(LPA_HE_join[\"p_pct_intersect\"], LPA_HE_join[\"s_pct_intersect\"], s = 8, alpha=0.6)\n",
    "fig.suptitle('Entity intersection %s', fontsize=14)\n",
    "plt.xlabel('% of LPA entity intersected', fontsize=10)\n",
    "plt.ylabel('% of Historic England entity intersected', fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8644be09",
   "metadata": {},
   "source": [
    "By the number of points on the far right of the chart we can see that there are a lot of LPA entities which are entirely or almost entirely contained within an HE entity, but how closely the HE area matches varies from not at all to almost exactly.\n",
    "\n",
    "Bottom left is a cluster of tiny edge intersections, and there are a small number of instances where HE entities are contained within LPA ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9964944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flag issue types - defined to pick up main issue clusters on chart above and using a 90% or 10% intersection cutoffs\n",
    "\n",
    "LPA_HE_join[\"issue_type\"] = np.select(\n",
    "    [\n",
    "        (LPA_HE_join[\"p_pct_intersect\"] >= 0.9) & (LPA_HE_join[\"s_pct_intersect\"] >= 0.9),\n",
    "        (LPA_HE_join[\"p_pct_intersect\"] <= 0.1) & (LPA_HE_join[\"s_pct_intersect\"] <= 0.1),\n",
    "        (LPA_HE_join[\"p_pct_intersect\"] >= 0.9),\n",
    "        (LPA_HE_join[\"s_pct_intersect\"] >= 0.9)\n",
    "    ],\n",
    "    [\n",
    "        \"LPA and HE cover each other\", \"edge intersection\", \"LPA covered by HE\", \"LPA covers HE\"\n",
    "    ],\n",
    "    default = \"-\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb861676",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# LPA_HE_join[(LPA_HE_join[\"pct_intersection\"] >= 0.9)].sort_values(\"pct_intersection\")\n",
    "# LPA_HE_join[(LPA_HE_join[\"issue_type\"] == \"LPA covers HE\")].sort_values(\"pct_intersection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81d94cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# count of issue types (where cover is defined as >=90% intersection, and edge as <=10%)\n",
    "LPA_HE_join.groupby([\"issue_type\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c200296c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count of non-edge issues\n",
    "nrow(LPA_HE_join[(LPA_HE_join[\"issue_type\"] != \"edge intersection\")])\n",
    "\n",
    "# LPAs with most non-intersection issues\n",
    "LPA_HE_join[(LPA_HE_join[\"issue_type\"] != \"edge intersection\")].groupby([\"organisation_name_1\"]).size().sort_values(ascending = False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d277ab",
   "metadata": {},
   "source": [
    "### Issue examples by type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35de951",
   "metadata": {},
   "source": [
    "#### LPA and HE cover each other (almost perfect matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e285dd",
   "metadata": {},
   "source": [
    "- need to get to the bottom of authority here, who can create conservation areas\n",
    "- could we just switch off HE conservation areas for an area when we add data for a new LPA?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0099304",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_issues_map(entity_gdf, \"44002803-44008960\", \"organisation_name\", \"Accent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6dac94",
   "metadata": {},
   "source": [
    "\n",
    "#### LPA covered by HE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e4f0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LPA_HE_join[(LPA_HE_join[\"issue_type\"] == \"LPA covered by HE\")].sort_values(\"pct_min_intersection\", ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbffcf2e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_issues_map(entity_gdf, \"44002322-44009177\", \"organisation_name\", \"Accent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc97495",
   "metadata": {},
   "source": [
    "\n",
    "#### LPA covers HE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69f21b7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_issues_map(entity_gdf, \"44005188-44009160\", \"organisation_name\", \"Accent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dbbb6a",
   "metadata": {},
   "source": [
    "#### Edge intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115bed8d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_issues_map(entity_gdf, \"44006481-44006512\", \"organisation_name\", \"Accent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56523059",
   "metadata": {},
   "source": [
    "#### Entities with multiple issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f87f919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LPA_HE_join[(LPA_HE_join[\"entity_1\"] == \"44006512\")]\n",
    "\n",
    "entity_count = LPA_HE_join.groupby([\"entity_1\"]).size().reset_index()\n",
    "entity_count.columns = [\"entity_1\", \"count\"]\n",
    "entity_count[entity_count[\"count\"] > 1].sort_values('count', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e790c295",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = LPA_HE_join[LPA_HE_join[\"entity_1\"] == \"44009090\"]\n",
    "\n",
    "# grab all entities that have an issue with  44009090\n",
    "te = np.concatenate((\n",
    "    t[\"entity_1\"].drop_duplicates().values,\n",
    "    t[\"entity_2\"].drop_duplicates().values\n",
    "))\n",
    "\n",
    "plot_issues_map(entity_gdf, te, \"organisation_name\", \"Accent\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e95126",
   "metadata": {},
   "source": [
    "#### Entities with non-classified issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f5e87f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# these are really just entities which have overlaps > 10% but less than 90% in one form \n",
    "LPA_HE_join[(LPA_HE_join[\"issue_type\"] == \"-\")].sort_values(\"pct_min_intersection\", ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a7916e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at entity re-directs\n",
    "entity_df[entity_df[\"entity\"].isin([\"44000549\", \"44008664\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce91c47",
   "metadata": {},
   "source": [
    "## Questions to resolve\n",
    "* how to find endpoint / resource for each entity?\n",
    "* what existing issues / replacements have been documented for the dataset?\n",
    "* which entity takes precedence? Oldest / newest?\n",
    "* what threshold to set for removing duplicates?\n",
    "* how to extract data required for updating through lookups file\n",
    "* how to replicate this check in endpoint checker with a new dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23c2d76",
   "metadata": {},
   "source": [
    "**notes from run-through with Swati**   \n",
    "feed in LPA boundaries here to make sure we contact the right LPA - change this query to use LPA boundaries.\n",
    "check with Carlos for how it's been done for brownfield"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdp_jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
