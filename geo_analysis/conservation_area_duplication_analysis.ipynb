{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d259be9-807c-4bf2-87d4-f5c88caf55e9",
   "metadata": {},
   "source": [
    "## Examining duplication Between Organisations\n",
    "\n",
    "In our data we often recieve multiple data sources per dataset. unfortunately this leads to duplication of geometries and other data points in the datasets. this notebook looks to investigate identifying these duplications between organisations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a279bd2a-487f-4496-8a2e-ba50e8de9070",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from download_data import download_dataset\n",
    "# from data import get_entity_dataset, nrow\n",
    "# from plot import plot_map, plot_issues_map\n",
    "import spatialite\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import itertools\n",
    "import shapely.wkt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import urllib\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022dabbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if running on Colab, uncomment and run this line below too:\n",
    "# !pip install mapclassify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aefbc24",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ddc2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nrow(df):\n",
    "    return print(f\"No. of records in df: {len(df):,}\")\n",
    "\n",
    "\n",
    "def plot_issues_map(gdf:gpd.GeoDataFrame, entity_list, chloro_var, palette):\n",
    "\n",
    "    if type(gdf) != gpd.GeoDataFrame:\n",
    "        logging.error('input is not a GeodataFrame')\n",
    "    \n",
    "    base = gdf[gdf[\"entity\"].isin(entity_list)].explore(\n",
    "        column = chloro_var,  # make choropleth based on \"BoroName\" column\n",
    "        cmap = palette,\n",
    "        tooltip = False,\n",
    "        popup = [\"organisation_name\", \"entity\", \"name\", \"reference\"],\n",
    "        tiles = \"CartoDB positron\",  # use \"CartoDB positron\" tiles\n",
    "        highlight = False,\n",
    "        style_kwds = {\n",
    "        \"fillOpacity\" : \"0.1\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return base\n",
    "\n",
    "def get_all_organisations():\n",
    "    params = urllib.parse.urlencode({\n",
    "        \"sql\": f\"\"\"\n",
    "        select organisation, name, entity as organisation_entity, statistical_geography\n",
    "        from organisation\n",
    "        \"\"\",\n",
    "        \"_size\": \"max\"\n",
    "        })\n",
    "    url = f\"https://datasette.planning.data.gov.uk/digital-land.csv?{params}\"\n",
    "    df = pd.read_csv(url)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c4f722",
   "metadata": {},
   "source": [
    "### Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a7b5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get LAD to LPA lookup from github\n",
    "lookup_lad_lpa = pd.read_csv(\"https://github.com/digital-land/organisation-collection/raw/main/data/local-authority.csv\",\n",
    "                             usecols = [\"entity\", \"local-authority-district\", \"local-planning-authority\"])\n",
    "\n",
    "lookup_lad_lpa.columns = [\"organisation_entity\", \"LADCD\", \"LPACD\"]\n",
    "\n",
    "nrow(lookup_lad_lpa)\n",
    "lookup_lad_lpa.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875da976",
   "metadata": {},
   "source": [
    "**Note on LAD to LPA mapping**   \n",
    "Currently this [lookup file from github](https://github.com/digital-land/organisation-collection/raw/main/data/local-authority.csv) just records a 1:1 link between LADs and LPAs, but according to the ONS this relationship is actually 1:many. \n",
    "See [2020 lookup file](https://geoportal.statistics.gov.uk/datasets/ons::local-planning-authority-to-local-authority-district-april-2020-in-the-united-kingdom-lookup-1/about) and the example of Ryedale [`E07000167`], which is mapped to the following two LPAs:\n",
    "\n",
    "* Ryedale LPA [`E60000061`]\n",
    "* North York Moors National Park LPA [`E60000322`]\n",
    "\n",
    "We need to agree some validation rules around this, i.e. can we expect Ryedale to submit data that might sit within either of these LPA areas, or for any London Boroughs to submit within the \"London Legacy Development Corporation LPA\" area?\n",
    "But for simplicity's sake at the moment to get things up and running (as per Owen's advice), will test with existing 1:1 mapping and aim to develop logic once there is more clarity about multiple area handling.\n",
    "\n",
    "The git lookup file also seems to be missing some areas, e.g. \"Peak District National Park Authority\" entity 405."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd32ce49",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_org[lookup_org[\"LADCD\"] == \"E07000167\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f4a672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get org data from datasette\n",
    "lookup_org = get_all_organisations()\n",
    "\n",
    "# lookup_org[\"organisation_entity\"] = lookup_org[\"organisation_entity\"].astype(str)\n",
    "lookup_org.columns = [\"organisation\", \"organisation_name\", \"organisation_entity\", \"statistical_geography\"]\n",
    "\n",
    "# split out org type and join on LPA codes from LAD to LPA lookup\n",
    "lookup_org[\"organisation_type\"] = lookup_org[\"organisation\"].apply(lambda x: x.split(\":\")[0])\n",
    "lookup_org = lookup_org.merge(lookup_lad_lpa, how = \"left\", on = \"organisation_entity\")\n",
    "\n",
    "nrow(lookup_org)\n",
    "lookup_org.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5112710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check what types of org are missing the LPA code\n",
    "nrow(lookup_org[lookup_org[\"LPACD\"].isnull()])\n",
    "lookup_org[lookup_org[\"LPACD\"].isnull()].groupby(\"organisation_type\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c238946a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LPA boundary data from planning.data.gov\n",
    "\n",
    "LPA_boundary_df = pd.read_csv(\"https://files.planning.data.gov.uk/dataset/local-planning-authority.csv\", \n",
    "                                  usecols = [\"reference\", \"name\", \"geometry\"])\n",
    "\n",
    "LPA_boundary_df.columns = [\"geometry\", \"name\", \"LPACD\"]\n",
    "\n",
    "\n",
    "# load geometry and create GDF\n",
    "LPA_boundary_df['geometry'] = LPA_boundary_df['geometry'].apply(shapely.wkt.loads)\n",
    "LPA_boundary_gdf = gpd.GeoDataFrame(LPA_boundary_df, geometry='geometry')\n",
    "\n",
    "# Transform to ESPG:27700 for more interpretable area units\n",
    "LPA_boundary_gdf.set_crs(epsg=4326, inplace=True)\n",
    "LPA_boundary_gdf.to_crs(epsg=27700, inplace=True)\n",
    "\n",
    "nrow(LPA_boundary_gdf)\n",
    "LPA_boundary_gdf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4f9db0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load conservation area entity dataset from planning.data.gov into geopandas and transform CRS to EPSG:27700\n",
    "\n",
    "entity_df = pd.read_csv(\"https://files.planning.data.gov.uk/dataset/conservation-area.csv\",\n",
    "                            usecols = [\"entity\", \"name\", \"organisation-entity\", \"reference\", \"geometry\"])\n",
    "            \n",
    "# entity_df.head()\n",
    "entity_df.columns = [x.replace(\"-\", \"_\") for x in entity_df.columns]\n",
    "\n",
    "\n",
    "\n",
    "# set entity to string, needed later to sort and remove duplicate self intersections\n",
    "entity_df[\"entity\"] = entity_df[\"entity\"].astype(str)\n",
    "# entity_df[\"organisation_entity\"] = entity_df[\"organisation_entity\"].astype(str)\n",
    "\n",
    "# join organisation name and LPA codes from lookup\n",
    "entity_df = entity_df.merge(\n",
    "    lookup_org[[\"organisation_name\", \"organisation_type\", \"organisation_entity\", \"LPACD\"]], \n",
    "    how = \"left\",\n",
    "    on = \"organisation_entity\")\n",
    "\n",
    "# load geometry and create GDF\n",
    "entity_df['geometry'] = entity_df['geometry'].apply(shapely.wkt.loads)\n",
    "entity_gdf = gpd.GeoDataFrame(entity_df, geometry='geometry')\n",
    "\n",
    "# Transform to ESPG:27700 for more interpretable area units\n",
    "entity_gdf.set_crs(epsg=4326, inplace=True)\n",
    "entity_gdf.to_crs(epsg=27700, inplace=True)\n",
    "\n",
    "# calculate area\n",
    "entity_gdf[\"area\"] = entity_gdf[\"geometry\"].area\n",
    "\n",
    "nrow(entity_gdf)\n",
    "entity_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155b018f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check of the organisations that we don't have an LPA code for\n",
    "entity_df[entity_df[\"LPACD\"].isnull()].groupby([\"organisation_type\", \"organisation_name\"]).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e509bf8b",
   "metadata": {},
   "source": [
    "# Identifying geographical duplicates\n",
    "\n",
    "## #1 - Intersection within organisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a708a928",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Overlay all non-Heritage England entities\n",
    "# [note - I was initially excluding Historic England from this, but don't see any reason to, changed below to include all]\n",
    "LPA_LPA_join = gpd.overlay(\n",
    "    entity_gdf, entity_gdf,\n",
    "    # entity_gdf[entity_gdf[\"organisation_entity\"] != 16],\n",
    "    # entity_gdf[entity_gdf[\"organisation_entity\"] != 16],\n",
    "    how = \"intersection\", keep_geom_type=False \n",
    ")\n",
    "\n",
    "# remove entity self-intersections and intersections across organisations\n",
    "LPA_LPA_join = LPA_LPA_join[(LPA_LPA_join[\"organisation_entity_1\"] == LPA_LPA_join[\"organisation_entity_2\"]) &\n",
    "             (LPA_LPA_join[\"entity_1\"] != LPA_LPA_join[\"entity_2\"])]\n",
    "\n",
    "# each intersection will be in there twice because we're joining the same dataset \n",
    "# (e.g. polygon1-polygon2 and polygon2-polygon1), so remove these\n",
    "LPA_LPA_join[\"entity_join\"] = LPA_LPA_join.apply(lambda x: '-'.join(sorted(x[[\"entity_1\", \"entity_2\"]])), axis=1)\n",
    "LPA_LPA_join.drop_duplicates(subset=\"entity_join\", inplace = True) #Drop them by name\n",
    "\n",
    "# calculate overlap %'s\n",
    "\n",
    "LPA_LPA_join[\"area_intersection\"] = LPA_LPA_join[\"geometry\"].area\n",
    "\n",
    "# LPA_LPA_join[\"p_pct_intersect\"] = LPA_LPA_join[\"area_intersection\"] / LPA_LPA_join[\"area_1\"]\n",
    "# LPA_LPA_join[\"pct_intersection\"] = LPA_LPA_join[\"area_intersection\"] / (LPA_LPA_join[\"area_1\"] + LPA_LPA_join[\"area_2\"] - LPA_LPA_join[\"area_intersection\"])\n",
    "# LPA_LPA_join[\"s_pct_intersect\"] = LPA_LPA_join[\"area_intersection\"] / LPA_LPA_join[\"area_2\"]\n",
    "\n",
    "# intersection area as % of smallest primary or secondary area\n",
    "LPA_LPA_join[\"pct_min_intersection\"] = LPA_LPA_join[\"area_intersection\"] / LPA_LPA_join[[\"area_1\", \"area_2\"]].min(axis = 1)\n",
    "\n",
    "nrow(LPA_LPA_join)\n",
    "LPA_LPA_join.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9621e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick check of distribution to check how many are edges vs. major overlaps\n",
    "plt.hist(LPA_LPA_join[\"pct_min_intersection\"], bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc648ba9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# how many entities with a greater than 10% intersection?\n",
    "nrow(LPA_LPA_join[(LPA_LPA_join[\"pct_min_intersection\"] > 0.5)])\n",
    "\n",
    "# LPA_LPA_join[(LPA_LPA_join[\"pct_min_intersection\"] > 0.1)].sort_values(\"pct_min_intersection\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ed5bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count by organisation of entities with intersections > 10%\n",
    "LPA_LPA_join[(LPA_LPA_join[\"pct_min_intersection\"] > 0.1)].groupby([\"organisation_name_1\"]).size().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d39c139",
   "metadata": {},
   "outputs": [],
   "source": [
    "LPA_LPA_join[(LPA_LPA_join[\"organisation_name_1\"] == \"Historic England\")].sort_values(\"pct_min_intersection\", ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2b3dff",
   "metadata": {},
   "source": [
    "**notes from run through with Swati**\n",
    "\n",
    "solution - go back to LPA\n",
    "possible explanation - data is coming from different endpoint, and first one is not retired. Need to rule this out before we go back to LPA.\n",
    "\n",
    "When new endpoint is added, we want to keep both. Want to keep record of data over time. Platform should only present latest version.\n",
    "Need to understand entity creation process a little bit more to understand how geo duplicates could get made - talk to Kena."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e67e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect example\n",
    "# plot_issues_map(entity_gdf, [\"44005062\", \"44002577\"], \"name\", \"Accent\")\n",
    "plot_issues_map(entity_gdf, [\"44000171\", \"44000170\"], \"name\", \"Accent\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc37eaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect example\n",
    "plot_issues_map(entity_gdf, [\"44008830\", \"44006848\"], \"name\", \"Accent\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9fdcd4",
   "metadata": {},
   "source": [
    "## #2 - Intersection across different LPAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106178b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlay all non-Heritage England entities\n",
    "LPA_cross_join = gpd.overlay(\n",
    "    entity_gdf[entity_gdf[\"organisation_entity\"] != 16],\n",
    "    entity_gdf[entity_gdf[\"organisation_entity\"] != 16],\n",
    "    how = \"intersection\", keep_geom_type=False \n",
    ")\n",
    "\n",
    "# filter to join across organisations and entities\n",
    "LPA_cross_join = LPA_cross_join[(LPA_cross_join[\"organisation_entity_1\"] != LPA_cross_join[\"organisation_entity_2\"]) &\n",
    "             (LPA_cross_join[\"entity_1\"] != LPA_cross_join[\"entity_2\"])]\n",
    "\n",
    "# each intersection will be in there twice because we're joining the same dataset \n",
    "# (e.g. polygon1-polygon2 and polygon2-polygon1), so remove these\n",
    "LPA_cross_join[\"entity_join\"] = LPA_cross_join.apply(lambda x: '-'.join(sorted(x[[\"entity_1\", \"entity_2\"]])), axis=1)\n",
    "LPA_cross_join.drop_duplicates(subset=\"entity_join\", inplace = True) #Drop them by name\n",
    "\n",
    "# # calculate overlap %'s\n",
    "\n",
    "LPA_cross_join[\"area_intersection\"] = LPA_cross_join[\"geometry\"].area\n",
    "\n",
    "# # LPA_LPA_join[\"p_pct_intersect\"] = LPA_LPA_join[\"area_intersection\"] / LPA_LPA_join[\"area_1\"]\n",
    "# # LPA_LPA_join[\"pct_intersection\"] = LPA_LPA_join[\"area_intersection\"] / (LPA_LPA_join[\"area_1\"] + LPA_LPA_join[\"area_2\"] - LPA_LPA_join[\"area_intersection\"])\n",
    "# # LPA_LPA_join[\"s_pct_intersect\"] = LPA_LPA_join[\"area_intersection\"] / LPA_LPA_join[\"area_2\"]\n",
    "\n",
    "# intersection area as % of smallest primary or secondary area\n",
    "LPA_cross_join[\"pct_min_intersection\"] = LPA_cross_join[\"area_intersection\"] / LPA_cross_join[[\"area_1\", \"area_2\"]].min(axis = 1)\n",
    "\n",
    "nrow(LPA_cross_join)\n",
    "LPA_cross_join.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314917c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at distribution to check how many are edges vs. major overlaps\n",
    "plt.hist(LPA_cross_join[\"pct_min_intersection\"], bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13770849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many entities which have issues of intersection > 10%? \n",
    "LPA_cross_join[(LPA_cross_join[\"pct_min_intersection\"] > 0.1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9224445",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = \"44009059\"\n",
    "ents = LPA_cross_join[(LPA_cross_join[\"entity_1\"] == e)][[\"entity_1\", \"entity_2\"]].iloc[0, :].values\n",
    "\n",
    "plot_issues_map(entity_gdf, ents, \"organisation_name\", \"Accent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacffd08",
   "metadata": {},
   "source": [
    "## #2.b - Beyond-border data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c58973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List LPA codes from entity df and check they're all in the LPA gdf\n",
    "lpa_list = entity_df[\"LPACD\"][entity_df[\"LPACD\"].notnull()].drop_duplicates().to_list()\n",
    "\n",
    "# check every one of our entity LPAs is in the LPA gdf\n",
    "print(len(lpa_list))\n",
    "nrow(LPA_boundary_gdf[LPA_boundary_gdf[\"LPACD\"].isin(lpa_list)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61796d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "geogs_out_entities = []\n",
    "\n",
    "# loop through LPA codes and for each check whether any conservation areas with that code don't intersect at all with the LPA boundary\n",
    "for lpa_code in lpa_list:\n",
    "\n",
    "    cons_areas = entity_gdf[entity_gdf[\"LPACD\"] == lpa_code]\n",
    "    cons_areas_intersect = cons_areas.geometry.intersects(LPA_boundary_gdf[LPA_boundary_gdf[\"LPACD\"] == lpa_code].iloc[0].geometry)\n",
    "\n",
    "    # add areas which don't intersect to the list\n",
    "    geogs_out_entities.extend(cons_areas.loc[~cons_areas_intersect][\"entity\"].to_list())\n",
    "\n",
    "\n",
    "entity_outside_LPA_df = entity_df[entity_df[\"entity\"].isin(geogs_out_entities)]\n",
    "\n",
    "# list of LPAs with entities outside them\n",
    "LPAs_with_bads = entity_outside_LPA_df[\"LPACD\"].drop_duplicates().to_list()\n",
    "\n",
    "print(f\"No. of bad entities found: {len(entity_outside_LPA_df):,}\")\n",
    "entity_outside_LPA_df.groupby(\"organisation_name\").size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ed318c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map for LPA with entities outside it\n",
    "\n",
    "LPA_code = LADs_with_bads[0]\n",
    "bad_ents = entity_outside_LPA_df[\"entity\"][entity_outside_LPA_df[\"LPACD\"] == LPA_code]\n",
    "\n",
    "\n",
    "map_entities = entity_gdf[entity_gdf[\"entity\"].isin(bad_ents)].explore(\n",
    "        # column = chloro_var,  # make choropleth based on \"BoroName\" column\n",
    "        # cmap = palette,\n",
    "    color = \"red\",\n",
    "        # tooltip = False,\n",
    "        # popup = [\"organisation_name\", \"entity\", \"name\", \"reference\"],\n",
    "        tiles = \"CartoDB positron\",  # use \"CartoDB positron\" tiles\n",
    "        highlight = False,\n",
    "        style_kwds = {\n",
    "        \"fillOpacity\" : \"0.1\"\n",
    "        }\n",
    ")\n",
    "\n",
    "LPA_boundary_gdf[LPA_boundary_gdf[\"LPACD\"] == LPA_code].explore(\n",
    "    m = map_entities,\n",
    "    color = \"blue\",\n",
    "        style_kwds = {\n",
    "        \"fillOpacity\" : \"0\"\n",
    "        }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44663791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map for LPA with entities outside it\n",
    "\n",
    "LPA_code = LADs_with_bads[2]\n",
    "bad_ents = entity_outside_LPA_df[\"entity\"][entity_outside_LPA_df[\"LPACD\"] == LPA_code]\n",
    "\n",
    "\n",
    "map_entities = entity_gdf[entity_gdf[\"entity\"].isin(bad_ents)].explore(\n",
    "        # column = chloro_var,  # make choropleth based on \"BoroName\" column\n",
    "        # cmap = palette,\n",
    "    color = \"red\",\n",
    "        # tooltip = False,\n",
    "        # popup = [\"organisation_name\", \"entity\", \"name\", \"reference\"],\n",
    "        tiles = \"CartoDB positron\",  # use \"CartoDB positron\" tiles\n",
    "        highlight = False,\n",
    "        style_kwds = {\n",
    "        \"fillOpacity\" : \"0.1\"\n",
    "        }\n",
    ")\n",
    "\n",
    "LPA_boundary_gdf[LPA_boundary_gdf[\"LPACD\"] == LPA_code].explore(\n",
    "    m = map_entities,\n",
    "    color = \"blue\",\n",
    "        style_kwds = {\n",
    "        \"fillOpacity\" : \"0\"\n",
    "        }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d192b28f",
   "metadata": {},
   "source": [
    "## Issue #3 LPA => Historic England intersections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1772ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = time.time()\n",
    "\n",
    "LPA_HE_join = gpd.overlay(\n",
    "    entity_gdf[entity_gdf[\"organisation_entity\"] != 16],\n",
    "    entity_gdf[entity_gdf[\"organisation_entity\"] == 16],\n",
    "    how = \"intersection\", keep_geom_type=False\n",
    ")\n",
    "\n",
    "LPA_HE_join[\"area_intersection\"] = LPA_HE_join[\"geometry\"].area\n",
    "\n",
    "LPA_HE_join[\"p_pct_intersect\"] = LPA_HE_join[\"area_intersection\"] / LPA_HE_join[\"area_1\"]\n",
    "LPA_HE_join[\"pct_intersection\"] = LPA_HE_join[\"area_intersection\"] / (LPA_HE_join[\"area_1\"] + LPA_HE_join[\"area_2\"] - LPA_HE_join[\"area_intersection\"])\n",
    "LPA_HE_join[\"s_pct_intersect\"] = LPA_HE_join[\"area_intersection\"] / LPA_HE_join[\"area_2\"]\n",
    "\n",
    "\n",
    "# intersection area as % of smallest primary or secondary area\n",
    "LPA_HE_join[\"pct_min_intersection\"] = LPA_HE_join[\"area_intersection\"] / LPA_HE_join[[\"area_1\", \"area_2\"]].min(axis = 1)\n",
    "\n",
    "\n",
    "# end_time = time.time()\n",
    "\n",
    "# elapsed_time = (end_time - start_time) \n",
    "# print(f\"Elapsed time: {elapsed_time:.2f} \")\n",
    "\n",
    "nrow(LPA_HE_join)\n",
    "LPA_HE_join.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dc94b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the issues by the amount the two entities which make up each issue intersect each other\n",
    "# this is useful to start to define categories for the types of issues they represent\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.grid()\n",
    "plt.scatter(LPA_HE_join[\"p_pct_intersect\"], LPA_HE_join[\"s_pct_intersect\"], s = 8, alpha=0.6)\n",
    "fig.suptitle('Entity intersection %s', fontsize=14)\n",
    "plt.xlabel('% of LPA entity intersected', fontsize=10)\n",
    "plt.ylabel('% of Historic England entity intersected', fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8644be09",
   "metadata": {},
   "source": [
    "By the number of points on the far right of the chart we can see that there are a lot of LPA entities which are entirely or almost entirely contained within an HE entity, but how closely the HE area matches varies from not at all to almost exactly.\n",
    "\n",
    "Bottom left is a cluster of tiny edge intersections, and there are a small number of instances where HE entities are contained within LPA ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9964944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flag issue types - defined to pick up main issue clusters on chart above and using a 90% or 10% intersection cutoffs\n",
    "\n",
    "LPA_HE_join[\"issue_type\"] = np.select(\n",
    "    [\n",
    "        (LPA_HE_join[\"p_pct_intersect\"] >= 0.9) & (LPA_HE_join[\"s_pct_intersect\"] >= 0.9),\n",
    "        (LPA_HE_join[\"p_pct_intersect\"] <= 0.1) & (LPA_HE_join[\"s_pct_intersect\"] <= 0.1),\n",
    "        (LPA_HE_join[\"p_pct_intersect\"] >= 0.9),\n",
    "        (LPA_HE_join[\"s_pct_intersect\"] >= 0.9)\n",
    "    ],\n",
    "    [\n",
    "        \"LPA and HE cover each other\", \"edge intersection\", \"LPA covered by HE\", \"LPA covers HE\"\n",
    "    ],\n",
    "    default = \"-\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb861676",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# LPA_HE_join[(LPA_HE_join[\"pct_intersection\"] >= 0.9)].sort_values(\"pct_intersection\")\n",
    "# LPA_HE_join[(LPA_HE_join[\"issue_type\"] == \"LPA covers HE\")].sort_values(\"pct_intersection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81d94cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# count of issue types (where cover is defined as >=90% intersection, and edge as <=10%)\n",
    "LPA_HE_join.groupby([\"issue_type\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c200296c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LPAs with most non-intersection issues\n",
    "LPA_HE_join[(LPA_HE_join[\"issue_type\"] != \"edge intersection\")].groupby([\"organisation_name_1\"]).size().sort_values(ascending = False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d277ab",
   "metadata": {},
   "source": [
    "### Issue examples by type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35de951",
   "metadata": {},
   "source": [
    "#### LPA and HE cover each other (almost perfect matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e285dd",
   "metadata": {},
   "source": [
    "- need to get to the bottom of authority here, who can create conservation areas\n",
    "- could we just switch off HE conservation areas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0099304",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "e = \"44008960\"\n",
    "ents = LPA_HE_join[(LPA_HE_join[\"entity_1\"] == e)][[\"entity_1\", \"entity_2\"]].iloc[0, :].values\n",
    "\n",
    "plot_issues_map(entity_gdf, ents, \"organisation_name\", \"Accent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6dac94",
   "metadata": {},
   "source": [
    "\n",
    "#### LPA covered by HE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e4f0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LPA_HE_join[(LPA_HE_join[\"issue_type\"] == \"LPA covered by HE\")].sort_values(\"pct_min_intersection\", ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbffcf2e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "e = \"44009177\"\n",
    "ents = LPA_HE_join[(LPA_HE_join[\"entity_1\"] == e)][[\"entity_1\", \"entity_2\"]].iloc[0, :].values\n",
    "\n",
    "plot_issues_map(entity_gdf, ents, \"organisation_name\", \"Accent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc97495",
   "metadata": {},
   "source": [
    "\n",
    "#### LPA covers HE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69f21b7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "e = \"44009160\"\n",
    "ents = LPA_HE_join[(LPA_HE_join[\"entity_1\"] == e)][[\"entity_1\", \"entity_2\"]].iloc[0, :].values\n",
    "\n",
    "plot_issues_map(entity_gdf, ents, \"organisation_name\", \"Accent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dbbb6a",
   "metadata": {},
   "source": [
    "#### Edge intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115bed8d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "e = \"44006512\"\n",
    "ents = LPA_HE_join[(LPA_HE_join[\"entity_1\"] == e)][[\"entity_1\", \"entity_2\"]].iloc[0, :].values\n",
    "\n",
    "plot_issues_map(entity_gdf, ents, \"organisation_name\", \"Accent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56523059",
   "metadata": {},
   "source": [
    "#### Entities with multiple issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f87f919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LPA_HE_join[(LPA_HE_join[\"entity_1\"] == \"44006512\")]\n",
    "\n",
    "entity_count = LPA_HE_join.groupby([\"entity_1\"]).size().reset_index()\n",
    "entity_count.columns = [\"entity_1\", \"count\"]\n",
    "entity_count[entity_count[\"count\"] > 1].sort_values('count', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e790c295",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = LPA_HE_join[LPA_HE_join[\"entity_1\"] == \"44009090\"]\n",
    "\n",
    "# grab all entities that have an issue with  44009090\n",
    "te = np.concatenate((\n",
    "    t[\"entity_1\"].drop_duplicates().values,\n",
    "    t[\"entity_2\"].drop_duplicates().values\n",
    "))\n",
    "\n",
    "plot_issues_map(entity_gdf, te, \"organisation_name\", \"Accent\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e95126",
   "metadata": {},
   "source": [
    "#### Entities with non-classified issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f5e87f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# these are really just entities which have overlaps > 10% but less than 90% in one form \n",
    "LPA_HE_join[(LPA_HE_join[\"issue_type\"] == \"-\")].sort_values(\"pct_min_intersection\", ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a7916e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at entity re-directs\n",
    "entity_df[entity_df[\"entity\"].isin([\"44000549\", \"44008664\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce91c47",
   "metadata": {},
   "source": [
    "## Questions to resolve\n",
    "* how to find endpoint / resource for each entity?\n",
    "* what existing issues / replacements have been documented for the dataset?\n",
    "* which entity takes precedence? Oldest / newest?\n",
    "* what threshold to set for removing duplicates?\n",
    "* how to extract data required for updating through lookups file\n",
    "* how to replicate this check in endpoint checker with a new dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23c2d76",
   "metadata": {},
   "source": [
    "**notes from run-through with Swati**   \n",
    "feed in LPA boundaries here to make sure we contact the right LPA - change this query to use LPA boundaries.\n",
    "check with Carlos for how it's been done for brownfield"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdp_jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
