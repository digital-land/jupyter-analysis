{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39a61a48",
   "metadata": {},
   "source": [
    "## Description    \n",
    "\n",
    "The purpose of this notebook is to produce some interactive html maps which can be shared with LPAs to help them explore and resolve duplication or overlap issues with conservation area data that's been supplied.\n",
    "\n",
    "The initial focus is on interaction between LPA and Historic England (HE) polygons, to highlight to LPAs where there are close matches (in which case we'll redirect the HE polygon to the LPA one), or where there are differences - for example there are many LPA polygons within a single HE polygon (in which case we'd like a steer from the LPA on the resolution).\n",
    "\n",
    "### How to use\n",
    "1. Run all cells within the \"Functions\", \"Data import\", and \"Report\" sections   \n",
    "\n",
    "2. In the \"Map for LPA analysis\" section set the `org_name` variable to one of the LPAs from the table above, and run all the section cells below - this should save a html version of the Folium map in the notebook directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a279bd2a-487f-4496-8a2e-ba50e8de9070",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from download_data import download_dataset\n",
    "# from data import get_entity_dataset, nrow\n",
    "# from plot import plot_map, plot_issues_map\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import shapely.wkt\n",
    "import logging\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "import urllib\n",
    "\n",
    "import numpy as np\n",
    "import folium\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022dabbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if running on Colab, uncomment and run this line below too:\n",
    "# !pip install mapclassify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "data_dir = \"../data/geo_analysis/LPA-investigations/\"\n",
    "os.makedirs(data_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aefbc24",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d566966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nrow(df):\n",
    "    return print(f\"No. of records in df: {len(df):,}\")\n",
    "\n",
    "\n",
    "def plot_issues_map(gdf:gpd.GeoDataFrame, entity_list, chloro_var, palette):\n",
    "\n",
    "    if type(gdf) != gpd.GeoDataFrame:\n",
    "        logging.error('input is not a GeodataFrame')\n",
    "    \n",
    "    base = gdf[gdf[\"entity\"].isin(entity_list)].explore(\n",
    "        column = chloro_var,  # make choropleth based on \"BoroName\" column\n",
    "        cmap = palette,\n",
    "        tooltip = False,\n",
    "        popup = [\"organisation_name\", \"entity\", \"name\", \"entry_date\", \"reference\"],\n",
    "        tiles = \"CartoDB positron\",  # use \"CartoDB positron\" tiles\n",
    "        highlight = True,\n",
    "        style_kwds = {\n",
    "        \"fillOpacity\" : \"0.1\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return base\n",
    "\n",
    "def get_all_organisations():\n",
    "    params = urllib.parse.urlencode({\n",
    "        \"sql\": f\"\"\"\n",
    "        select organisation, name, entity as organisation_entity, statistical_geography\n",
    "        from organisation\n",
    "        \"\"\",\n",
    "        \"_size\": \"max\"\n",
    "        })\n",
    "    url = f\"https://datasette.planning.data.gov.uk/digital-land.csv?{params}\"\n",
    "    df = pd.read_csv(url)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_old_entity(collection_name):\n",
    "    params = urllib.parse.urlencode({\n",
    "        \"sql\": f\"\"\"\n",
    "        select *\n",
    "        from old_entity\n",
    "        \"\"\",\n",
    "        \"_size\": \"max\"\n",
    "        })\n",
    "    url = f\"https://datasette.planning.data.gov.uk/{collection_name}.csv?{params}\"\n",
    "    df = pd.read_csv(url)\n",
    "    return df\n",
    "\n",
    "def get_issue_entities(issues_df):\n",
    "\n",
    "    return pd.concat([issues_df[\"entity_1\"], issues_df[\"entity_2\"]]).drop_duplicates().to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c4f722",
   "metadata": {},
   "source": [
    "### Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a7b5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get LAD to LPA lookup from github\n",
    "lookup_lad_lpa = pd.read_csv(\"https://github.com/digital-land/organisation-collection/raw/main/data/local-authority.csv\",\n",
    "                             usecols = [\"entity\", \"local-authority-district\", \"local-planning-authority\"])\n",
    "\n",
    "lookup_lad_lpa.columns = [\"organisation_entity\", \"LADCD\", \"LPACD\"]\n",
    "\n",
    "nrow(lookup_lad_lpa)\n",
    "lookup_lad_lpa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f4a672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get org data from datasette\n",
    "lookup_org = get_all_organisations()\n",
    "\n",
    "# lookup_org[\"organisation_entity\"] = lookup_org[\"organisation_entity\"].astype(str)\n",
    "lookup_org.columns = [\"organisation\", \"organisation_name\", \"organisation_entity\", \"statistical_geography\"]\n",
    "\n",
    "# split out org type and join on LPA codes from LAD to LPA lookup\n",
    "lookup_org[\"organisation_type\"] = lookup_org[\"organisation\"].apply(lambda x: x.split(\":\")[0])\n",
    "lookup_org = lookup_org.merge(lookup_lad_lpa, how = \"left\", on = \"organisation_entity\")\n",
    "\n",
    "nrow(lookup_org)\n",
    "lookup_org.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5112710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check what types of org are missing the LPA code\n",
    "nrow(lookup_org[lookup_org[\"LPACD\"].isnull()])\n",
    "# lookup_org[lookup_org[\"LPACD\"].isnull()].groupby(\"organisation_type\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c238946a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LPA boundary data from planning.data.gov\n",
    "\n",
    "LPA_boundary_df = pd.read_csv(\"https://files.planning.data.gov.uk/dataset/local-planning-authority.csv\", \n",
    "                                  usecols = [\"reference\", \"name\", \"geometry\"])\n",
    "\n",
    "LPA_boundary_df.columns = [\"geometry\", \"name\", \"LPACD\"]\n",
    "\n",
    "\n",
    "# load geometry and create GDF\n",
    "LPA_boundary_df['geometry'] = LPA_boundary_df['geometry'].apply(shapely.wkt.loads)\n",
    "LPA_boundary_gdf = gpd.GeoDataFrame(LPA_boundary_df, geometry='geometry')\n",
    "\n",
    "# Transform to ESPG:27700 for more interpretable area units\n",
    "LPA_boundary_gdf.set_crs(epsg=4326, inplace=True)\n",
    "LPA_boundary_gdf.to_crs(epsg=27700, inplace=True)\n",
    "\n",
    "nrow(LPA_boundary_gdf)\n",
    "# LPA_boundary_gdf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4f9db0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load conservation area entity dataset from planning.data.gov into geopandas and transform CRS to EPSG:27700\n",
    "\n",
    "entity_df = pd.read_csv(\"https://files.planning.data.gov.uk/dataset/conservation-area.csv\",\n",
    "                            usecols = [\"entity\", \"name\", \"organisation-entity\", \"reference\", \"entry-date\", \"geometry\"])\n",
    "            \n",
    "# entity_df.head()\n",
    "entity_df.columns = [x.replace(\"-\", \"_\") for x in entity_df.columns]\n",
    "\n",
    "\n",
    "\n",
    "# set entity to string, needed later to sort and remove duplicate self intersections\n",
    "entity_df[\"entity\"] = entity_df[\"entity\"].astype(str)\n",
    "# entity_df[\"organisation_entity\"] = entity_df[\"organisation_entity\"].astype(str)\n",
    "\n",
    "# join organisation name and LPA codes from lookup\n",
    "entity_df = entity_df.merge(\n",
    "    lookup_org[[\"organisation_name\", \"organisation_type\", \"organisation_entity\", \"LPACD\"]], \n",
    "    how = \"left\",\n",
    "    on = \"organisation_entity\")\n",
    "\n",
    "# load geometry and create GDF\n",
    "entity_df['geometry'] = entity_df['geometry'].apply(shapely.wkt.loads)\n",
    "entity_gdf = gpd.GeoDataFrame(entity_df, geometry='geometry')\n",
    "\n",
    "# Transform to ESPG:27700 for more interpretable area units\n",
    "entity_gdf.set_crs(epsg=4326, inplace=True)\n",
    "entity_gdf.to_crs(epsg=27700, inplace=True)\n",
    "\n",
    "# calculate area\n",
    "entity_gdf[\"area\"] = entity_gdf[\"geometry\"].area\n",
    "\n",
    "\n",
    "# flag for whether org is HE or LPA\n",
    "entity_gdf[\"org_HE_LPA\"] = np.where(entity_gdf[\"organisation_entity\"] == 16, \"Historic England\", \"Local Planning Authority\")\n",
    "\n",
    "nrow(entity_gdf)\n",
    "entity_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155b018f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check of the organisations that we don't have an LPA code for\n",
    "entity_df[entity_df[\"LPACD\"].isnull()].groupby([\"organisation_type\", \"organisation_name\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf820b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_entity_df = get_old_entity(\"conservation-area\")\n",
    "old_entity_df[\"entity\"] = old_entity_df[\"entity\"].astype('str')\n",
    "old_entity_df[\"old_entity\"] = old_entity_df[\"old_entity\"].astype('str')\n",
    "\n",
    "nrow(old_entity_df)\n",
    "old_entity_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b25f827",
   "metadata": {},
   "source": [
    "# Identifying geographical duplicates  \n",
    "## Report\n",
    "\n",
    "Aim of this is to quickly categorise the overlaps based on whether they fall into the following groups:\n",
    "\n",
    "Entity overlaps with another: \n",
    "\n",
    "1. within the same organisation\n",
    "    \n",
    "2. from a different organisation   \n",
    "\n",
    "    a. LPA entity overlaps with entity from another LPA\n",
    "        \n",
    "    b. LPA entity overlaps with entity from Historic England\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "As well as classifying by how much the overlaps are happening in order inform possible resolutions. Each entity-entity overlap is put in one of the following groups, which are given a corresponding priority to address:\n",
    "\n",
    "\n",
    "* **> 90% combined match** (high priority): 90% or more of each entity's area overlaps with the other - this suggests the boundaries of each almost perfectly match  \n",
    "\n",
    "* **> 90% single match** (medium priority): 90% of more of one entity's area overlaps with the other - this suggests the entities overlap but the boundaries don't closely match (one may be much larger than the other, for instance)\n",
    "* **> edge intersection** (low priority): between 1 - 10% of each entity's area overlaps with the other\n",
    "* **> unclassified** (low priority): the two entities overlap somewhat, but the overlapped area makes up less than 90% of each entity's area\n",
    "* **> tiny edge** (ignore): less than 1% of each entity's area overlaps with the other - there are a large number of these and are relatively normal when combining data from many sources.\n",
    "\n",
    "<br>\n",
    "\n",
    "Some other useful bits of information are flagged in order to make some suggestions about why the problem has happened. These should be checked when using the output csvs:\n",
    "* does the entry date for each entity match? When it doesn't it suggests that the issue may have arisen from data being combined from successive endpoints.\n",
    "* do either of the entities exist as an old entity in the `old-entity.csv` for the collection?\n",
    "* do either of the entities have other issues associated with them (excluding edge intersections, as it's common to have many of these). This can be useful to know if an issue is that one much larger polygon covers many smaller ones.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f29f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "MATCH_LOWER_THRESH = 0.9  # defines the lower limit of the shared overlap between two entities to be called a match\n",
    "EDGE_UPPER_THRESH = 0.1   # defines the upper limit of the shared overlap between two entities to be called an edge intersection\n",
    "EDGE_LOWER_THRESH = 0.01   # defines the lower limit of the shared overlap between two entities to be called an edge intersection\n",
    "\n",
    "\n",
    "# full join of all geometries\n",
    "entity_join_all = gpd.overlay(\n",
    "    entity_gdf, \n",
    "    entity_gdf,\n",
    "    how = \"intersection\", keep_geom_type=False \n",
    ")\n",
    "\n",
    "\n",
    "# remove self-intersections and duplicates of the same intersections\n",
    "entity_join_all = entity_join_all[entity_join_all[\"entity_1\"] != entity_join_all[\"entity_2\"]]\n",
    "\n",
    "entity_join_all[\"entity_join\"] = entity_join_all.apply(lambda x: '-'.join(sorted(x[[\"entity_1\", \"entity_2\"]])), axis=1)\n",
    "\n",
    "# extra sort to make sure matches to Historic England always show as Historic England as org 2 \n",
    "entity_join_all[\"name_for_sort\"] = np.where(entity_join_all[\"organisation_entity_1\"] == 16, \"Z\", \"A\")\n",
    "entity_join_all.sort_values([\"entity_join\", \"name_for_sort\"], ascending=True, inplace=True)\n",
    "\n",
    "entity_join_all.drop_duplicates(subset=\"entity_join\", inplace = True)  #Drop them by name\n",
    "\n",
    "# nrow(entity_join_all)\n",
    "\n",
    "# flag the types of intersections between organisations\n",
    "# is org the same\n",
    "entity_join_all[\"int_org_match\"] = np.where(entity_join_all[\"organisation_entity_1\"] == entity_join_all[\"organisation_entity_2\"], True, False)\n",
    "\n",
    "# the types of org-org matches\n",
    "entity_join_all[\"int_org_types\"] = np.select(\n",
    "    [\n",
    "        (entity_join_all[\"organisation_entity_1\"] == 16) & (entity_join_all[\"organisation_entity_2\"] == 16),\n",
    "        (entity_join_all[\"organisation_entity_1\"] != 16) & (entity_join_all[\"organisation_entity_2\"] != 16),\n",
    "        ((entity_join_all[\"organisation_entity_1\"] != 16) & (entity_join_all[\"organisation_entity_2\"] == 16)) |\n",
    "        ((entity_join_all[\"organisation_entity_1\"] == 16) & (entity_join_all[\"organisation_entity_2\"] != 16))\n",
    "    ],\n",
    "    [\"HE - HE\", \"LPA - LPA\", \"HE - other\"],\n",
    "    default = \"-\"\n",
    ")\n",
    "\n",
    "# does the entity entry date match?\n",
    "entity_join_all[\"date_match\"] = np.where(entity_join_all[\"entry_date_1\"] == entity_join_all[\"entry_date_2\"], True, False)\n",
    "\n",
    "# has one of the intersected entities already been re-mapped?\n",
    "entity_join_all[\"entity_old\"] = np.where(entity_join_all[\"entity_1\"].isin(old_entity_df[\"old_entity\"]) |\n",
    "                                         entity_join_all[\"entity_2\"].isin(old_entity_df[\"old_entity\"]), True, False)\n",
    "\n",
    "\n",
    "# calculate overlap %'s\n",
    "\n",
    "entity_join_all[\"area_intersection\"] = entity_join_all[\"geometry\"].area\n",
    "\n",
    "entity_join_all[\"p_pct_intersect\"] = entity_join_all[\"area_intersection\"] / entity_join_all[\"area_1\"]\n",
    "entity_join_all[\"pct_intersection\"] = entity_join_all[\"area_intersection\"] / (entity_join_all[\"area_1\"] + entity_join_all[\"area_2\"] - entity_join_all[\"area_intersection\"])\n",
    "entity_join_all[\"s_pct_intersect\"] = entity_join_all[\"area_intersection\"] / entity_join_all[\"area_2\"]\n",
    "\n",
    "# intersection area as % of smallest primary or secondary area\n",
    "entity_join_all[\"pct_min_intersection\"] = entity_join_all[\"area_intersection\"] / entity_join_all[[\"area_1\", \"area_2\"]].min(axis = 1)\n",
    "\n",
    "\n",
    "entity_join_all[\"intersection_type\"] = np.select(\n",
    "    [\n",
    "        (entity_join_all[\"p_pct_intersect\"] >= MATCH_LOWER_THRESH) & (entity_join_all[\"s_pct_intersect\"] >= MATCH_LOWER_THRESH),\n",
    "        (entity_join_all[\"pct_min_intersection\"] <= EDGE_UPPER_THRESH) & (entity_join_all[\"pct_min_intersection\"] >= EDGE_LOWER_THRESH),\n",
    "        (entity_join_all[\"pct_min_intersection\"] < EDGE_LOWER_THRESH),\n",
    "        ((entity_join_all[\"p_pct_intersect\"] >= MATCH_LOWER_THRESH) | (entity_join_all[\"s_pct_intersect\"] >= MATCH_LOWER_THRESH)),\n",
    "        \n",
    "    ],\n",
    "    [\n",
    "        \"> 90% combined match\", \"edge intersection\", \"tiny edge - ignore\", \"> 90% single match\"\n",
    "    ],\n",
    "    default = \"unclassified\"\n",
    ")\n",
    "\n",
    "nrow(entity_join_all)\n",
    "entity_join_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db37f4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag entities which have multiple issues (this is discounting where the issue type is tiny edge intersections)\n",
    "no_tinies = entity_join_all[entity_join_all[\"intersection_type\"] != \"tiny edge - ignore\"]\n",
    "\n",
    "all_ents = pd.concat([no_tinies[\"entity_1\"], no_tinies[\"entity_2\"]], ignore_index = True)\n",
    "multi_issue_ents = all_ents.loc[all_ents.duplicated(keep = False)]\n",
    "\n",
    "\n",
    "entity_join_all[\"multiple_issues\"] = np.where(\n",
    "    ((entity_join_all[\"intersection_type\"] != \"tiny edge - ignore\") & (entity_join_all[\"entity_2\"].isin(multi_issue_ents))) |\n",
    "    ((entity_join_all[\"intersection_type\"] != \"tiny edge - ignore\") & (entity_join_all[\"entity_1\"].isin(multi_issue_ents))),\n",
    "    True, False)\n",
    "\n",
    "entity_join_all.groupby(\"multiple_issues\").size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5567b041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLAGGING ISSUE DETAILS\n",
    "\n",
    "# Org overlap types\n",
    "entity_join_all[\"issue_type\"] = np.select(\n",
    "    [\n",
    "        (entity_join_all[\"int_org_match\"] == False) & (entity_join_all[\"int_org_types\"] == \"HE - other\"),\n",
    "        (entity_join_all[\"int_org_match\"] == False) & (entity_join_all[\"int_org_types\"] == \"LPA - LPA\"),\n",
    "        (entity_join_all[\"int_org_match\"] == True) & (entity_join_all[\"int_org_types\"] == \"HE - HE\"),\n",
    "        (entity_join_all[\"int_org_match\"] == True) & (entity_join_all[\"int_org_types\"] == \"LPA - LPA\")\n",
    "    ],\n",
    "    [\"Between organisations - Historic England to LPA\",\n",
    "     \"Between organisations - LPA to a different LPA\",\n",
    "     \"Within organisation - Historic England\",\n",
    "     \"Within organisation - LPA\"],\n",
    "\n",
    "    default = \"-\"\n",
    ")\n",
    "\n",
    "# Action\n",
    "entity_join_all[\"action\"] = np.select(\n",
    "    [\n",
    "        (entity_join_all[\"intersection_type\"] == \"tiny edge - ignore\"),\n",
    "        (entity_join_all[\"int_org_match\"] == True) & (entity_join_all[\"int_org_types\"] == \"HE - HE\"),\n",
    "        (entity_join_all[\"int_org_match\"] == False) & \n",
    "            (entity_join_all[\"int_org_types\"] == \"HE - other\") & \n",
    "            (entity_join_all[\"intersection_type\"] == \"> 90% combined match\") &\n",
    "            (entity_join_all[\"multiple_issues\"] == False) \n",
    "\n",
    "    ],\n",
    "    [\"ignore\", \"ignore\", \"remap\"],\n",
    "    default = \"investigate\"\n",
    ")\n",
    "\n",
    "# Priority and hint\n",
    "issue_priority_mapping = {\n",
    "    \"> 90% combined match\" : \"high\",\n",
    "    \"> 90% single match\" : \"medium\",\n",
    "    \"edge intersection\" : \"low\",\n",
    "    \"unclassified\" : \"low\",\n",
    "    \"tiny edge - ignore\" : \"\"\n",
    "}\n",
    "\n",
    "issue_hint_mapping = {\n",
    "    True : \"raise with LPA\",\n",
    "    False : \"check endpoints\"\n",
    "}\n",
    "\n",
    "entity_join_all[\"priority\"] = [issue_priority_mapping[data[\"intersection_type\"]] if data[\"action\"] != \"ignore\" else \"\" for (index, data) in entity_join_all.iterrows()]\n",
    "entity_join_all[\"hint\"] = [issue_hint_mapping[data[\"date_match\"]] if \n",
    "                           (data[\"int_org_match\"] == True) & (data[\"int_org_types\"] == \"LPA - LPA\") & (data[\"action\"] != \"ignore\") \n",
    "                           else \"\" for (index, data) in entity_join_all.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c186bf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the flagging or intersections between different org types is correct\n",
    "# entity_join_all.groupby([\"int_org_match\", \"int_org_types\", \"organisation_entity_1\", \"organisation_entity_2\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3bbea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "addressable_issues = entity_join_all[entity_join_all[\"action\"] != \"ignore\"]\n",
    "\n",
    "print(f\"there are {len(addressable_issues)} addressable issues in total\")\n",
    "print(\"\\n\")\n",
    "addressable_issues.groupby(['issue_type', 'intersection_type', 'action', 'priority']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6a6e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count of issues by type breakdown\n",
    "\n",
    "print(f\"there are {len(entity_join_all)} issues in total\")\n",
    "print(\"\\n\")\n",
    "entity_join_all.groupby(['issue_type', 'intersection_type', 'action', 'priority', 'multiple_issues', 'hint']).size().head(40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63442f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write full report table to csv\n",
    "\n",
    "nicecols = [\n",
    "    'entity_join', 'entity_1', 'entry_date_1', 'name_1', 'organisation_entity_1',\n",
    "    'reference_1', 'organisation_name_1', \n",
    "    'entity_2', 'entry_date_2', 'name_2', 'organisation_entity_2',\n",
    "    'reference_2', 'organisation_name_2', \n",
    "    'pct_min_intersection', \n",
    "    'p_pct_intersect', 's_pct_intersect',\n",
    "    'date_match', 'entity_old',\n",
    "    'intersection_type', 'issue_type', 'action',\n",
    "    'priority', 'hint', 'multiple_issues'\n",
    "    ]\n",
    "\n",
    "# entity_join_all[nicecols].to_csv(os.path.join(data_dir, \"issues_all.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297984d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lpa_fund_list = ['Buckinghamshire Council','Doncaster Metropolitan Borough Council','Gloucester City Council','London Borough of Camden','London Borough of Lambeth','London Borough of Southwark','Medway Council','Newcastle City Council','Birmingham City Council','Canterbury City Council','Epsom and Ewell Borough Council','London Borough of Barnet','Gateshead Metropolitan Borough Council','Great Yarmouth Borough Council','Royal Borough of Kingston upon Thames','St Albans City and District Council','Tewkesbury Borough Council','West Berkshire Council','Dorset District Council','Dover District Council','Liverpool City Council','London Borough of Redbridge','London Borough of Waltham Forest','North Lincolnshire Council','North Somerset Council','Salford City Council','Wirral Borough Council']\n",
    "\n",
    "lpa_fund_issues = entity_join_all[\n",
    "    entity_join_all[\"organisation_name_1\"].isin(lpa_fund_list) | entity_join_all[\"organisation_name_2\"].isin(lpa_fund_list)\n",
    "    ]\n",
    "\n",
    "# export issues list for all funded lpas\n",
    "# lpa_fund_issues[nicecols].to_csv(os.path.join(data_dir, \"issues_all-funded_LPAs.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041644b2",
   "metadata": {},
   "source": [
    "## Checking issues for funded LPAs - external duplicates (LPA to Historic England)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd9b134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarise and output all non-ignore issues\n",
    "issues_2b_df = entity_join_all.loc[\n",
    "    (entity_join_all[\"issue_type\"] == \"Between organisations - Historic England to LPA\") & \n",
    "    (entity_join_all[\"action\"] != \"ignore\") &\n",
    "    (entity_join_all[\"organisation_name_1\"].isin(lpa_fund_list))].copy()\n",
    "\n",
    "# add in extra LPA - HE overlap types field for this table\n",
    "issues_2b_df.loc[:, \"org_overlap_type\"] = np.select(\n",
    "    [\n",
    "        (issues_2b_df[\"p_pct_intersect\"] >= MATCH_LOWER_THRESH) & (issues_2b_df[\"s_pct_intersect\"] >= MATCH_LOWER_THRESH),\n",
    "        (issues_2b_df[\"p_pct_intersect\"] <= EDGE_UPPER_THRESH) & (issues_2b_df[\"s_pct_intersect\"] <= EDGE_UPPER_THRESH),\n",
    "        (issues_2b_df[\"p_pct_intersect\"] >= MATCH_LOWER_THRESH),\n",
    "        (issues_2b_df[\"s_pct_intersect\"] >= MATCH_LOWER_THRESH)\n",
    "    ],\n",
    "    [\n",
    "        \"LPA and HE polygons closely match\", \"LPA and HE edges overlap\", \n",
    "        \"LPA polygon covered by larger Historic England polygon\", \"LPA polygon covers smaller Historic England polygon\"\n",
    "    ],\n",
    "    default = \"Ambiguous overlap of LPA and Historic England polygons\"\n",
    ")\n",
    "\n",
    "# issues_2b_df[nicecols + [\"org_overlap_type\"]].to_csv(os.path.join(data_dir, \"issues_type_2b-between_org-HE_to_LPA-funded_LPAs.csv\"))\n",
    "\n",
    "# summarise\n",
    "issues_2b_df.groupby([\"issue_type\", \"intersection_type\", \"action\", \"priority\", \"org_overlap_type\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d102fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check no. of issues per LPA \n",
    "issues_2b_df.groupby([\"organisation_entity_1\", \"organisation_name_1\"]).size().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a28749",
   "metadata": {},
   "source": [
    "### Map for LPA analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf87dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save HE to LPA issues which need further investigation\n",
    "investigates = issues_2b_df.loc[issues_2b_df[\"action\"] == \"investigate\"].copy()\n",
    "\n",
    "# Check no. of issues per LPA \n",
    "investigates.groupby([\"organisation_entity_1\", \"organisation_name_1\"]).size().sort_values(ascending = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0836a606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get issues for selected LPA\n",
    "org_name = \"Great Yarmouth Borough Council\"\n",
    "\n",
    "issues_lpa = investigates[(issues_2b_df[\"organisation_name_1\"] == org_name)].copy()\n",
    "\n",
    "issues_lpa.groupby([\"issue_type\", \"intersection_type\", \"action\", \"priority\", \"org_overlap_type\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13774135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get geometries for entities with issues and split into LPA and Historic England\n",
    "issue_geoms = entity_gdf[entity_gdf[\"entity\"].isin(get_issue_entities(issues_lpa))].to_crs(4326)\n",
    "\n",
    "lpa_geoms = issue_geoms[issue_geoms[\"organisation_entity\"] != 16]\n",
    "he_geoms = issue_geoms[issue_geoms[\"organisation_entity\"] == 16]\n",
    "\n",
    "# join the overlap type field onto the LPA geoms to use in the map\n",
    "lpa_geoms = lpa_geoms.merge(\n",
    "    issues_2b_df[[\"entity_1\", \"org_overlap_type\"]].drop_duplicates(),\n",
    "    how = \"left\",\n",
    "    left_on = \"entity\",\n",
    "    right_on = \"entity_1\"\n",
    ")\n",
    "\n",
    "# lpa_geoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd9a7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define colours\n",
    "color_dict = dict(\n",
    "    zip(\n",
    "        lpa_geoms[\"org_overlap_type\"].drop_duplicates().values, \n",
    "        [\"#fc8d62\", \"#8da0cb\", \"#e78ac3\", \"#ffd92f\", \"#e5c494\"])\n",
    ")\n",
    "\n",
    "# map\n",
    "m = folium.Map(\n",
    "    location=[52.60707, 1.728],\n",
    "    tiles=\"CartoDB positron\",\n",
    "    zoom_start=11,\n",
    ")\n",
    "\n",
    "popup = folium.GeoJsonPopup(fields=[\"name\", \"reference\", \"organisation_name\", \"org_overlap_type\"])\n",
    "\n",
    "# styling for LPA\n",
    "folium.GeoJson(\n",
    "    lpa_geoms.to_json(),\n",
    "    popup=popup,\n",
    "    name = \"Yarmouth\",\n",
    "    style_function=lambda feature: {\n",
    "        \"fillColor\": color_dict[feature[\"properties\"][\"org_overlap_type\"]],\n",
    "        \"color\": color_dict[feature[\"properties\"][\"org_overlap_type\"]],\n",
    "        \"weight\": 2,\n",
    "        \"fillOpacity\": 0.5,\n",
    "    },\n",
    "    highlight_function=lambda feature: {\n",
    "        \"fillColor\": \"#ffff00\"\n",
    "    }\n",
    ").add_to(m)\n",
    "\n",
    "popup2 = folium.GeoJsonPopup(fields=[\"name\", \"reference\", \"organisation_name\"])\n",
    "\n",
    "# styling for HE\n",
    "folium.GeoJson(\n",
    "    he_geoms.to_json(),\n",
    "    popup=popup2,\n",
    "    name = \"Historic England\",\n",
    "    show = False,\n",
    "    style_function=lambda feature: {\n",
    "        \"fillColor\": None,\n",
    "        \"color\": \"green\",\n",
    "        \"dashArray\": \"5, 5\",\n",
    "        \"weight\": 2,\n",
    "        \"fillOpacity\": 0.1,\n",
    "    },\n",
    "    highlight_function=lambda feature: {\n",
    "        \"fillColor\": \"green\",\n",
    "        \"fillOpacity\": 0.5\n",
    "    }\n",
    ").add_to(m)\n",
    "\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "org_formatted = org_name.replace(\" \", \"_\")\n",
    "# m.save(f\"issues_map-{org_formatted}.html\")\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c2f7a9",
   "metadata": {},
   "source": [
    "## Checking issues for funded LPAs - internal duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a803eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export issues list for all funded lpas\n",
    "# lpa_fund_issues[nicecols].to_csv(\"temp_issues_funded.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afd3f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epsom ones to remove\n",
    "# entity_gdf[(entity_gdf[\"organisation_entity\"] == 129) & (entity_gdf[\"reference\"].apply(lambda x: len(x)) < 5)].to_csv(\"temp_epsom_to_remove.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1c5946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in current lambeth endpoint and outer join to existing entities\n",
    "lambeth_endpoint_gdf = gpd.read_file(\"https://gis.lambeth.gov.uk/arcgis/rest/services/LambethConservationAreas/MapServer/0/query?where=1%3D1&text=&objectIds=&time=&geometry=&geometryType=esriGeometryEnvelope&inSR=&spatialRel=esriSpatialRelIntersects&distance=&units=esriSRUnit_Foot&relationParam=&outFields=*&returnGeometry=true&returnTrueCurves=false&maxAllowableOffset=&geometryPrecision=&outSR=&havingClause=&returnIdsOnly=false&returnCountOnly=false&orderByFields=&groupByFieldsForStatistics=&outStatistics=&returnZ=false&returnM=false&gdbVersion=&historicMoment=&returnDistinctValues=false&resultOffset=&resultRecordCount=&returnExtentOnly=false&datumTransformation=&parameterValues=&rangeValues=&quantizationParameters=&featureEncoding=esriDefault&f=geojson\")\n",
    "\n",
    "lambeth_endpoint_gdf = lambeth_endpoint_gdf[[\"CA_REF_NO\"]]\n",
    "lambeth_endpoint_gdf[\"record_in_endpoint\"] = True\n",
    "\n",
    "# nrow(lambeth_endpoint_gdf)\n",
    "# lambeth_endpoint_gdf.head()\n",
    "\n",
    "entity_df[entity_df[\"organisation_entity\"] == 192][[\"entity\", \"reference\", \"name\"]].merge(\n",
    "    lambeth_endpoint_gdf,\n",
    "    how =  \"outer\",\n",
    "    left_on  = \"reference\", right_on = \"CA_REF_NO\"\n",
    ").to_csv(\"../data/geo_analysis/funded_lpa_checks/temp_lambeth_entity_endpoint_check.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e634bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsom_endpoint_gdf = pd.read_csv(\"../data/geo_analysis/funded_lpa_checks/Epsom_conservation-area_WFS.csv\")\n",
    "epsom_endpoint_gdf = epsom_endpoint_gdf[[\"name\", \"reference\"]]\n",
    "epsom_endpoint_gdf[\"record_in_endpoint\"] = True\n",
    "\n",
    "nrow(epsom_endpoint_gdf)\n",
    "epsom_endpoint_gdf.head()\n",
    "\n",
    "epsom_pdp_gdf = gpd.read_file(\"https://www.planning.data.gov.uk/entity.geojson?organisation_entity=129&dataset=conservation-area&limit=100\")\n",
    "epsom_pdp_gdf[\"record_in_pdp\"] = True\n",
    "\n",
    "nrow(epsom_pdp_gdf)\n",
    "# epsom_pdp_gdf.head()\n",
    "\n",
    "epsom_pdp_gdf[[\"entity\", \"reference\", \"name\", \"record_in_pdp\"]].merge(\n",
    "    epsom_endpoint_gdf,\n",
    "    how =  \"outer\",\n",
    "    on  = \"reference\"\n",
    ").to_csv(\"../data/geo_analysis/funded_lpa_checks/temp_epsom_entity_endpoint_check.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdp_jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
