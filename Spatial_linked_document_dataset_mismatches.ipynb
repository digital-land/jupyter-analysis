{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4fc9742-3f39-4ec6-98e5-939f50b15c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib.parse\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a95253-e56c-4a04-8f47-271277974c5e",
   "metadata": {},
   "source": [
    "# Merging the Entity Tables of Two Datasets\n",
    "The following cell should allow you to select a combination of datasets, fetch and merge the two respective entity dataframes. This often leads to null values in the x/y fields, depending on which dataset entries did not match with one in the other dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8476e38b-9a41-42e4-9c54-7f65ddf491ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ca6157c84eb45cba4f8dc9d99c91be9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='dataset_combination', options={'Article 4 Direction and Article 4 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasette_url = \"https://datasette.planning.data.gov.uk/\"\n",
    "\n",
    "global collection_options    \n",
    "collection_options = {\n",
    "    \"Article 4 Direction and Article 4 Direction Area\": [\"article-4-direction\", \"article-4-direction-area\"],\n",
    "    \"Conservation Area and Documents\": [\"conservation-area\",\"conservation-area-document\"],\n",
    "    \"Tree Preservation Order and Tree\": [\"tree-preservation-order\", \"tree\"],\n",
    "    \"Tree Preservation Order and Tree Preservation Zones\":[\"tree-preservation-order\", \"tree-preservation-zone\"]\n",
    "}\n",
    "\n",
    "collection_dropdown = widgets.Dropdown(\n",
    "    options=collection_options,\n",
    "    description=\"Select dataset combination:\",\n",
    ")\n",
    "\n",
    "def get_organisations():\n",
    "    global org_df  \n",
    "    params = urllib.parse.urlencode({\n",
    "        \"sql\": f\"\"\"\n",
    "        select\n",
    "          *\n",
    "        from\n",
    "          organisation o\n",
    "        \"\"\",\n",
    "        \"_size\": \"max\"\n",
    "    })\n",
    "    url = f\"{datasette_url}digital-land.csv?{params}\"\n",
    "    org_df = pd.read_csv(url)\n",
    "    return org_df\n",
    "\n",
    "def get_spatial_doc_matched_df(dataset_combination):\n",
    "    global spatial_doc_matched_df\n",
    "    df_one = pd.read_csv(f\"https://files.planning.data.gov.uk/dataset/{dataset_combination[0]}.csv\")\n",
    "    df_two = pd.read_csv(f\"https://files.planning.data.gov.uk/dataset/{dataset_combination[1]}.csv\")\n",
    "    df_one = df_one[['entity', 'dataset', 'organisation-entity', 'reference']]\n",
    "    df_two = df_two[['entity','dataset', 'organisation-entity', dataset_combination[0]]]\n",
    "    merged_df = pd.merge(df_one, df_two, how='outer', left_on=['reference', 'organisation-entity'], right_on=[dataset_combination[0], 'organisation-entity'])\n",
    "    org_df = get_organisations()[['name', 'entity']]\n",
    "    merged_df = pd.merge(merged_df, org_df, how='left', left_on='organisation-entity', right_on='entity')\n",
    "    spatial_doc_matched_df = merged_df[['entity_x','entity_y','dataset_x', 'dataset_y', 'name', 'reference', dataset_combination[0]]]\n",
    "    return spatial_doc_matched_df\n",
    "\n",
    "widgets.interact(get_spatial_doc_matched_df, dataset_combination=collection_options)\n",
    "initial_organisation = collection_dropdown.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e18307b-f126-4fab-baf6-b5e2972f3e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to download the table? (yes/no):  yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query result downloaded as 'spatial_doc_matched_df.csv'\n"
     ]
    }
   ],
   "source": [
    "download = input(\"Do you want to download the table? (yes/no): \")\n",
    "\n",
    "if download.lower() == \"yes\":\n",
    "    spatial_doc_matched_df.to_csv(\"spatial_doc_matched_df.csv\", index=False)\n",
    "    print(\"Query result downloaded as 'spatial_doc_matched_df.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64811b9-8905-4ac7-b2b0-2317ce1cf6c5",
   "metadata": {},
   "source": [
    "# Filtering for Rows with Null Values\n",
    "The following cell takes the dataframe generated above and filters it, selecting only rows with null values. This is to identify which entities from dataframe 'x' do not match with entities in dataframe 'y' (and vice versa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7092019c-191d-4640-bac1-34956d69adb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6b298bb3b7649e283a1d98650601169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='dataset_combination', options={'Article 4 Direction and Article 4 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_mismatched_entities(dataset_combination):\n",
    "    global mismatched_entities\n",
    "    df = get_spatial_doc_matched_df(dataset_combination)\n",
    "    null_mask = df.isnull().any(axis=1)\n",
    "    mismatched_entities = df[null_mask].reset_index(drop=True)\n",
    "    return mismatched_entities\n",
    "    \n",
    "widgets.interact(get_mismatched_entities, dataset_combination=collection_options)\n",
    "initial_organisation = collection_dropdown.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "335dbf9c-ae5f-465e-a36e-73298d3dfba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to download the table? (yes/no):  yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query result downloaded as 'mismatched_entities.csv'\n"
     ]
    }
   ],
   "source": [
    "download = input(\"Do you want to download the table? (yes/no): \")\n",
    "\n",
    "if download.lower() == \"yes\":\n",
    "    mismatched_entities.to_csv(\"mismatched_entities.csv\", index=False)\n",
    "    print(\"Query result downloaded as 'mismatched_entities.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
