{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fc9742-3f39-4ec6-98e5-939f50b15c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib.parse\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a95253-e56c-4a04-8f47-271277974c5e",
   "metadata": {},
   "source": [
    "# Merging the Entity Tables of Two Datasets\n",
    "The following cell should allow you to select a combination of datasets, fetch and merge the two respective entity dataframes. This often leads to null values in the x/y fields, depending on which dataset entries did not match with one in the other dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8476e38b-9a41-42e4-9c54-7f65ddf491ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasette_url = \"https://datasette.planning.data.gov.uk/\"\n",
    "\n",
    "global collection_options    \n",
    "collection_options = {\n",
    "    \"Article 4 Direction and Article 4 Direction Area\": [\"article-4-direction\", \"article-4-direction-area\"],\n",
    "    \"Conservation Area and Documents\": [\"conservation-area\",\"conservation-area-document\"],\n",
    "    \"Tree Preservation Order, Tree and Tree Preservation Zones\":[\"tree-preservation-order\", \"tree-preservation-zone\", \"tree\"]\n",
    "}\n",
    "\n",
    "collection_dropdown = widgets.Dropdown(\n",
    "    options=collection_options,\n",
    "    description=\"Select dataset combination:\",\n",
    ")\n",
    "\n",
    "def get_organisations():\n",
    "    global org_df  \n",
    "    params = urllib.parse.urlencode({\n",
    "        \"sql\": f\"\"\"\n",
    "        select\n",
    "          *\n",
    "        from\n",
    "          organisation o\n",
    "        \"\"\",\n",
    "        \"_size\": \"max\"\n",
    "    })\n",
    "    url = f\"{datasette_url}digital-land.csv?{params}\"\n",
    "    org_df = pd.read_csv(url)\n",
    "    return org_df\n",
    "\n",
    "def get_spatial_doc_matched_df(dataset_combination):\n",
    "    global spatial_doc_matched_df\n",
    "    df_one = pd.read_csv(f\"https://files.planning.data.gov.uk/dataset/{dataset_combination[0]}.csv\")\n",
    "    df_two = pd.read_csv(f\"https://files.planning.data.gov.uk/dataset/{dataset_combination[1]}.csv\")\n",
    "    df_one = df_one[['entity', 'dataset', 'organisation-entity', 'reference']]\n",
    "    df_two = df_two[['entity','dataset', 'organisation-entity', dataset_combination[0]]]\n",
    "\n",
    "    # The logic here assumes that if the combination is of three datasets, that the second and third are the geometry datasets and will be appended\n",
    "    if (len(dataset_combination) == 3):\n",
    "        df_three = pd.read_csv(f\"https://files.planning.data.gov.uk/dataset/{dataset_combination[2]}.csv\")\n",
    "        df_three = df_three[['entity','dataset', 'organisation-entity', dataset_combination[0]]]\n",
    "        df_two = pd.concat([df_two, df_three])\n",
    "    \n",
    "    merged_df = pd.merge(df_one, df_two, how='outer', left_on=['reference', 'organisation-entity'], right_on=[dataset_combination[0], 'organisation-entity'])\n",
    "    org_df = get_organisations()[['name', 'entity']]\n",
    "    merged_df = pd.merge(merged_df, org_df, how='left', left_on='organisation-entity', right_on='entity')\n",
    "    spatial_doc_matched_df = merged_df[['entity_x','entity_y','dataset_x', 'dataset_y', 'name', 'reference', dataset_combination[0]]]\n",
    "    return spatial_doc_matched_df\n",
    "\n",
    "widgets.interact(get_spatial_doc_matched_df, dataset_combination=collection_options)\n",
    "initial_organisation = collection_dropdown.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e18307b-f126-4fab-baf6-b5e2972f3e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "download = input(\"Do you want to download the table? (yes/no): \")\n",
    "\n",
    "if download.lower() == \"yes\":\n",
    "    spatial_doc_matched_df.to_csv(\"spatial_doc_matched_df.csv\", index=False)\n",
    "    print(\"Query result downloaded as 'spatial_doc_matched_df.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64811b9-8905-4ac7-b2b0-2317ce1cf6c5",
   "metadata": {},
   "source": [
    "# Filtering for Rows with Null Values\n",
    "The following cell takes the dataframe generated above and filters it, selecting only rows with null values. This is to identify which entities from dataframe 'x' do not match with entities in dataframe 'y' (and vice versa). Keep in mind this also returns rows which have null values in both reference columns and therefore didn't match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7092019c-191d-4640-bac1-34956d69adb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mismatched_entities(dataset_combination):\n",
    "    global mismatched_entities\n",
    "    df = get_spatial_doc_matched_df(dataset_combination)\n",
    "    null_mask = df.isnull().any(axis=1)\n",
    "    mismatched_entities = df[null_mask].reset_index(drop=True)\n",
    "    return mismatched_entities\n",
    "    \n",
    "widgets.interact(get_mismatched_entities, dataset_combination=collection_options)\n",
    "initial_organisation = collection_dropdown.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d42aec-b602-4b6c-be1d-59b19aa5623d",
   "metadata": {},
   "outputs": [],
   "source": [
    "download = input(\"Do you want to download the table? (yes/no): \")\n",
    "\n",
    "if download.lower() == \"yes\":\n",
    "    mismatched_entities.to_csv(\"mismatched_entities.csv\", index=False)\n",
    "    print(\"Query result downloaded as 'mismatched_entities.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5713fc70-1890-46ec-8718-65099a84188d",
   "metadata": {},
   "source": [
    "# Filtering for Rows without References\n",
    "Many unmatched references can be created because they were not initially assigned references, therefore will not be matched using the above method. The following cell filters so that it returns only rows which do contain a reference from either dataset, but still could not be matched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3937b3a9-f95c-42fb-a9a8-8accb1fc286d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNonNullReferences (dataset_combination):\n",
    "    global mismatched_entities_with_references\n",
    "    df = get_mismatched_entities(dataset_combination)\n",
    "    mismatched_entities_with_references = df[df[\"reference\"].notnull() | df[dataset_combination[0]].notnull()].reset_index(drop=True)\n",
    "    return mismatched_entities_with_references\n",
    "\n",
    "widgets.interact(getNonNullReferences, dataset_combination=collection_options)\n",
    "initial_organisation = collection_dropdown.value\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c374ae6-b723-4149-b1a2-c3ad06671e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "download = input(\"Do you want to download the table? (yes/no): \")\n",
    "\n",
    "if download.lower() == \"yes\":\n",
    "    mismatched_entities_with_references.to_csv(\"mismatched_entities_with_references.csv\", index=False)\n",
    "    print(\"Query result downloaded as 'mismatched_entities_with_references.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faf0db5-a721-4e61-aa7e-1a9df5bd6b2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
